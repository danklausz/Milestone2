{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed08001c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Collection - NBA Games (2021-2024)\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from nba_api.stats.endpoints import leaguegamelog\n",
    "from nba_api.stats.endpoints import leaguegamefinder\n",
    "from nba_api.stats.static import teams\n",
    "\n",
    "## Fetch 2023-24 Season\n",
    "print(\"Fetching 2023-24 season...\")\n",
    "games_finder_24 = leaguegamefinder.LeagueGameFinder(\n",
    "    season_nullable='2023-24',\n",
    "    timeout=120\n",
    ")\n",
    "games_24 = games_finder_24.get_data_frames()[0]\n",
    "print(f\"2023-24: {len(games_24)} records\")\n",
    "time.sleep(2)\n",
    "\n",
    "## Get 2022-23 season\n",
    "print(\"Fetching 2022-23 season...\")\n",
    "games_finder_23 = leaguegamefinder.LeagueGameFinder(\n",
    "    season_nullable='2022-23',\n",
    "    timeout=120\n",
    ")\n",
    "games_23 = games_finder_23.get_data_frames()[0]\n",
    "print(f\"2022-23: {len(games_23)} records\")\n",
    "time.sleep(2)\n",
    "\n",
    "## Get 2021-22 season\n",
    "print(\"Fetching 2021-22 season...\")\n",
    "games_finder_22 = leaguegamefinder.LeagueGameFinder(\n",
    "    season_nullable='2021-22',\n",
    "    timeout=120\n",
    ")\n",
    "games_22 = games_finder_22.get_data_frames()[0]\n",
    "print(f\"2021-22: {len(games_22)} records\")\n",
    "time.sleep(2)\n",
    "\n",
    "## Get 2020-21 season\n",
    "print(\"Fetching 2020-21 season...\")\n",
    "games_finder_21 = leaguegamefinder.LeagueGameFinder(\n",
    "    season_nullable='2020-21',\n",
    "    timeout=120\n",
    ")\n",
    "games_21 = games_finder_21.get_data_frames()[0]\n",
    "print(f\"2020-21: {len(games_21)} records\")\n",
    "\n",
    "## Combine All Seasons\n",
    "all_games = pd.concat([games_21, games_22, games_23, games_24], ignore_index=True)\n",
    "print(f\"\\nTotal combined records: {len(all_games)}\")\n",
    "\n",
    "# Get unique game IDs sorted\n",
    "unique_game_ids = sorted(all_games['GAME_ID'].dropna().unique())  # There are NAs to drop\n",
    "print(f\"Unique games: {len(unique_game_ids)}\")\n",
    "\n",
    "## Save to CSV\n",
    "all_games.to_csv('nba_games_2021_to_2024.csv', index=False)\n",
    "print(\"Written to 'nba_games_2021_to_2024.csv'\")\n",
    "\n",
    "# Save unique game IDs separately\n",
    "game_ids_df = pd.DataFrame({'GAME_ID': unique_game_ids})\n",
    "game_ids_df['GAME_ID'] = game_ids_df['GAME_ID'].astype(str)\n",
    "game_ids_df.to_csv('unique_game_ids.csv', index=False)\n",
    "print(\"Written unique game IDs to 'unique_game_ids.csv'\")\n",
    "\n",
    "## Summary\n",
    "print(f\"\\nTotal records: {len(all_games)}\")\n",
    "print(f\"Unique games: {len(unique_game_ids)}\")\n",
    "print(f\"First game ID: {unique_game_ids[0]}\")\n",
    "print(f\"Last game ID: {unique_game_ids[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71c3cac",
   "metadata": {},
   "source": [
    "With the NBA API it was a trial and error process to pull data. It did not seem like there was a definitive reason why data was not pulling. So we built a script that would simply run multiple passes over a unique games list and try to get a complete set of data. This proved to be successful. Even testing different sleep times proved to be unsuccessful.\n",
    "\n",
    "Basically we were collecting two sets of data one was from \"boxscoretraditionalv2\" which gave team and player stats. We needed to collect a set for the first half and the complete game this would give us a complete picture of the data so we could predict a second half point total. We also used \"boxscoresummaryv2\" to collect game times, referees, injuries, points by qtr. It would basically pull a list of 7 tables, the multiple pass code was neccesarily for this as it seemed to fail to pull more often. In addition we had to patch this API pull to code in 'GAME_ID' for a couple of the tables that did not have it present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42255892",
   "metadata": {},
   "outputs": [],
   "source": [
    "## First Half Box Score Data - Multi-Pass Version\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "from nba_api.stats.endpoints import boxscoretraditionalv2\n",
    "\n",
    "## Configuration\n",
    "PASS_NUMBER = 3\n",
    "INPUT_FILE = 'unique_game_ids.csv' if PASS_NUMBER == 1 else f'failed_game_ids_fh_pass{PASS_NUMBER-1}.csv'\n",
    "OUTPUT_SUFFIX = '' if PASS_NUMBER == 1 else f'_pt{PASS_NUMBER}'\n",
    "\n",
    "\n",
    "## Load Game IDs\n",
    "game_ids_df = pd.read_csv(INPUT_FILE, dtype={'GAME_ID': str})\n",
    "game_ids_list = game_ids_df['GAME_ID'].tolist()\n",
    "\n",
    "print(f\"=== PASS {PASS_NUMBER} ===\")\n",
    "print(f\"Total games to process: {len(game_ids_list)}\")\n",
    "print(f\"First game ID: {game_ids_list[0]}\")\n",
    "print(f\"Last game ID: {game_ids_list[-1]}\")\n",
    "\n",
    "\n",
    "## Initialize Data Collection\n",
    "all_fh_player_stats = []\n",
    "all_fh_team_stats = []\n",
    "all_fh_starter_bench = []\n",
    "\n",
    "# Track progress\n",
    "games_processed = 0\n",
    "games_failed = 0\n",
    "start_time = time.time()\n",
    "failed_game_ids = []\n",
    "\n",
    "\n",
    "## First Half Loop\n",
    "for idx, game_id in enumerate(game_ids_list):\n",
    "    try:\n",
    "        # Call API\n",
    "        fh = boxscoretraditionalv2.BoxScoreTraditionalV2(\n",
    "            game_id=game_id,\n",
    "            range_type=1,\n",
    "            start_period=1,\n",
    "            end_period=2\n",
    "        )\n",
    "        \n",
    "        # Convert to dataframes\n",
    "        dfs = fh.get_data_frames()\n",
    "        \n",
    "        # Append\n",
    "        all_fh_player_stats.append(dfs[0])\n",
    "        all_fh_team_stats.append(dfs[1])\n",
    "        all_fh_starter_bench.append(dfs[2])\n",
    "        \n",
    "        # Track process\n",
    "        games_processed += 1\n",
    "        \n",
    "        # Progress update every 1000 games\n",
    "        if (idx + 1) % 1000 == 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print(f\"Progress: {idx + 1}/{len(game_ids_list)} games ({games_processed} success, {games_failed} failed) - {elapsed/60:.1f} min elapsed\")\n",
    "        \n",
    "        time.sleep(0.5)\n",
    "        \n",
    "    except Exception as e:\n",
    "        games_failed += 1\n",
    "        failed_game_ids.append(game_id)\n",
    "        \n",
    "        # Print at 1st failure and every 50\n",
    "        if games_failed == 1 or games_failed % 50 == 0:\n",
    "            print(f\"Failures: {games_failed}\")\n",
    "        continue\n",
    "\n",
    "\n",
    "## Combine and Save\n",
    "if all_fh_player_stats:\n",
    "    fh_players_combined = pd.concat(all_fh_player_stats, ignore_index=True)\n",
    "    fh_teams_combined = pd.concat(all_fh_team_stats, ignore_index=True)\n",
    "    fh_starters_bench_combined = pd.concat(all_fh_starter_bench, ignore_index=True)\n",
    "    \n",
    "    # Save with suffix\n",
    "    fh_players_combined.to_csv(f'first_half_players{OUTPUT_SUFFIX}.csv', index=False)\n",
    "    fh_teams_combined.to_csv(f'first_half_teams{OUTPUT_SUFFIX}.csv', index=False)\n",
    "    fh_starters_bench_combined.to_csv(f'first_half_starters_bench{OUTPUT_SUFFIX}.csv', index=False)\n",
    "    \n",
    "    print(f\"\\nSuccessfully processed: {games_processed}\")\n",
    "    print(f\"Player records: {len(fh_players_combined)}\")\n",
    "    print(f\"Team records: {len(fh_teams_combined)}\")\n",
    "else:\n",
    "    print(\"\\nNo data collected - all games failed\")\n",
    "\n",
    "\n",
    "# Save failed game IDs\n",
    "if failed_game_ids:\n",
    "    failed_df = pd.DataFrame({'GAME_ID': failed_game_ids})\n",
    "    failed_df.to_csv(f'failed_game_ids_fh_pass{PASS_NUMBER}.csv', index=False)\n",
    "    print(f\"\\nFailed game IDs saved to 'failed_game_ids_fh_pass{PASS_NUMBER}.csv'\")\n",
    "    print(f\"Failed games: {len(failed_game_ids)}\")\n",
    "    print(f\"\\nTo run pass {PASS_NUMBER + 1}:\")\n",
    "else:\n",
    "    print(f\"\\n All games successful - no need for pass {PASS_NUMBER + 1}!\")\n",
    "\n",
    "\n",
    "## Final Summary\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"\\n=== PASS {PASS_NUMBER} COMPLETE ===\")\n",
    "print(f\"Successfully processed: {games_processed}/{len(game_ids_list)}\")\n",
    "print(f\"Failed: {games_failed}/{len(game_ids_list)}\")\n",
    "print(f\"Total time: {elapsed/60:.1f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84affc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Box Score Summary Data - Multi-Pass Auto-Loop Version\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "from nba_api.stats.endpoints import boxscoresummaryv2\n",
    "\n",
    "\n",
    "## Configuration\n",
    "MAX_PASSES = 15\n",
    "INITIAL_INPUT_FILE = 'unique_game_ids.csv'\n",
    "\n",
    "\n",
    "## Auto-Loop Through Passes\n",
    "for pass_num in range(1, MAX_PASSES + 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"=== STARTING PASS {pass_num} ===\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Determine input file\n",
    "    if pass_num == 1:\n",
    "        input_file = INITIAL_INPUT_FILE\n",
    "    else:\n",
    "        input_file = f'failed_game_ids_bss_pass{pass_num-1}.csv'\n",
    "        \n",
    "        # Check if there are failures to process\n",
    "        if not os.path.exists(input_file):\n",
    "            print(f\"No failures from pass {pass_num-1} - All done!\")\n",
    "            break\n",
    "    \n",
    "    # Loading Game IDs\n",
    "    game_ids_df = pd.read_csv(input_file, dtype={'GAME_ID': str})\n",
    "    game_ids_list = game_ids_df['GAME_ID'].tolist()\n",
    "    \n",
    "    # Output suffix\n",
    "    output_suffix = '' if pass_num == 1 else f'_pt{pass_num}'\n",
    "    \n",
    "    print(f\"Total games to process: {len(game_ids_list)}\")\n",
    "    print(f\"First game ID: {game_ids_list[0]}\")\n",
    "    print(f\"Last game ID: {game_ids_list[-1]}\")\n",
    "    \n",
    "    \n",
    "    ## Data Collection\n",
    "    all_game_summary = []\n",
    "    all_team_stats = []\n",
    "    all_refs = []\n",
    "    all_inactive = []\n",
    "    all_game_info = []\n",
    "    all_points_by_qtr = []\n",
    "    all_last_meeting = []\n",
    "    \n",
    "    # Track progress\n",
    "    games_processed = 0\n",
    "    games_failed = 0\n",
    "    start_time = time.time()\n",
    "    failed_game_ids = []\n",
    "    \n",
    "    \n",
    "    ## Loop through games\n",
    "    for idx, game_id in enumerate(game_ids_list):\n",
    "        try:\n",
    "            # Call API\n",
    "            summary = boxscoresummaryv2.BoxScoreSummaryV2(game_id=game_id)\n",
    "            \n",
    "            # Get all dataframes\n",
    "            dfs = summary.get_data_frames()\n",
    "            \n",
    "            # Add GAME_ID to each dataframe if missing\n",
    "            for i in range(7):  # Only process 0-6, skip 7-8\n",
    "                if 'GAME_ID' not in dfs[i].columns:\n",
    "                    dfs[i]['GAME_ID'] = game_id\n",
    "            \n",
    "            # Append only the ones we want (0-6, drop 7-8)\n",
    "            all_game_summary.append(dfs[0])\n",
    "            all_team_stats.append(dfs[1])\n",
    "            all_refs.append(dfs[2])\n",
    "            all_inactive.append(dfs[3])\n",
    "            all_game_info.append(dfs[4])\n",
    "            all_points_by_qtr.append(dfs[5])\n",
    "            all_last_meeting.append(dfs[6])\n",
    "            \n",
    "            games_processed += 1\n",
    "            \n",
    "            # Progress Update every 1000 games\n",
    "            if (idx + 1) % 1000 == 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                print(f\"Progress: {idx + 1}/{len(game_ids_list)} games ({games_processed} success, {games_failed} failed) - {elapsed/60:.1f} min elapsed\")\n",
    "            \n",
    "            time.sleep(0.5)\n",
    "            \n",
    "        except Exception as e:\n",
    "            games_failed += 1\n",
    "            failed_game_ids.append(game_id)\n",
    "            if games_failed == 1 or games_failed % 50 == 0:\n",
    "                print(f\"Failures: {games_failed}\")\n",
    "            continue\n",
    "    \n",
    "    ## Combine and Save\n",
    "    if all_game_summary:\n",
    "        game_summary_combined = pd.concat(all_game_summary, ignore_index=True)\n",
    "        team_stats_combined = pd.concat(all_team_stats, ignore_index=True)\n",
    "        refs_combined = pd.concat(all_refs, ignore_index=True)\n",
    "        inactive_combined = pd.concat(all_inactive, ignore_index=True)\n",
    "        game_info_combined = pd.concat(all_game_info, ignore_index=True)\n",
    "        points_qtr_combined = pd.concat(all_points_by_qtr, ignore_index=True)\n",
    "        last_meeting_combined = pd.concat(all_last_meeting, ignore_index=True)\n",
    "        \n",
    "        # Save with suffix\n",
    "        game_summary_combined.to_csv(f'game_summary{output_suffix}.csv', index=False)\n",
    "        team_stats_combined.to_csv(f'team_stats{output_suffix}.csv', index=False)\n",
    "        refs_combined.to_csv(f'refs{output_suffix}.csv', index=False)\n",
    "        inactive_combined.to_csv(f'inactive_players{output_suffix}.csv', index=False)\n",
    "        game_info_combined.to_csv(f'game_info{output_suffix}.csv', index=False)\n",
    "        points_qtr_combined.to_csv(f'points_by_quarter{output_suffix}.csv', index=False)\n",
    "        last_meeting_combined.to_csv(f'last_meeting{output_suffix}.csv', index=False)\n",
    "        \n",
    "        print(f\"\\nPass {pass_num} data saved!\")\n",
    "        print(f\"Successfully processed: {games_processed}\")\n",
    "    else:\n",
    "        print(f\"\\nPass {pass_num}: No data collected - all games failed\")\n",
    "    \n",
    "    \n",
    "    ## Save Failed Game IDs\n",
    "    if failed_game_ids:\n",
    "        failed_df = pd.DataFrame({'GAME_ID': failed_game_ids})\n",
    "        failed_df.to_csv(f'failed_game_ids_bss_pass{pass_num}.csv', index=False)\n",
    "        print(f\"Failed game IDs saved to 'failed_game_ids_bss_pass{pass_num}.csv'\")\n",
    "        print(f\"Failed games: {len(failed_game_ids)}\")\n",
    "    else:\n",
    "        print(f\"Pass {pass_num}: All games successful!\")\n",
    "    \n",
    "    \n",
    "    ## Pass Summary\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\n=== PASS {pass_num} COMPLETE ===\")\n",
    "    print(f\"Successfully processed: {games_processed}/{len(game_ids_list)}\")\n",
    "    print(f\"Failed: {games_failed}/{len(game_ids_list)}\")\n",
    "    print(f\"Total time: {elapsed/60:.1f} minutes\")\n",
    "    \n",
    "    # Check if we should continue to next pass\n",
    "    if not failed_game_ids:\n",
    "        print(f\"\\nAll games processed successfully! No need for more passes.\")\n",
    "        break\n",
    "    elif pass_num < MAX_PASSES:\n",
    "        print(f\"\\nWill attempt pass {pass_num + 1} with {len(failed_game_ids)} failed games...\")\n",
    "        time.sleep(5)  # Brief pause between passes\n",
    "    else:\n",
    "        print(f\"\\nReached maximum passes ({MAX_PASSES}). {len(failed_game_ids)} games still failed.\")\n",
    "\n",
    "print(\"\\n=== ALL PASSES COMPLETE ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd268331",
   "metadata": {},
   "source": [
    "This next cell block is code to concatenate all the various pass files together. This could have been more elegant but I hard coded the amount of passes I had for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028dbed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Concatenate Multi-Pass Files\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "## Initialize Storage\n",
    "combined_data = {}\n",
    "\n",
    "\n",
    "## First Half Files (3 Passes)\n",
    "fh_files = [\n",
    "    ('first_half_players', 3),\n",
    "    ('first_half_teams', 3),\n",
    "    ('first_half_starters_bench', 3)\n",
    "]\n",
    "\n",
    "for base_name, num_passes in fh_files:\n",
    "    all_dfs = []\n",
    "    \n",
    "    for pass_num in range(1, num_passes + 1):\n",
    "        if pass_num == 1:\n",
    "            filename = f'{base_name}.csv'\n",
    "        else:\n",
    "            filename = f'{base_name}_pt{pass_num}.csv'\n",
    "        \n",
    "        if os.path.exists(filename):\n",
    "            df = pd.read_csv(filename)\n",
    "            all_dfs.append(df)\n",
    "            print(f\" Loaded {filename}: {len(df)} records\")\n",
    "        else:\n",
    "            print(f\"{filename} not found, skipping\")\n",
    "    \n",
    "    if all_dfs:\n",
    "        combined = pd.concat(all_dfs, ignore_index=True)\n",
    "        combined_data[base_name] = combined\n",
    "        print(f\"Combined {base_name}: {len(combined)} total records\\n\")\n",
    "\n",
    "\n",
    "## Complete Game Files (5 Passes)\n",
    "cg_files = [\n",
    "    ('complete_game_players', 5),\n",
    "    ('complete_game_teams', 5),\n",
    "    ('complete_game_starters_bench', 5)\n",
    "]\n",
    "\n",
    "for base_name, num_passes in cg_files:\n",
    "    all_dfs = []\n",
    "    \n",
    "    for pass_num in range(1, num_passes + 1):\n",
    "        if pass_num == 1:\n",
    "            filename = f'{base_name}.csv'\n",
    "        else:\n",
    "            filename = f'{base_name}_pt{pass_num}.csv'\n",
    "        \n",
    "        if os.path.exists(filename):\n",
    "            df = pd.read_csv(filename)\n",
    "            all_dfs.append(df)\n",
    "            print(f\"Loaded {filename}: {len(df)} records\")\n",
    "        else:\n",
    "            print(f\"{filename} not found, skipping\")\n",
    "    \n",
    "    if all_dfs:\n",
    "        combined = pd.concat(all_dfs, ignore_index=True)\n",
    "        combined_data[base_name] = combined\n",
    "        print(f\"Combined {base_name}: {len(combined)} total records\\n\")\n",
    "\n",
    "\n",
    "## Box Score Summary Files (9 Passes)\n",
    "bss_files = [\n",
    "    ('game_summary', 9),\n",
    "    ('team_stats', 9),\n",
    "    ('refs', 9),\n",
    "    ('inactive_players', 9),\n",
    "    ('game_info', 9),\n",
    "    ('points_by_quarter', 9),\n",
    "    ('last_meeting', 9)\n",
    "]\n",
    "\n",
    "for base_name, num_passes in bss_files:\n",
    "    all_dfs = []\n",
    "    \n",
    "    for pass_num in range(1, num_passes + 1):\n",
    "        if pass_num == 1:\n",
    "            filename = f'{base_name}.csv'\n",
    "        else:\n",
    "            filename = f'{base_name}_pt{pass_num}.csv'\n",
    "        \n",
    "        if os.path.exists(filename):\n",
    "            df = pd.read_csv(filename)\n",
    "            all_dfs.append(df)\n",
    "            print(f\"Loaded {filename}: {len(df)} records\")\n",
    "        else:\n",
    "            print(f\"{filename} not found, skipping\")\n",
    "    \n",
    "    if all_dfs:\n",
    "        combined = pd.concat(all_dfs, ignore_index=True)\n",
    "        combined_data[base_name] = combined\n",
    "        print(f\"  ðŸ“Š Combined {base_name}: {len(combined)} total records\\n\")\n",
    "\n",
    "## Save All Combined Files\n",
    "print(\"SAVING COMBINED FILES\")\n",
    "\n",
    "for name, df in combined_data.items():\n",
    "    output_filename = f'{name}_COMBINED.csv'\n",
    "    df.to_csv(output_filename, index=False)\n",
    "    print(f\"Saved {output_filename}: {len(df)} records\")\n",
    "\n",
    "print(f\"\\nAll files combined and saved!\")\n",
    "print(f\"Total combined datasets: {len(combined_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda6081a",
   "metadata": {},
   "source": [
    "This next cell block does a quick pass to check if we have a complete dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254500da",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check for Missing Games in Combined Datasets\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "## Load Original Game IDs\n",
    "original_game_ids = pd.read_csv('unique_game_ids.csv', dtype={'GAME_ID': str})\n",
    "total_games = len(original_game_ids)\n",
    "all_game_ids = set(original_game_ids['GAME_ID'].tolist())\n",
    "\n",
    "print(f\"Total games expected: {total_games}\")\n",
    "print(f\"First game ID: {original_game_ids['GAME_ID'].iloc[0]}\")\n",
    "print(f\"Last game ID: {original_game_ids['GAME_ID'].iloc[-1]}\")\n",
    "\n",
    "\n",
    "## Track Coverage by Dataset\n",
    "coverage_report = {}\n",
    "\n",
    "\n",
    "## Check First Half Datasets\n",
    "print(\"\\nFirst Half Datasets\")\n",
    "\n",
    "fh_files = [\n",
    "    'first_half_players_COMBINED.csv',\n",
    "    'first_half_teams_COMBINED.csv',\n",
    "    'first_half_starters_bench_COMBINED.csv'\n",
    "]\n",
    "\n",
    "for filename in fh_files:\n",
    "    if os.path.exists(filename):\n",
    "        df = pd.read_csv(filename)\n",
    "        if 'GAME_ID' in df.columns:\n",
    "            unique_games = df['GAME_ID'].nunique()\n",
    "            game_ids_in_file = set(df['GAME_ID'].dropna().astype(str).unique())\n",
    "            missing_games = all_game_ids - game_ids_in_file\n",
    "            coverage_pct = (unique_games / total_games) * 100\n",
    "            \n",
    "            coverage_report[filename] = {\n",
    "                'games_found': unique_games,\n",
    "                'missing_count': len(missing_games),\n",
    "                'coverage_pct': coverage_pct,\n",
    "                'missing_ids': sorted(missing_games)\n",
    "            }\n",
    "            \n",
    "            print(f\"  {filename}:\")\n",
    "            print(f\"    Games found: {unique_games}/{total_games} ({coverage_pct:.1f}%)\")\n",
    "            print(f\"    Missing: {len(missing_games)}\")\n",
    "        else:\n",
    "            print(f\"{filename}: No GAME_ID column found\")\n",
    "    else:\n",
    "        print(f\"{filename} not found\")\n",
    "\n",
    "\n",
    "## Check Complete Game Datasets\n",
    "print(\"\\nComplete Game Datasets\")\n",
    "\n",
    "cg_files = [\n",
    "    'complete_game_players_COMBINED.csv',\n",
    "    'complete_game_teams_COMBINED.csv',\n",
    "    'complete_game_starters_bench_COMBINED.csv'\n",
    "]\n",
    "\n",
    "for filename in cg_files:\n",
    "    if os.path.exists(filename):\n",
    "        df = pd.read_csv(filename)\n",
    "        if 'GAME_ID' in df.columns:\n",
    "            unique_games = df['GAME_ID'].nunique()\n",
    "            game_ids_in_file = set(df['GAME_ID'].dropna().astype(str).unique())\n",
    "            missing_games = all_game_ids - game_ids_in_file\n",
    "            coverage_pct = (unique_games / total_games) * 100\n",
    "            \n",
    "            coverage_report[filename] = {\n",
    "                'games_found': unique_games,\n",
    "                'missing_count': len(missing_games),\n",
    "                'coverage_pct': coverage_pct,\n",
    "                'missing_ids': sorted(missing_games)\n",
    "            }\n",
    "            \n",
    "            print(f\"{filename}:\")\n",
    "            print(f\"Games found: {unique_games}/{total_games} ({coverage_pct:.1f}%)\")\n",
    "            print(f\"Missing: {len(missing_games)}\")\n",
    "        else:\n",
    "            print(f\"{filename}: No GAME_ID column found\")\n",
    "    else:\n",
    "        print(f\"{filename} not found\")\n",
    "\n",
    "\n",
    "## Check Box Score Summary Datasets\n",
    "print(\"\\nBox Score Summary Datasets\")\n",
    "\n",
    "bss_files = [\n",
    "    'game_summary_COMBINED.csv',\n",
    "    'team_stats_COMBINED.csv',\n",
    "    'refs_COMBINED.csv',\n",
    "    'inactive_players_COMBINED.csv',\n",
    "    'game_info_COMBINED.csv',\n",
    "    'points_by_quarter_COMBINED.csv',\n",
    "    'last_meeting_COMBINED.csv'\n",
    "]\n",
    "\n",
    "for filename in bss_files:\n",
    "    if os.path.exists(filename):\n",
    "        df = pd.read_csv(filename)\n",
    "        if 'GAME_ID' in df.columns:\n",
    "            unique_games = df['GAME_ID'].nunique()\n",
    "            game_ids_in_file = set(df['GAME_ID'].dropna().astype(str).unique())\n",
    "            missing_games = all_game_ids - game_ids_in_file\n",
    "            coverage_pct = (unique_games / total_games) * 100\n",
    "            \n",
    "            coverage_report[filename] = {\n",
    "                'games_found': unique_games,\n",
    "                'missing_count': len(missing_games),\n",
    "                'coverage_pct': coverage_pct,\n",
    "                'missing_ids': sorted(missing_games)\n",
    "            }\n",
    "            \n",
    "            print(f\"{filename}:\")\n",
    "            print(f\"Games found: {unique_games}/{total_games} ({coverage_pct:.1f}%)\")\n",
    "            print(f\"Missing: {len(missing_games)}\")\n",
    "        else:\n",
    "            print(f\"{filename}: No GAME_ID column found\")\n",
    "    else:\n",
    "        print(f\"{filename} not found\")\n",
    "\n",
    "\n",
    "## Summary Report\n",
    "print(\"\\nSummary\")\n",
    "print(f\"Total expected games: {total_games}\")\n",
    "\n",
    "if coverage_report:\n",
    "    best_coverage = max(coverage_report.items(), key=lambda x: x[1]['coverage_pct'])\n",
    "    worst_coverage = min(coverage_report.items(), key=lambda x: x[1]['coverage_pct'])\n",
    "    \n",
    "    print(f\"\\nBest coverage: {best_coverage[0]}\")\n",
    "    print(f\"  {best_coverage[1]['games_found']}/{total_games} ({best_coverage[1]['coverage_pct']:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nWorst coverage: {worst_coverage[0]}\")\n",
    "    print(f\"  {worst_coverage[1]['games_found']}/{total_games} ({worst_coverage[1]['coverage_pct']:.1f}%)\")\n",
    "    \n",
    "    # Find games missing from all datasets\n",
    "    all_missing = set.intersection(*[set(v['missing_ids']) for v in coverage_report.values()])\n",
    "    \n",
    "    if all_missing:\n",
    "        print(f\"\\nGames missing from ALL datasets: {len(all_missing)}\")\n",
    "        print(f\"Sample missing IDs: {list(all_missing)[:10]}\")\n",
    "        \n",
    "        # Save to CSV\n",
    "        missing_df = pd.DataFrame({'GAME_ID': sorted(all_missing)})\n",
    "        missing_df.to_csv('games_missing_from_all_datasets.csv', index=False)\n",
    "        print(f\" Saved to 'games_missing_from_all_datasets.csv'\")\n",
    "    else:\n",
    "        print(f\"\\nNo games are missing from ALL datasets!\")\n",
    "        print(\"(Some datasets may have missing games, but coverage varies)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b368816b",
   "metadata": {},
   "source": [
    "Upon inspecting that data we had thoughts about pulling more specific player information but this was incredibly cumbersome with the API since we would have to make individual pulls on each PLAYER_ID. In thinking about it more it did not make sense to go through the trouble since we want the model to generalize well since we're using an old dataset and players move teams, players retire, and new players arrive.\n",
    "\n",
    "The next cell block is for feature engineering. It is a bit of a mess and desperately needs to be refactored. We added more code snippets to add more features to the datasets. The need for more opponent features created another nested loop which felt easier at the time but simply kept growing it would have been better to replace it with a function. Also the dataset got to be over 1,000 columns and I added some redundant columns because I forgot which ones were already there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486e4672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Configuration\n",
    "time_windows = [7, 14, 30] # 1 week, 2 week, and 1 month rolling snapshots\n",
    "player_groups = [1, 2, 3, 4, 5, 6, 7, 'rest'] #top 7 of the rotation averages and lump sum for rest of team\n",
    "\n",
    "# Stats to average\n",
    "player_stats_avg = ['PTS', 'FGM', 'FGA', 'FG3M', 'FG3A', 'FTM', 'FTA',\n",
    "                    'OREB', 'DREB', 'REB', 'AST', 'STL', 'BLK', 'TO', 'PF', 'PLUS_MINUS']\n",
    "player_stats_total = ['MIN']\n",
    "\n",
    "# Team Complete Game\n",
    "team_stats_avg_cg = ['PTS', 'FGM', 'FGA', 'FG3M', 'FG3A', 'FTM', 'FTA',\n",
    "                    'OREB', 'DREB', 'REB', 'AST', 'STL', 'BLK', 'TO', 'PF', 'PLUS_MINUS']\n",
    "team_stats_total_cg = ['MIN']\n",
    "\n",
    "# Team First Half\n",
    "team_stats_avg_fh = ['PTS', 'FGM', 'FGA', 'FG3M', 'FG3A', 'FTM', 'FTA',\n",
    "                    'OREB', 'DREB', 'REB', 'AST', 'STL', 'BLK', 'TO', 'PF', 'PLUS_MINUS']\n",
    "team_stats_total_fh = ['MIN']\n",
    "\n",
    "# Load our data\n",
    "cg_players = pd.read_csv('complete_game_players_COMBINED.csv')\n",
    "cg_teams = pd.read_csv('complete_game_teams_COMBINED.csv')\n",
    "fh_players = pd.read_csv('first_half_players_COMBINED.csv')\n",
    "fh_teams = pd.read_csv('first_half_teams_COMBINED.csv')\n",
    "games_master = pd.read_csv('nba_games_2021_to_2024.csv')\n",
    "game_summary = pd.read_csv('game_summary_COMBINED.csv')\n",
    "refs = pd.read_csv('refs_COMBINED.csv')\n",
    "last_meeting = pd.read_csv('last_meeting_COMBINED.csv')\n",
    "\n",
    "# Cast numeric for the above\n",
    "for col in player_stats_avg + player_stats_total:\n",
    "    if col in cg_players.columns:\n",
    "        cg_players[col] = pd.to_numeric(cg_players[col], errors='coerce')\n",
    "        fh_players[col] = pd.to_numeric(fh_players[col], errors='coerce')\n",
    "\n",
    "for col in team_stats_avg + team_stats_total:\n",
    "    if col in cg_teams.columns:\n",
    "        cg_teams[col] = pd.to_numeric(cg_teams[col], errors='coerce')\n",
    "        fh_teams[col] = pd.to_numeric(fh_teams[col], errors='coerce')\n",
    "\n",
    "# Format Dates\n",
    "games_master['GAME_DATE'] = pd.to_datetime(games_master['GAME_DATE'])\n",
    "last_meeting['LAST_GAME_DATE_EST'] = pd.to_datetime(last_meeting['LAST_GAME_DATE_EST'], errors='coerce')\n",
    "\n",
    "\n",
    "# Creating an index with unique game_id and date\n",
    "game_date_map = games_master[['GAME_ID', 'GAME_DATE']].drop_duplicates('GAME_ID').set_index('GAME_ID')['GAME_DATE']\n",
    "\n",
    "# Apply it\n",
    "for df in [cg_players, fh_players, cg_teams, fh_teams]:\n",
    "    df['GAME_DATE'] = df['GAME_ID'].map(game_date_map)\n",
    "\n",
    "## Computing Second-Half Stats since we pulled first half and complete game\n",
    "# Merge Key\n",
    "cg_teams['merge_key'] = cg_teams['GAME_ID'].astype(str) + '_' + cg_teams['TEAM_ID'].astype(str)\n",
    "fh_teams['merge_key'] = fh_teams['GAME_ID'].astype(str) + '_' + fh_teams['TEAM_ID'].astype(str)\n",
    "\n",
    "# Merge Alignment\n",
    "merged = cg_teams.merge(\n",
    "    fh_teams[['merge_key', 'PTS', 'FGM', 'FGA', 'FG3M', 'FG3A', 'FTM', 'FTA', 'REB', 'AST', 'TO', 'STL', 'BLK']], \n",
    "    on='merge_key', \n",
    "    how='left',\n",
    "    suffixes=('', '_fh')\n",
    ")\n",
    "\n",
    "# Second-half stats to compute\n",
    "second_half_stats = ['PTS', 'FGM', 'FGA', 'FG3M', 'FG3A', 'FTM', 'FTA', 'REB', 'AST', 'TO', 'STL', 'BLK']\n",
    "\n",
    "# Quick diff for counting stats\n",
    "for stat in second_half_stats:\n",
    "    cg_teams[f'second_half_{stat}'] = merged[stat] - merged[f'{stat}_fh']\n",
    "\n",
    "# Calculate percentage stats\n",
    "cg_teams['second_half_FG_PCT'] = np.where(\n",
    "    cg_teams['second_half_FGA'] > 0,\n",
    "    cg_teams['second_half_FGM'] / cg_teams['second_half_FGA'],\n",
    "    np.nan\n",
    ")\n",
    "cg_teams['second_half_FG3_PCT'] = np.where(\n",
    "    cg_teams['second_half_FG3A'] > 0,\n",
    "    cg_teams['second_half_FG3M'] / cg_teams['second_half_FG3A'],\n",
    "    np.nan\n",
    ")\n",
    "cg_teams['second_half_FT_PCT'] = np.where(\n",
    "    cg_teams['second_half_FTA'] > 0,\n",
    "    cg_teams['second_half_FTM'] / cg_teams['second_half_FTA'],\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "# Kill merge key since its unnessary now\n",
    "cg_teams.drop('merge_key', axis=1, inplace=True)\n",
    "fh_teams.drop('merge_key', axis=1, inplace=True)\n",
    "\n",
    "# Add it to the stats list\n",
    "team_stats_avg_cg.extend([f'second_half_{stat}' for stat in second_half_stats])\n",
    "team_stats_avg_cg.extend(['second_half_FG_PCT', 'second_half_FG3_PCT', 'second_half_FT_PCT'])\n",
    "\n",
    "## Players\n",
    "# Lasso stats into time windows\n",
    "def calculate_player_time_features(player_df, game_id, game_date, player_id, team_id, days):\n",
    "    window_start = game_date - pd.Timedelta(days=days)\n",
    "    \n",
    "    player_games = player_df[\n",
    "        (player_df['PLAYER_ID'] == player_id) &\n",
    "        (player_df['TEAM_ID'] == team_id) &\n",
    "        (player_df['GAME_DATE'] >= window_start) &\n",
    "        (player_df['GAME_DATE'] < game_date) &\n",
    "        (player_df['GAME_ID'] != game_id)\n",
    "    ].copy()\n",
    "    \n",
    "    # Excludes inactivity\n",
    "    if len(player_games) == 0:\n",
    "        base_features = {stat: np.nan for stat in player_stats_total + player_stats_avg}\n",
    "        base_features['FG_PCT'] = np.nan\n",
    "        base_features['FG3_PCT'] = np.nan\n",
    "        base_features['FT_PCT'] = np.nan\n",
    "        return base_features\n",
    "    \n",
    "    features = {}\n",
    "    \n",
    "    # Sum counting stats for percentages later\n",
    "    for stat in player_stats_total:\n",
    "        features[stat] = player_games[stat].sum()\n",
    "        \n",
    "    # Averages for features\n",
    "    for stat in player_stats_avg:\n",
    "        features[stat] = player_games[stat].mean()\n",
    "    \n",
    "    # Calculate percentages from underlying counting stats instead of averaging percentages\n",
    "    total_fgm = player_games['FGM'].sum()\n",
    "    total_fga = player_games['FGA'].sum()\n",
    "    total_fg3m = player_games['FG3M'].sum()\n",
    "    total_fg3a = player_games['FG3A'].sum()\n",
    "    total_ftm = player_games['FTM'].sum()\n",
    "    total_fta = player_games['FTA'].sum()\n",
    "    \n",
    "    features['FG_PCT'] = total_fgm / total_fga if total_fga > 0 else np.nan\n",
    "    features['FG3_PCT'] = total_fg3m / total_fg3a if total_fg3a > 0 else np.nan\n",
    "    features['FT_PCT'] = total_ftm / total_fta if total_fta > 0 else np.nan\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Ranking our top players, which is done on a 30 day basis\n",
    "# 30 day basis will show dropoffs of top players.\n",
    "def get_team_top_players(player_df, game_id, game_date, team_id):\n",
    "    window_start = game_date - pd.Timedelta(days=30)\n",
    "    \n",
    "    team_players = player_df[\n",
    "        (player_df['TEAM_ID'] == team_id) &\n",
    "        (player_df['GAME_DATE'] >= window_start) &\n",
    "        (player_df['GAME_DATE'] < game_date) &\n",
    "        (player_df['GAME_ID'] != game_id)\n",
    "    ].copy()\n",
    "    \n",
    "    # Excludes inactivity\n",
    "    if len(team_players) == 0:\n",
    "        return []\n",
    "    \n",
    "    player_minutes = team_players.groupby('PLAYER_ID')['MIN'].sum().sort_values(ascending=False)\n",
    "    return player_minutes.index.tolist()\n",
    "\n",
    "## Teamwide\n",
    "# Lasso stats into time windows\n",
    "def calculate_team_time_features(team_df, game_id, game_date, team_id, days, stats_avg, stats_total):\n",
    "    window_start = game_date - pd.Timedelta(days=days)\n",
    "    \n",
    "    team_games = team_df[\n",
    "        (team_df['TEAM_ID'] == team_id) &\n",
    "        (team_df['GAME_DATE'] >= window_start) &\n",
    "        (team_df['GAME_DATE'] < game_date) &\n",
    "        (team_df['GAME_ID'] != game_id)\n",
    "    ].copy()\n",
    "    \n",
    "    if len(team_games) == 0:\n",
    "        base_features = {stat: np.nan for stat in stats_total + stats_avg}  # Changed\n",
    "        base_features['FG_PCT'] = np.nan\n",
    "        base_features['FG3_PCT'] = np.nan\n",
    "        base_features['FT_PCT'] = np.nan\n",
    "        base_features['WIN_PCT'] = np.nan\n",
    "        return base_features\n",
    "    \n",
    "    features = {}\n",
    "    \n",
    "    # Sum totals\n",
    "    for stat in stats_total:  # Changed\n",
    "        features[stat] = team_games[stat].sum()\n",
    "    \n",
    "    # Average the averages (including second-half stats for CG only)\n",
    "    for stat in stats_avg:  # Changed\n",
    "        features[stat] = team_games[stat].mean()\n",
    "    \n",
    "    # Calculate TRUE percentages from summed makes/attempts\n",
    "    total_fgm = team_games['FGM'].sum()\n",
    "    total_fga = team_games['FGA'].sum()\n",
    "    total_fg3m = team_games['FG3M'].sum()\n",
    "    total_fg3a = team_games['FG3A'].sum()\n",
    "    total_ftm = team_games['FTM'].sum()\n",
    "    total_fta = team_games['FTA'].sum()\n",
    "    \n",
    "    features['FG_PCT'] = total_fgm / total_fga if total_fga > 0 else np.nan\n",
    "    features['FG3_PCT'] = total_fg3m / total_fg3a if total_fg3a > 0 else np.nan\n",
    "    features['FT_PCT'] = total_ftm / total_fta if total_fta > 0 else np.nan\n",
    "    \n",
    "    # Win percentage\n",
    "    team_game_ids = team_games['GAME_ID'].unique()\n",
    "    team_game_results = games_master[\n",
    "        (games_master['GAME_ID'].isin(team_game_ids)) &\n",
    "        (games_master['TEAM_ID'] == team_id)\n",
    "    ]\n",
    "    if len(team_game_results) > 0:\n",
    "        features['WIN_PCT'] = (team_game_results['WL'] == 'W').mean()\n",
    "    else:\n",
    "        features['WIN_PCT'] = np.nan\n",
    "    \n",
    "    return features\n",
    "\n",
    "## Functions for Schedule\n",
    "# Rest days, back-to-back games, and some general game density\n",
    "def calculate_schedule_features(games_master, game_id, game_date, team_id):\n",
    "    team_games = games_master[\n",
    "        (games_master['TEAM_ID'] == team_id) &\n",
    "        (games_master['GAME_DATE'] < game_date)\n",
    "    ].sort_values('GAME_DATE')\n",
    "    \n",
    "    features = {}\n",
    "    \n",
    "    if len(team_games) == 0:\n",
    "        features['days_since_last_game'] = np.nan\n",
    "        features['is_back_to_back'] = 0\n",
    "        features['games_in_last_3_days'] = 0\n",
    "        features['games_in_last_5_days'] = 0\n",
    "        features['games_in_last_7_days'] = 0\n",
    "    else:\n",
    "        # Here we compute last game and back to backs\n",
    "        last_game_date = team_games['GAME_DATE'].iloc[-1]\n",
    "        features['days_since_last_game'] = (game_date - last_game_date).days\n",
    "        features['is_back_to_back'] = 1 if features['days_since_last_game'] == 1 else 0\n",
    "        \n",
    "        # Game density\n",
    "        recent_games_3d = team_games[team_games['GAME_DATE'] >= game_date - pd.Timedelta(days=3)]\n",
    "        recent_games_5d = team_games[team_games['GAME_DATE'] >= game_date - pd.Timedelta(days=5)]\n",
    "        recent_games_7d = team_games[team_games['GAME_DATE'] >= game_date - pd.Timedelta(days=7)]\n",
    "        \n",
    "        features['games_in_last_3_days'] = len(recent_games_3d)\n",
    "        features['games_in_last_5_days'] = len(recent_games_5d)\n",
    "        features['games_in_last_7_days'] = len(recent_games_7d)\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Lets get home and road game lengths (streaks of home or away)\n",
    "def calculate_home_road_context(games_master, game_id, game_date, team_id):\n",
    "    team_games = games_master[\n",
    "        (games_master['TEAM_ID'] == team_id) &\n",
    "        (games_master['GAME_DATE'] < game_date)\n",
    "    ].sort_values('GAME_DATE')\n",
    "    \n",
    "    features = {}\n",
    "    \n",
    "    # Determine if current game is home\n",
    "    current_game = games_master[(games_master['GAME_ID'] == game_id) & (games_master['TEAM_ID'] == team_id)]\n",
    "    if len(current_game) > 0:\n",
    "        matchup = current_game['MATCHUP'].iloc[0]\n",
    "        features['is_home_game'] = 1 if 'vs.' in str(matchup) else 0 # vs and @ determined home vs away\n",
    "    else:\n",
    "        features['is_home_game'] = np.nan\n",
    "    \n",
    "    if len(team_games) == 0:\n",
    "        # First game of season - count as game #1\n",
    "        features['home_stand_game_number'] = 1 if features['is_home_game'] == 1 else 0\n",
    "        features['road_trip_game_number'] = 1 if features['is_home_game'] == 0 else 0\n",
    "        return features\n",
    "    \n",
    "    # Count consecutive home or road games (BEFORE current game)\n",
    "    consecutive_count = 0\n",
    "    \n",
    "    for _, game in team_games.iloc[::-1].iterrows():\n",
    "        matchup = str(game['MATCHUP'])\n",
    "        is_home = 1 if 'vs.' in matchup else 0\n",
    "        \n",
    "        # Check if this past game matches current game's location\n",
    "        if features['is_home_game'] == is_home:\n",
    "            consecutive_count += 1\n",
    "        else:\n",
    "            break  # Different arena, stop counting\n",
    "    \n",
    "    # Add 1 to include the CURRENT game\n",
    "    features['home_stand_game_number'] = consecutive_count + 1 if features['is_home_game'] == 1 else 0\n",
    "    features['road_trip_game_number'] = consecutive_count + 1 if features['is_home_game'] == 0 else 0\n",
    "    \n",
    "    return features\n",
    "\n",
    "## Record Features\n",
    "# Win and Loss streaks\n",
    "def calculate_streak_features(games_master, game_id, game_date, team_id, lookback_games=[3, 5, 10]):\n",
    "    team_games = games_master[\n",
    "        (games_master['TEAM_ID'] == team_id) &\n",
    "        (games_master['GAME_DATE'] < game_date)\n",
    "    ].sort_values('GAME_DATE')\n",
    "    \n",
    "    features = {}\n",
    "    \n",
    "    if len(team_games) == 0:\n",
    "        features['current_streak'] = 0\n",
    "        for n in lookback_games:\n",
    "            features[f'wins_last_{n}'] = np.nan\n",
    "        features['home_win_pct_last_10'] = np.nan\n",
    "        features['road_win_pct_last_10'] = np.nan\n",
    "        return features\n",
    "    \n",
    "    # Current streak (positive = wins, negative = losses)\n",
    "    recent_results = team_games['WL'].iloc[::-1].values\n",
    "    current_result = recent_results[0] if len(recent_results) > 0 else None\n",
    "    streak = 0\n",
    "    \n",
    "    for result in recent_results:\n",
    "        if result == current_result:\n",
    "            streak += 1\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    features['current_streak'] = streak if current_result == 'W' else -streak\n",
    "    \n",
    "    # Wins in last N games\n",
    "    for n in lookback_games:\n",
    "        last_n = team_games.tail(n)\n",
    "        if len(last_n) > 0:\n",
    "            features[f'wins_last_{n}'] = (last_n['WL'] == 'W').sum()\n",
    "        else:\n",
    "            features[f'wins_last_{n}'] = np.nan\n",
    "    \n",
    "    # Home/Road splits\n",
    "    last_10 = team_games.tail(10)\n",
    "    home_games = last_10[last_10['MATCHUP'].str.contains('vs.', na=False)]\n",
    "    road_games = last_10[last_10['MATCHUP'].str.contains('@', na=False)]\n",
    "    \n",
    "    features['home_win_pct_last_10'] = (home_games['WL'] == 'W').mean() if len(home_games) > 0 else np.nan\n",
    "    features['road_win_pct_last_10'] = (road_games['WL'] == 'W').mean() if len(road_games) > 0 else np.nan\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Head to head record calculations (Team matched against their Opponent)\n",
    "def calculate_head_to_head_features(games_master, last_meeting, game_id, game_date, team_id):\n",
    "    features = {}\n",
    "    \n",
    "    # Get opponent team_id for this game\n",
    "    game_teams = games_master[games_master['GAME_ID'] == game_id]['TEAM_ID'].unique()\n",
    "    opponent_id = [t for t in game_teams if t != team_id]\n",
    "    \n",
    "    if len(opponent_id) == 0:\n",
    "        features['days_since_last_matchup'] = np.nan\n",
    "        features['won_last_matchup'] = np.nan\n",
    "        features['point_diff_last_matchup'] = np.nan\n",
    "        features['season_record_vs_opponent'] = np.nan\n",
    "        return features\n",
    "    \n",
    "    opponent_id = opponent_id[0]\n",
    "    \n",
    "    # Last meeting info\n",
    "    last_mtg = last_meeting[last_meeting['GAME_ID'] == game_id]\n",
    "    if len(last_mtg) > 0 and pd.notna(last_mtg['LAST_GAME_DATE_EST'].iloc[0]):\n",
    "        last_game_date = last_mtg['LAST_GAME_DATE_EST'].iloc[0]\n",
    "        features['days_since_last_matchup'] = (game_date - last_game_date).days\n",
    "        \n",
    "        # Determine who won\n",
    "        home_pts = last_mtg['LAST_GAME_HOME_TEAM_POINTS'].iloc[0]\n",
    "        visitor_pts = last_mtg['LAST_GAME_VISITOR_TEAM_POINTS'].iloc[0]\n",
    "        home_team = last_mtg['LAST_GAME_HOME_TEAM_ID'].iloc[0]\n",
    "        \n",
    "        if home_team == team_id:\n",
    "            features['won_last_matchup'] = 1 if home_pts > visitor_pts else 0\n",
    "            features['point_diff_last_matchup'] = home_pts - visitor_pts\n",
    "        else:\n",
    "            features['won_last_matchup'] = 1 if visitor_pts > home_pts else 0\n",
    "            features['point_diff_last_matchup'] = visitor_pts - home_pts\n",
    "    else:\n",
    "        features['days_since_last_matchup'] = np.nan\n",
    "        features['won_last_matchup'] = np.nan\n",
    "        features['point_diff_last_matchup'] = np.nan\n",
    "    \n",
    "    # Season record vs opponent\n",
    "    season_games = games_master[\n",
    "        (games_master['TEAM_ID'] == team_id) &\n",
    "        (games_master['GAME_DATE'] < game_date)\n",
    "    ]\n",
    "    \n",
    "    # Find games against this opponent\n",
    "    opponent_game_ids = games_master[\n",
    "        (games_master['TEAM_ID'] == opponent_id)\n",
    "    ]['GAME_ID'].unique()\n",
    "    \n",
    "    matchup_games = season_games[season_games['GAME_ID'].isin(opponent_game_ids)]\n",
    "    \n",
    "    if len(matchup_games) > 0:\n",
    "        features['season_record_vs_opponent'] = (matchup_games['WL'] == 'W').sum()\n",
    "    else:\n",
    "        features['season_record_vs_opponent'] = 0\n",
    "    \n",
    "    return features\n",
    "\n",
    "## Referee Features -- basically a join\n",
    "def get_referee_ids(refs, game_id):\n",
    "    game_refs = refs[refs['GAME_ID'] == game_id].sort_values('JERSEY_NUM')\n",
    "    \n",
    "    ref_ids = [np.nan, np.nan, np.nan]\n",
    "    for i, (_, ref) in enumerate(game_refs.iterrows()):\n",
    "        if i < 3:\n",
    "            ref_ids[i] = ref['OFFICIAL_ID']\n",
    "    \n",
    "    return {\n",
    "        'ref_1_id': ref_ids[0],\n",
    "        'ref_2_id': ref_ids[1],\n",
    "        'ref_3_id': ref_ids[2]\n",
    "    }\n",
    "\n",
    "## Opponent features -- this is calculating features for the opponent\n",
    "def get_opponent_id(games_master, game_id, team_id):\n",
    "    \"\"\"Get the opponent team ID for this game\"\"\"\n",
    "    game_teams = games_master[games_master['GAME_ID'] == game_id]['TEAM_ID'].unique()\n",
    "    opponent_ids = [t for t in game_teams if t != team_id]\n",
    "    return opponent_ids[0] if len(opponent_ids) > 0 else None\n",
    "\n",
    "# Unique filter to make sure we are not counting duplicates\n",
    "unique_games = games_master[['GAME_ID', 'GAME_DATE', 'TEAM_ID']].drop_duplicates()\n",
    "unique_games = unique_games.sort_values('GAME_DATE')\n",
    "\n",
    "# Index Reset\n",
    "unique_games = unique_games.reset_index(drop=True)\n",
    "\n",
    "# Preparing to run it\n",
    "all_features = []\n",
    "\n",
    "# Looping over all games\n",
    "for idx, row in unique_games.iterrows():    \n",
    "    if idx % 500 == 0:\n",
    "        print(f\"Progress: {idx}/{len(unique_games)}\")\n",
    "    \n",
    "    game_id = row['GAME_ID']\n",
    "    game_date = row['GAME_DATE']\n",
    "    team_id = row['TEAM_ID']\n",
    "    \n",
    "    game_features = {\n",
    "        'GAME_ID': game_id,\n",
    "        'GAME_DATE': game_date,\n",
    "        'TEAM_ID': team_id\n",
    "    }\n",
    "    \n",
    "    # Player features\n",
    "    top_players_cg = get_team_top_players(cg_players, game_id, game_date, team_id)\n",
    "    top_players_fh = get_team_top_players(fh_players, game_id, game_date, team_id)\n",
    "    \n",
    "    for days in time_windows:\n",
    "        # Complete game players\n",
    "        for n in player_groups:\n",
    "            if n == 'rest':\n",
    "                players = top_players_cg[7:] if len(top_players_cg) > 7 else []\n",
    "            else:\n",
    "                players = top_players_cg[:n] if len(top_players_cg) >= n else []\n",
    "            \n",
    "            if len(players) == 0:\n",
    "                for stat in player_stats_total + player_stats_avg + ['FG_PCT', 'FG3_PCT', 'FT_PCT']:\n",
    "                    game_features[f'top{n}_cg_{stat.lower()}_{days}d'] = np.nan\n",
    "                continue\n",
    "            \n",
    "            player_features_list = [\n",
    "                calculate_player_time_features(cg_players, game_id, game_date, p, team_id, days)\n",
    "                for p in players\n",
    "            ]\n",
    "            \n",
    "            for stat in player_stats_total + player_stats_avg + ['FG_PCT', 'FG3_PCT', 'FT_PCT']:\n",
    "                values = [pf[stat] for pf in player_features_list if not pd.isna(pf[stat])]\n",
    "                game_features[f'top{n}_cg_{stat.lower()}_{days}d'] = np.mean(values) if values else np.nan\n",
    "        \n",
    "        # First half players\n",
    "        for n in player_groups:\n",
    "            if n == 'rest':\n",
    "                players = top_players_fh[7:] if len(top_players_fh) > 7 else []\n",
    "            else:\n",
    "                players = top_players_fh[:n] if len(top_players_fh) >= n else []\n",
    "            \n",
    "            if len(players) == 0:\n",
    "                for stat in player_stats_total + player_stats_avg + ['FG_PCT', 'FG3_PCT', 'FT_PCT']:\n",
    "                    game_features[f'top{n}_fh_{stat.lower()}_{days}d'] = np.nan\n",
    "                continue\n",
    "            \n",
    "            player_features_list = [\n",
    "                calculate_player_time_features(fh_players, game_id, game_date, p, team_id, days)\n",
    "                for p in players\n",
    "            ]\n",
    "            \n",
    "            for stat in player_stats_total + player_stats_avg + ['FG_PCT', 'FG3_PCT', 'FT_PCT']:\n",
    "                values = [pf[stat] for pf in player_features_list if not pd.isna(pf[stat])]\n",
    "                game_features[f'top{n}_fh_{stat.lower()}_{days}d'] = np.mean(values) if values else np.nan\n",
    "    \n",
    "    # Team features\n",
    "    for days in time_windows:\n",
    "    # Complete game with second-half stats\n",
    "        team_cg = calculate_team_time_features(cg_teams, game_id, game_date, team_id, days, \n",
    "                                                team_stats_avg_cg, team_stats_total_cg)\n",
    "        for stat, value in team_cg.items():\n",
    "            game_features[f'team_cg_{stat.lower()}_{days}d'] = value\n",
    "        \n",
    "        # First half WITHOUT second-half stats\n",
    "        team_fh = calculate_team_time_features(fh_teams, game_id, game_date, team_id, days,\n",
    "                                                team_stats_avg_fh, team_stats_total_fh)\n",
    "        for stat, value in team_fh.items():\n",
    "            game_features[f'team_fh_{stat.lower()}_{days}d'] = value\n",
    "    \n",
    "    # Schedule and Record Featurres\n",
    "    schedule_feats = calculate_schedule_features(games_master, game_id, game_date, team_id)\n",
    "    game_features.update(schedule_feats)\n",
    "    \n",
    "    home_road_feats = calculate_home_road_context(games_master, game_id, game_date, team_id)\n",
    "    game_features.update(home_road_feats)\n",
    "    \n",
    "    streak_feats = calculate_streak_features(games_master, game_id, game_date, team_id)\n",
    "    game_features.update(streak_feats)\n",
    "    \n",
    "    h2h_feats = calculate_head_to_head_features(games_master, last_meeting, game_id, game_date, team_id)\n",
    "    game_features.update(h2h_feats)\n",
    "    \n",
    "    # Ref features\n",
    "    ref_feats = get_referee_ids(refs, game_id)\n",
    "    game_features.update(ref_feats)\n",
    "    \n",
    "    # Current Game Stats columns\n",
    "    current_game_fh = fh_teams[\n",
    "        (fh_teams['GAME_ID'] == game_id) & \n",
    "        (fh_teams['TEAM_ID'] == team_id)\n",
    "    ]\n",
    "    \n",
    "    if len(current_game_fh) > 0:\n",
    "        game_features['current_fh_pts'] = current_game_fh['PTS'].iloc[0]\n",
    "        game_features['current_fh_fgm'] = current_game_fh['FGM'].iloc[0]\n",
    "        game_features['current_fh_fga'] = current_game_fh['FGA'].iloc[0]\n",
    "        game_features['current_fh_fg3m'] = current_game_fh['FG3M'].iloc[0]\n",
    "        game_features['current_fh_fg3a'] = current_game_fh['FG3A'].iloc[0]\n",
    "        game_features['current_fh_ftm'] = current_game_fh['FTM'].iloc[0]\n",
    "        game_features['current_fh_fta'] = current_game_fh['FTA'].iloc[0]\n",
    "        game_features['current_fh_reb'] = current_game_fh['REB'].iloc[0]\n",
    "        game_features['current_fh_ast'] = current_game_fh['AST'].iloc[0]\n",
    "        game_features['current_fh_to'] = current_game_fh['TO'].iloc[0]\n",
    "        game_features['current_fh_stl'] = current_game_fh['STL'].iloc[0]\n",
    "        game_features['current_fh_blk'] = current_game_fh['BLK'].iloc[0]\n",
    "        game_features['current_fh_pf'] = current_game_fh['PF'].iloc[0]\n",
    "        \n",
    "        # Calculate percentages and pace\n",
    "        fga = current_game_fh['FGA'].iloc[0]\n",
    "        fg3a = current_game_fh['FG3A'].iloc[0]\n",
    "        fta = current_game_fh['FTA'].iloc[0]\n",
    "        \n",
    "        game_features['current_fh_fg_pct'] = current_game_fh['FGM'].iloc[0] / fga if fga > 0 else np.nan\n",
    "        game_features['current_fh_fg3_pct'] = current_game_fh['FG3M'].iloc[0] / fg3a if fg3a > 0 else np.nan\n",
    "        game_features['current_fh_ft_pct'] = current_game_fh['FTM'].iloc[0] / fta if fta > 0 else np.nan\n",
    "        game_features['current_fh_pace'] = fga + current_game_fh['TO'].iloc[0]\n",
    "    else:\n",
    "        fh_stats = ['pts', 'fgm', 'fga', 'fg3m', 'fg3a', 'ftm', 'fta', 'reb', 'ast', 'to', \n",
    "                    'stl', 'blk', 'pf', 'fg_pct', 'fg3_pct', 'ft_pct', 'pace']\n",
    "        for stat in fh_stats:\n",
    "            game_features[f'current_fh_{stat}'] = np.nan\n",
    "\n",
    "    ## Opponnet Features\n",
    "    opponent_id = get_opponent_id(games_master, game_id, team_id)\n",
    "    \n",
    "    if opponent_id is not None:\n",
    "        # Opponent team features for each time window\n",
    "        for days in time_windows:\n",
    "            opp_team_cg = calculate_team_time_features(cg_teams, game_id, game_date, opponent_id, days,\n",
    "                                                        team_stats_avg_cg, team_stats_total_cg)\n",
    "            for stat, value in opp_team_cg.items():\n",
    "                game_features[f'opp_team_cg_{stat.lower()}_{days}d'] = value\n",
    "            \n",
    "            opp_team_fh = calculate_team_time_features(fh_teams, game_id, game_date, opponent_id, days,\n",
    "                                                        team_stats_avg_fh, team_stats_total_fh)\n",
    "            for stat, value in opp_team_fh.items():\n",
    "                game_features[f'opp_team_fh_{stat.lower()}_{days}d'] = value\n",
    "        \n",
    "        # Opponent schedule features\n",
    "        opp_schedule_feats = calculate_schedule_features(games_master, game_id, game_date, opponent_id)\n",
    "        for key, value in opp_schedule_feats.items():\n",
    "            game_features[f'opp_{key}'] = value\n",
    "        \n",
    "        # Opponent streak features\n",
    "        opp_streak_feats = calculate_streak_features(games_master, game_id, game_date, opponent_id)\n",
    "        for key, value in opp_streak_feats.items():\n",
    "            game_features[f'opp_{key}'] = value\n",
    "            \n",
    "        # Team vs Opponent Differentials\n",
    "        if not pd.isna(game_features.get('days_since_last_game')) and not pd.isna(game_features.get('opp_days_since_last_game')):\n",
    "            game_features['rest_advantage'] = game_features['days_since_last_game'] - game_features['opp_days_since_last_game']\n",
    "        else:\n",
    "            game_features['rest_advantage'] = np.nan\n",
    "        \n",
    "        # Win percentage differential\n",
    "        for days in time_windows:\n",
    "            team_win_pct = game_features.get(f'team_cg_win_pct_{days}d', np.nan)\n",
    "            opp_win_pct = game_features.get(f'opp_team_cg_win_pct_{days}d', np.nan)\n",
    "            if not pd.isna(team_win_pct) and not pd.isna(opp_win_pct):\n",
    "                game_features[f'win_pct_diff_{days}d'] = team_win_pct - opp_win_pct\n",
    "            else:\n",
    "                game_features[f'win_pct_diff_{days}d'] = np.nan\n",
    "        \n",
    "        # Recent form differential (wins in last 5)\n",
    "        team_wins_5 = game_features.get('wins_last_5', np.nan)\n",
    "        opp_wins_5 = game_features.get('opp_wins_last_5', np.nan)\n",
    "        if not pd.isna(team_wins_5) and not pd.isna(opp_wins_5):\n",
    "            game_features['recent_form_diff'] = team_wins_5 - opp_wins_5\n",
    "        else:\n",
    "            game_features['recent_form_diff'] = np.nan\n",
    "        \n",
    "        # Scoring differential\n",
    "        for days in time_windows:\n",
    "            team_pts = game_features.get(f'team_cg_pts_{days}d', np.nan)\n",
    "            opp_pts = game_features.get(f'opp_team_cg_pts_{days}d', np.nan)\n",
    "            if not pd.isna(team_pts) and not pd.isna(opp_pts):\n",
    "                game_features[f'avg_scoring_diff_{days}d'] = team_pts - opp_pts\n",
    "            else:\n",
    "                game_features[f'avg_scoring_diff_{days}d'] = np.nan\n",
    "        \n",
    "        # Opponent Current Game Columns        \n",
    "        opp_game_fh = fh_teams[\n",
    "            (fh_teams['GAME_ID'] == game_id) & \n",
    "            (fh_teams['TEAM_ID'] == opponent_id)\n",
    "        ]\n",
    "        \n",
    "        if len(opp_game_fh) > 0:\n",
    "            game_features['opp_current_fh_pts'] = opp_game_fh['PTS'].iloc[0]\n",
    "            game_features['opp_current_fh_fgm'] = opp_game_fh['FGM'].iloc[0]\n",
    "            game_features['opp_current_fh_fga'] = opp_game_fh['FGA'].iloc[0]\n",
    "            game_features['opp_current_fh_fg3m'] = opp_game_fh['FG3M'].iloc[0]\n",
    "            game_features['opp_current_fh_fg3a'] = opp_game_fh['FG3A'].iloc[0]\n",
    "            game_features['opp_current_fh_reb'] = opp_game_fh['REB'].iloc[0]\n",
    "            game_features['opp_current_fh_ast'] = opp_game_fh['AST'].iloc[0]\n",
    "            game_features['opp_current_fh_to'] = opp_game_fh['TO'].iloc[0]\n",
    "            game_features['opp_current_fh_pf'] = opp_game_fh['PF'].iloc[0]\n",
    "            \n",
    "            opp_fga = opp_game_fh['FGA'].iloc[0]\n",
    "            opp_fg3a = opp_game_fh['FG3A'].iloc[0]\n",
    "            \n",
    "            game_features['opp_current_fh_fg_pct'] = opp_game_fh['FGM'].iloc[0] / opp_fga if opp_fga > 0 else np.nan\n",
    "            game_features['opp_current_fh_fg3_pct'] = opp_game_fh['FG3M'].iloc[0] / opp_fg3a if opp_fg3a > 0 else np.nan\n",
    "            game_features['opp_current_fh_pace'] = opp_fga + opp_game_fh['TO'].iloc[0]\n",
    "        else:\n",
    "            opp_fh_stats = ['pts', 'fgm', 'fga', 'fg3m', 'fg3a', 'reb', 'ast', 'to', 'pf', \n",
    "                            'fg_pct', 'fg3_pct', 'pace']\n",
    "            for stat in opp_fh_stats:\n",
    "                game_features[f'opp_current_fh_{stat}'] = np.nan\n",
    "        \n",
    "        # Halftime Stats        \n",
    "        if len(current_game_fh) > 0 and len(opp_game_fh) > 0:\n",
    "            \n",
    "            # Totals\n",
    "            game_features['halftime_total'] = current_game_fh['PTS'].iloc[0] + opp_game_fh['PTS'].iloc[0]\n",
    "            \n",
    "            # PAce\n",
    "            team_pace = game_features.get('current_fh_pace', 0)\n",
    "            opp_pace = game_features.get('opp_current_fh_pace', 0)\n",
    "            game_features['halftime_total_pace'] = team_pace + opp_pace\n",
    "            \n",
    "            # Shooting PCTs\n",
    "            team_fg_pct = game_features.get('current_fh_fg_pct', np.nan)\n",
    "            opp_fg_pct = game_features.get('opp_current_fh_fg_pct', np.nan)\n",
    "            if not pd.isna(team_fg_pct) and not pd.isna(opp_fg_pct):\n",
    "                game_features['halftime_combined_fg_pct'] = (team_fg_pct + opp_fg_pct) / 2\n",
    "            else:\n",
    "                game_features['halftime_combined_fg_pct'] = np.nan\n",
    "            \n",
    "            # Turnovers\n",
    "            game_features['halftime_total_to'] = current_game_fh['TO'].iloc[0] + opp_game_fh['TO'].iloc[0]\n",
    "            \n",
    "            # Scoring\n",
    "            team_avg = game_features.get('team_fh_pts_7d', np.nan)\n",
    "            opp_avg = game_features.get('opp_team_fh_pts_7d', np.nan)\n",
    "            team_current = current_game_fh['PTS'].iloc[0]\n",
    "            opp_current = opp_game_fh['PTS'].iloc[0]\n",
    "            \n",
    "            if not pd.isna(team_avg) and not pd.isna(opp_avg):\n",
    "                team_var = team_current - team_avg\n",
    "                opp_var = opp_current - opp_avg\n",
    "                game_features['halftime_combined_scoring_variance'] = team_var + opp_var\n",
    "            else:\n",
    "                game_features['halftime_combined_scoring_variance'] = np.nan\n",
    "            \n",
    "            # Lead\n",
    "            game_features['halftime_lead_abs'] = abs(current_game_fh['PTS'].iloc[0] - opp_game_fh['PTS'].iloc[0])\n",
    "        \n",
    "        else:\n",
    "            game_features['halftime_total'] = np.nan\n",
    "            game_features['halftime_total_pace'] = np.nan\n",
    "            game_features['halftime_combined_fg_pct'] = np.nan\n",
    "            game_features['halftime_total_to'] = np.nan\n",
    "            game_features['halftime_combined_scoring_variance'] = np.nan\n",
    "            game_features['halftime_lead_abs'] = np.nan\n",
    "    \n",
    "    ## Getting Second Half Targets\n",
    "    current_game_cg = cg_teams[\n",
    "        (cg_teams['GAME_ID'] == game_id) & \n",
    "        (cg_teams['TEAM_ID'] == team_id)\n",
    "    ]\n",
    "    \n",
    "    # Team's second-half score\n",
    "    if len(current_game_cg) > 0 and len(current_game_fh) > 0:\n",
    "        complete_pts = current_game_cg['PTS'].iloc[0]\n",
    "        first_half_pts = current_game_fh['PTS'].iloc[0]\n",
    "        game_features['actual_second_half_pts'] = complete_pts - first_half_pts\n",
    "    else:\n",
    "        game_features['actual_second_half_pts'] = np.nan\n",
    "    \n",
    "    # Opponent's second-half score\n",
    "    if opponent_id is not None:\n",
    "        opp_game_cg = cg_teams[\n",
    "            (cg_teams['GAME_ID'] == game_id) & \n",
    "            (cg_teams['TEAM_ID'] == opponent_id)\n",
    "        ]\n",
    "        \n",
    "        if len(opp_game_cg) > 0 and len(opp_game_fh) > 0:\n",
    "            opp_complete_pts = opp_game_cg['PTS'].iloc[0]\n",
    "            opp_first_half_pts = opp_game_fh['PTS'].iloc[0]\n",
    "            opp_second_half_pts = opp_complete_pts - opp_first_half_pts\n",
    "            \n",
    "            # Both teams combined for second half (this is the target)\n",
    "            if not pd.isna(game_features['actual_second_half_pts']) and not pd.isna(opp_second_half_pts):\n",
    "                game_features['actual_second_half_total'] = game_features['actual_second_half_pts'] + opp_second_half_pts\n",
    "            else:\n",
    "                game_features['actual_second_half_total'] = np.nan\n",
    "        else:\n",
    "            game_features['actual_second_half_total'] = np.nan\n",
    "    else:\n",
    "        game_features['actual_second_half_total'] = np.nan\n",
    "\n",
    "    all_features.append(game_features)\n",
    "    \n",
    "## Create Final Dataframe\n",
    "features_df = pd.DataFrame(all_features)\n",
    "print(f\"\\nFeature engineering complete!\")\n",
    "print(f\"Total features: {len(features_df.columns)}\")\n",
    "print(f\"Total games: {len(features_df)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccbddbe",
   "metadata": {},
   "source": [
    "Used this to inspect the dataset and then also write the dataset. They're split as a relic of testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd66b2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inspect and Save Features Dataset\n",
    "features_df.head()\n",
    "features_df.to_csv('nba_time_based_features.csv', index=False)\n",
    "print(\"Saved to 'nba_time_based_features.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2263bf",
   "metadata": {},
   "source": [
    "Next cell is using a mapping table to try and create a key based on the team and the date so we can join it to our NBA dataset. There were a number of games missing and a big bulk of those is because we only have half of the 2023 season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930364f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Mapping Table for Betting Lines\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## Load Data\n",
    "betting_data = pd.read_csv('betting_data.csv')\n",
    "games_master = pd.read_csv('nba_games_2021_to_2024.csv')\n",
    "\n",
    "# Format dates\n",
    "betting_data['date'] = pd.to_datetime(betting_data['date'])\n",
    "games_master['GAME_DATE'] = pd.to_datetime(games_master['GAME_DATE'])\n",
    "\n",
    "\n",
    "## Create Team Abbreviation Mapping\n",
    "team_map = {\n",
    "    'atl': 'ATL', 'bos': 'BOS', 'bkn': 'BKN', 'cha': 'CHA', 'chi': 'CHI',\n",
    "    'cle': 'CLE', 'dal': 'DAL', 'den': 'DEN', 'det': 'DET', 'gs': 'GSW',\n",
    "    'hou': 'HOU', 'ind': 'IND', 'lac': 'LAC', 'lal': 'LAL', 'mem': 'MEM',\n",
    "    'mia': 'MIA', 'mil': 'MIL', 'min': 'MIN', 'no': 'NOP', 'nyk': 'NYK',\n",
    "    'okc': 'OKC', 'orl': 'ORL', 'phi': 'PHI', 'phx': 'PHX', 'por': 'POR',\n",
    "    'sac': 'SAC', 'sa': 'SAS', 'tor': 'TOR', 'utah': 'UTA', 'wsh': 'WAS',\n",
    "    'nj': 'BKN', 'ny': 'NYK'\n",
    "}\n",
    "\n",
    "# Apply mapping\n",
    "betting_data['away_team'] = betting_data['away'].map(team_map)\n",
    "betting_data['home_team'] = betting_data['home'].map(team_map)\n",
    "\n",
    "\n",
    "## Create Match Keys\n",
    "betting_data['match_key'] = (\n",
    "    betting_data['date'].dt.strftime('%Y-%m-%d') + '_' + \n",
    "    betting_data['away_team'] + '_' + \n",
    "    betting_data['home_team']\n",
    ")\n",
    "\n",
    "\n",
    "## Create NBA Match Keys\n",
    "games_master['is_home'] = games_master['MATCHUP'].str.contains('vs.', na=False)\n",
    "\n",
    "# Separate home and away games\n",
    "home_games = games_master[games_master['is_home'] == True][\n",
    "    ['GAME_ID', 'GAME_DATE', 'TEAM_ABBREVIATION']\n",
    "].copy()\n",
    "away_games = games_master[games_master['is_home'] == False][\n",
    "    ['GAME_ID', 'GAME_DATE', 'TEAM_ABBREVIATION']\n",
    "].copy()\n",
    "\n",
    "home_games.columns = ['GAME_ID', 'GAME_DATE', 'home_team']\n",
    "away_games.columns = ['GAME_ID', 'GAME_DATE', 'away_team']\n",
    "\n",
    "# Merge to create matchups\n",
    "game_matchups = home_games.merge(away_games, on=['GAME_ID', 'GAME_DATE'])\n",
    "\n",
    "# Create match key\n",
    "game_matchups['match_key'] = (\n",
    "    game_matchups['GAME_DATE'].dt.strftime('%Y-%m-%d') + '_' + \n",
    "    game_matchups['away_team'] + '_' + \n",
    "    game_matchups['home_team']\n",
    ")\n",
    "\n",
    "\n",
    "## Join and Create Mapping\n",
    "game_id_target = game_matchups.merge(\n",
    "    betting_data[['match_key', 'h2_total']],\n",
    "    on='match_key',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Keep only GAME_ID and h2_total\n",
    "game_id_target = game_id_target[['GAME_ID', 'h2_total']].drop_duplicates()\n",
    "\n",
    "print(f\"\\nCreated GAME_ID to h2_total mapping\")\n",
    "print(f\"Total games: {len(game_id_target)}\")\n",
    "print(f\"Games with h2_total: {game_id_target['h2_total'].notna().sum()}\")\n",
    "print(f\"Games missing h2_total: {game_id_target['h2_total'].isna().sum()}\")\n",
    "\n",
    "## Save Mapping\n",
    "game_id_target.to_csv('game_id_to_h2_total.csv', index=False)\n",
    "print(f\"\\nSaved to game_id_to_h2_total.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697ce94e",
   "metadata": {},
   "source": [
    "Cell below actually does the join. Upon further investigation we realized that the failed joins were preseason and international exhibition games so we can drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62608b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge Betting Lines and Filter Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "## Load Data\n",
    "features_df = pd.read_csv('nba_time_based_features.csv')\n",
    "game_id_target = pd.read_csv('game_id_to_h2_total.csv')\n",
    "\n",
    "## Join h2_total to Features\n",
    "features_with_target = features_df.merge(\n",
    "    game_id_target,\n",
    "    on='GAME_ID',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"After join: {features_with_target.shape}\")\n",
    "print(f\"Rows with h2_total: {features_with_target['h2_total'].notna().sum()}\")\n",
    "print(f\"Rows without h2_total: {features_with_target['h2_total'].isna().sum()}\")\n",
    "\n",
    "\n",
    "## Drop Rows Without h2_total\n",
    "features_with_target = features_with_target[features_with_target['h2_total'].notna()]\n",
    "\n",
    "print(f\"\\nAfter dropping preseason/exhibition: {features_with_target.shape}\")\n",
    "\n",
    "## Save the joined dataset\n",
    "print(f\"\\nSaving to nba_features_with_target.csv...\")\n",
    "features_with_target.to_csv('nba_features_with_target.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231b4791",
   "metadata": {},
   "source": [
    "This next cell block preps the data for modelling. First it drops all columns that would cost data leaks (basically ones that have second half information) since we are using walk forward building dates are fine. We are testing on the second most recent season we had betting information on and before that is train data. We held out the last partial season of data for seperate validation processes.\n",
    "\n",
    "*** This is where you start the code from the Git Repo ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e3efc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Train/Test/Holdout Splits\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "## Load data\n",
    "df = pd.read_csv('nba_features_with_target.csv')\n",
    "df['GAME_DATE'] = pd.to_datetime(df['GAME_DATE'])\n",
    "\n",
    "\n",
    "## Drop leakage columns\n",
    "drop_columns = [\n",
    "    # Rolling second-half team stats\n",
    "    'team_cg_second_half_pts_7d', 'team_cg_second_half_fgm_7d', \n",
    "    'team_cg_second_half_fga_7d', 'team_cg_second_half_fg3m_7d',\n",
    "    'team_cg_second_half_fg3a_7d', 'team_cg_second_half_ftm_7d',\n",
    "    'team_cg_second_half_fta_7d', 'team_cg_second_half_reb_7d',\n",
    "    'team_cg_second_half_ast_7d', 'team_cg_second_half_to_7d',\n",
    "    'team_cg_second_half_stl_7d', 'team_cg_second_half_blk_7d',\n",
    "    'team_cg_second_half_fg_pct_7d', 'team_cg_second_half_fg3_pct_7d',\n",
    "    'team_cg_second_half_ft_pct_7d', 'team_cg_second_half_pts_14d',\n",
    "    'team_cg_second_half_fgm_14d', 'team_cg_second_half_fga_14d',\n",
    "    'team_cg_second_half_fg3m_14d', 'team_cg_second_half_fg3a_14d',\n",
    "    'team_cg_second_half_ftm_14d', 'team_cg_second_half_fta_14d',\n",
    "    'team_cg_second_half_reb_14d', 'team_cg_second_half_ast_14d',\n",
    "    'team_cg_second_half_to_14d', 'team_cg_second_half_stl_14d',\n",
    "    'team_cg_second_half_blk_14d', 'team_cg_second_half_fg_pct_14d',\n",
    "    'team_cg_second_half_fg3_pct_14d', 'team_cg_second_half_ft_pct_14d',\n",
    "    'team_cg_second_half_pts_30d', 'team_cg_second_half_fgm_30d',\n",
    "    'team_cg_second_half_fga_30d', 'team_cg_second_half_fg3m_30d',\n",
    "    'team_cg_second_half_fg3a_30d', 'team_cg_second_half_ftm_30d',\n",
    "    'team_cg_second_half_fta_30d', 'team_cg_second_half_reb_30d',\n",
    "    'team_cg_second_half_ast_30d', 'team_cg_second_half_to_30d',\n",
    "    'team_cg_second_half_stl_30d', 'team_cg_second_half_blk_30d',\n",
    "    'team_cg_second_half_fg_pct_30d', 'team_cg_second_half_fg3_pct_30d',\n",
    "    'team_cg_second_half_ft_pct_30d',\n",
    "\n",
    "    # Direct post-game leakage columns\n",
    "    'actual_second_half_pts', 'actual_second_half_fgm',\n",
    "    'actual_second_half_fga', 'actual_second_half_fg3m',\n",
    "    'actual_second_half_fg3a', 'actual_second_half_ftm',\n",
    "    'actual_second_half_fta', 'actual_second_half_reb',\n",
    "    'actual_second_half_ast', 'actual_second_half_to',\n",
    "    'actual_second_half_stl', 'actual_second_half_blk',\n",
    "    'actual_second_half_fg_pct', 'actual_second_half_fg3_pct',\n",
    "    'actual_second_half_ft_pct', 'actual_second_half_plus_minus'\n",
    "]\n",
    "\n",
    "df = df.drop(columns=drop_columns, errors='ignore')\n",
    "\n",
    "\n",
    "## Get seasons\n",
    "def get_nba_season(date):\n",
    "    year = date.year\n",
    "    month = date.month\n",
    "    return f\"{year}-{year+1}\" if month >= 10 else f\"{year-1}-{year}\"\n",
    "\n",
    "df['season'] = df['GAME_DATE'].apply(get_nba_season)\n",
    "df = df.sort_values('GAME_DATE')\n",
    "\n",
    "seasons = sorted(df['season'].unique())\n",
    "\n",
    "\n",
    "## Create dataset splits\n",
    "holdout_season = seasons[-1]\n",
    "test_season = seasons[-2]\n",
    "train_seasons = seasons[:-2]\n",
    "\n",
    "# Filter data\n",
    "train_data = df[\n",
    "    (df['season'].isin(train_seasons)) & \n",
    "    (df['actual_second_half_total'].notna()) &\n",
    "    (df['h2_total'].notna())\n",
    "]\n",
    "\n",
    "test_data = df[\n",
    "    (df['season'] == test_season) & \n",
    "    (df['actual_second_half_total'].notna()) &\n",
    "    (df['h2_total'].notna())\n",
    "]\n",
    "\n",
    "holdout_data = df[\n",
    "    (df['season'] == holdout_season) & \n",
    "    (df['actual_second_half_total'].notna())\n",
    "]\n",
    "\n",
    "print(f\"\\nTrain: {len(train_data)} games\")\n",
    "print(f\"Test: {len(test_data)} games\")\n",
    "print(f\"Holdout: {len(holdout_data)} games\")\n",
    "\n",
    "\n",
    "## Prepare Feature List\n",
    "metadata_cols = ['GAME_ID', 'GAME_DATE', 'TEAM_ID', 'season']\n",
    "target_col = 'actual_second_half_total'\n",
    "betting_line_col = 'h2_total'\n",
    "\n",
    "feature_cols = [c for c in df.columns \n",
    "                if c not in metadata_cols + [target_col, betting_line_col]]\n",
    "\n",
    "## Save datasets\n",
    "train_data.to_csv('train_data.csv', index=False)\n",
    "test_data.to_csv('test_data.csv', index=False)\n",
    "holdout_data.to_csv('holdout_data.csv', index=False)\n",
    "\n",
    "with open('feature_list.txt', 'w') as f:\n",
    "    for col in feature_cols:\n",
    "        f.write(f\"{col}\\n\")\n",
    "\n",
    "print(\"\\nSaved: train_data.csv, test_data.csv, holdout_data.csv, feature_list.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556de189",
   "metadata": {},
   "outputs": [],
   "source": [
    "## First XGBoost Model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "## Load Data\n",
    "train_data = pd.read_csv('train_data.csv')\n",
    "test_data = pd.read_csv('test_data.csv')\n",
    "\n",
    "# Format Dates\n",
    "train_data['GAME_DATE'] = pd.to_datetime(train_data['GAME_DATE'])\n",
    "test_data['GAME_DATE'] = pd.to_datetime(test_data['GAME_DATE'])\n",
    "\n",
    "## Define Columns\n",
    "metadata_cols = ['GAME_ID', 'GAME_DATE', 'TEAM_ID', 'season']\n",
    "target_col = 'actual_second_half_total'\n",
    "betting_line_col = 'h2_total'\n",
    "\n",
    "# Feature columns\n",
    "drop_from_features = set(metadata_cols + [target_col])\n",
    "if betting_line_col in train_data.columns:\n",
    "    drop_from_features.add(betting_line_col)\n",
    "\n",
    "feature_cols = [c for c in train_data.columns if c not in drop_from_features]\n",
    "\n",
    "\n",
    "## Split into X and y\n",
    "X_train = train_data[feature_cols]\n",
    "y_train = train_data[target_col]\n",
    "\n",
    "X_test = test_data[feature_cols]\n",
    "y_test = test_data[target_col]\n",
    "\n",
    "\n",
    "## Impute Missing Values\n",
    "missing_train = X_train.isnull().sum()\n",
    "cols_with_missing = missing_train[missing_train > 0]\n",
    "\n",
    "if len(cols_with_missing) > 0:\n",
    "    for col in cols_with_missing.index:\n",
    "        median_val = X_train[col].median()\n",
    "        X_train[col].fillna(median_val, inplace=True)\n",
    "        X_test[col].fillna(median_val, inplace=True)\n",
    "    print(\"Missing values handled!\")\n",
    "else:\n",
    "    print(\"No missing values!\")\n",
    "\n",
    "\n",
    "## Train Model\n",
    "model = xgb.XGBRegressor(\n",
    "    n_estimators=1800,\n",
    "    learning_rate=0.018,\n",
    "    max_depth=8,\n",
    "    min_child_weight=1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.75,\n",
    "    gamma=0.05,\n",
    "    reg_alpha=0.2,\n",
    "    reg_lambda=0.6,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    early_stopping_rounds=120,\n",
    "    eval_metric='rmse'\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "    verbose=50\n",
    ")\n",
    "\n",
    "\n",
    "## Evaluate Model\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "\n",
    "print(f\"\\nTest Metrics:\")\n",
    "print(f\"MAE:  {mae_test:.3f} points\")\n",
    "print(f\"RMSE: {rmse_test:.3f} points\")\n",
    "print(f\"RÂ²:   {r2_test:.3f}\")\n",
    "\n",
    "\n",
    "## Save Results\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Test predictions\n",
    "test_results = test_data.copy()\n",
    "test_results['actual_second_half_total_predicted'] = y_pred_test\n",
    "test_results['prediction_error'] = np.abs(y_test - y_pred_test)\n",
    "\n",
    "show_cols = ['GAME_ID', 'GAME_DATE', 'actual_second_half_total',\n",
    "            'actual_second_half_total_predicted', 'prediction_error']\n",
    "if betting_line_col in test_results.columns:\n",
    "    test_results['edge_vs_line'] = test_results['actual_second_half_total_predicted'] - test_results[betting_line_col]\n",
    "    show_cols.append(betting_line_col)\n",
    "    show_cols.append('edge_vs_line')\n",
    "\n",
    "\n",
    "# Save\n",
    "model.save_model('xgboost_model.json')\n",
    "print(\"Saved xgboost_model.json\")\n",
    "\n",
    "feature_importance.to_csv('feature_importance.csv', index=False)\n",
    "print(\"Saved feature_importance.csv\")\n",
    "\n",
    "test_results.to_csv('test_predictions.csv', index=False)\n",
    "print(\"Saved test_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce8dcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Comparison XGBoost and XGboost with resid\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "## Load Prediction Files\n",
    "resid = pd.read_csv(\"test_predictions.csv\")                  # main (no residual) model\n",
    "no_resid = pd.read_csv(\"test_predictions_residual.csv\")      # residual model\n",
    "\n",
    "\n",
    "## Get Prediction Column Names (i named them badly)\n",
    "def get_pred_col(df):\n",
    "    if \"predicted_total\" in df.columns:\n",
    "        return \"predicted_total\"\n",
    "    elif \"actual_second_half_total_predicted\" in df.columns:\n",
    "        return \"actual_second_half_total_predicted\"\n",
    "    else:\n",
    "        raise KeyError(\"still can't get the columns right\")\n",
    "\n",
    "pred_col_resid = get_pred_col(resid)\n",
    "pred_col_no_resid = get_pred_col(no_resid)\n",
    "\n",
    "\n",
    "## Define Targets and Predictions\n",
    "y_true = resid[\"actual_second_half_total\"]\n",
    "y_vegas = resid[\"h2_total\"]\n",
    "\n",
    "y_pred_no_residual = resid[pred_col_resid]\n",
    "y_pred_residual = no_resid[pred_col_no_resid]\n",
    "\n",
    "\n",
    "## Evaluation Function\n",
    "def evaluate(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mae, rmse, r2\n",
    "\n",
    "\n",
    "## Calculate Metrics\n",
    "results = {\n",
    "    \"Vegas Line\": evaluate(y_true, y_vegas),\n",
    "    \"No Residual Model\": evaluate(y_true, y_pred_no_residual),\n",
    "    \"Residual Model\": evaluate(y_true, y_pred_residual),\n",
    "}\n",
    "\n",
    "\n",
    "## Create Summary\n",
    "summary = pd.DataFrame(results, index=[\"MAE\", \"RMSE\", \"RÂ²\"]).T\n",
    "summary[\"Î” MAE vs Vegas\"] = summary[\"MAE\"] - summary.loc[\"Vegas Line\", \"MAE\"]\n",
    "summary[\"Î” RMSE vs Vegas\"] = summary[\"RMSE\"] - summary.loc[\"Vegas Line\", \"RMSE\"]\n",
    "\n",
    "print(\"SECOND HALF TOTALS â€“ MODEL BENCHMARK COMPARISON\")\n",
    "print(summary.to_string(float_format=lambda x: f\"{x:0.3f}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c4d2ef",
   "metadata": {},
   "source": [
    "In these next 3 cell blocks we do our feature importance, ablation, and sensitivity analysis on depth. Most of which confirm our choice to use XGBoost (we do test other models after this). Moreover, it shows that given our wide feature set depth does not prove to be very important and the 7-day rolling stats were great features to implement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe12ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## FEature Importance\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "## Load Model\n",
    "model = xgb.XGBRegressor()\n",
    "model.load_model(\"xgboost_model.json\")\n",
    "\n",
    "## Load Data\n",
    "train_data = pd.read_csv('train_data.csv')\n",
    "test_data = pd.read_csv('test_data.csv')\n",
    "\n",
    "\n",
    "## Get Feature Importance\n",
    "importance = model.get_booster().get_score(importance_type=\"gain\")\n",
    "importance_df = pd.DataFrame(importance.items(), columns=[\"feature\", \"gain\"])\n",
    "importance_df = importance_df.sort_values(\"gain\", ascending=False)\n",
    "\n",
    "print(importance_df.head(20).to_string(index=False, float_format=lambda x: f\"{x:0.3f}\"))\n",
    "\n",
    "\n",
    "## Categorize Features\n",
    "def categorize_feature(feat):\n",
    "    if \"halftime\" in feat or \"current_fh\" in feat:\n",
    "        return \"Halftime Stats\"\n",
    "    elif \"opp_\" in feat:\n",
    "        return \"Opponent Features\"\n",
    "    elif \"h2_total\" in feat:\n",
    "        return \"Vegas Line\"\n",
    "    elif \"_7d\" in feat:\n",
    "        return \"7-Day Rolling\"\n",
    "    elif \"_14d\" in feat:\n",
    "        return \"14-Day Rolling\"\n",
    "    elif \"_30d\" in feat:\n",
    "        return \"30-Day Rolling\"\n",
    "    elif \"top\" in feat:\n",
    "        return \"Player Level\"\n",
    "    elif any(x in feat for x in [\"rest\", \"back_to_back\", \"home_stand\", \"road_trip\"]):\n",
    "        return \"Schedule\"\n",
    "    elif \"ref\" in feat:\n",
    "        return \"Referee\"\n",
    "    else:\n",
    "        return \"Other\"\n",
    "    \n",
    "    \n",
    "## Summarize Feature Importance by Category\n",
    "importance_df[\"category\"] = importance_df[\"feature\"].apply(categorize_feature)\n",
    "category_importance = (\n",
    "    importance_df.groupby(\"category\")[\"gain\"].sum().sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "print()\n",
    "print(category_importance.to_string(float_format=lambda x: f\"{x:0.3f}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151a8c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ABLATION ANALYSIS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "## Load Data\n",
    "train = pd.read_csv(\"train_data.csv\")\n",
    "test = pd.read_csv(\"test_data.csv\")\n",
    "\n",
    "## Define Columns (matching training script)\n",
    "metadata_cols = [\"GAME_ID\", \"GAME_DATE\", \"TEAM_ID\", \"season\"]\n",
    "target_col = \"actual_second_half_total\"\n",
    "vegas_col = \"h2_total\"\n",
    "\n",
    "# Get all feature columns (same as training script)\n",
    "feature_cols = [c for c in train.columns if c not in metadata_cols + [target_col]]\n",
    "\n",
    "# Residual target\n",
    "y_train = train[target_col] - train[vegas_col]\n",
    "y_test = test[target_col] - test[vegas_col]\n",
    "X_train = train[feature_cols].copy()\n",
    "X_test = test[feature_cols].copy()\n",
    "\n",
    "## Impute Missing Values (matching training script)\n",
    "for col in X_train.columns:\n",
    "    if X_train[col].isnull().any():\n",
    "        median_val = X_train[col].median()\n",
    "        X_train[col].fillna(median_val, inplace=True)\n",
    "        X_test[col].fillna(median_val, inplace=True)\n",
    "\n",
    "\n",
    "## Load Trained Residual Model\n",
    "model = xgb.XGBRegressor()\n",
    "model.load_model(\"xgboost_residual_model.json\")\n",
    "\n",
    "\n",
    "## Baseline Evaluation\n",
    "baseline_mae = mean_absolute_error(y_test, model.predict(X_test))\n",
    "ablation_results = [{\n",
    "    \"Feature Group Removed\": \"None (Full Model)\",\n",
    "    \"Test MAE\": baseline_mae,\n",
    "    \"Î” MAE\": 0.0,\n",
    "    \"% Degradation\": 0.0\n",
    "}]\n",
    "print(f\"Baseline Residual MAE: {baseline_mae:.3f}\")\n",
    "\n",
    "\n",
    "## Helper Function\n",
    "def train_and_eval(Xtr, ytr, Xte, yte, group_name):\n",
    "    print(f\"\\nTesting without {group_name} features...\")\n",
    "    \n",
    "    # Impute missing values for ablated data\n",
    "    for col in Xtr.columns:\n",
    "        if Xtr[col].isnull().any():\n",
    "            median_val = Xtr[col].median()\n",
    "            Xtr[col].fillna(median_val, inplace=True)\n",
    "            Xte[col].fillna(median_val, inplace=True)\n",
    "    \n",
    "    model_temp = xgb.XGBRegressor(\n",
    "        n_estimators=1800, \n",
    "        learning_rate=0.018, \n",
    "        max_depth=8,\n",
    "        min_child_weight=1, \n",
    "        subsample=0.8, \n",
    "        colsample_bytree=0.75,\n",
    "        gamma=0.05, \n",
    "        reg_alpha=0.2, \n",
    "        reg_lambda=0.6,\n",
    "        random_state=42, \n",
    "        n_jobs=-1\n",
    "    )\n",
    "    model_temp.fit(Xtr, ytr, verbose=False)\n",
    "    mae = mean_absolute_error(yte, model_temp.predict(Xte))\n",
    "    ablation_results.append({\n",
    "        \"Feature Group Removed\": group_name,\n",
    "        \"Test MAE\": mae,\n",
    "        \"Î” MAE\": mae - baseline_mae,\n",
    "        \"% Degradation\": ((mae - baseline_mae) / baseline_mae) * 100\n",
    "    })\n",
    "    print(f\"MAE: {mae:.3f} | Î”: {mae - baseline_mae:+.3f} | %Î”: {((mae - baseline_mae) / baseline_mae) * 100:.2f}%\")\n",
    "\n",
    "\n",
    "## Feature groups to test (keeping Vegas line in all tests)\n",
    "feature_groups = {\n",
    "    \"30-Day Rolling\": [col for col in X_train.columns if \"_30d\" in col and col != vegas_col],\n",
    "    \"14-Day Rolling\": [col for col in X_train.columns if \"_14d\" in col and col != vegas_col],\n",
    "    \"7-Day Rolling\": [col for col in X_train.columns if \"_7d\" in col and col != vegas_col],\n",
    "    \"Opponent Features\": [col for col in X_train.columns if col.startswith(\"opp_\") and col != vegas_col],\n",
    "    \"Halftime Stats\": [col for col in X_train.columns if (\"halftime\" in col or \"current_fh\" in col) and col != vegas_col],\n",
    "    \"Schedule\": [col for col in X_train.columns if any(x in col for x in [\"rest\", \"back_to_back\", \"home_stand\", \"road_trip\"]) and col != vegas_col],\n",
    "    \"Referee\": [col for col in X_train.columns if \"ref\" in col and col != vegas_col]\n",
    "}\n",
    "\n",
    "\n",
    "## Run ablation tests\n",
    "for group_name, cols_to_remove in feature_groups.items():\n",
    "    print(f\"\\nFound {len(cols_to_remove)} {group_name} columns: {cols_to_remove[:5] if len(cols_to_remove) > 5 else cols_to_remove} ...\")\n",
    "    if cols_to_remove:\n",
    "        Xtr = X_train.drop(columns=cols_to_remove)\n",
    "        Xte = X_test.drop(columns=cols_to_remove)\n",
    "        train_and_eval(Xtr.copy(), y_train.copy(), Xte.copy(), y_test.copy(), group_name)\n",
    "\n",
    "\n",
    "## Results\n",
    "ablation_df = pd.DataFrame(ablation_results)\n",
    "\n",
    "print(\"\\nABLATION RESULTS\")\n",
    "print(ablation_df.to_string(index=False, float_format=lambda x: f\"{x:.3f}\"))\n",
    "ablation_df.to_csv(\"ablation_results.csv\", index=False)\n",
    "print(\"\\nSaved results to ablation_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f584a42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sensitivity Analysis - Hyperparameter Testing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Load Data\n",
    "train_data = pd.read_csv(\"train_data.csv\")\n",
    "test_data = pd.read_csv(\"test_data.csv\")\n",
    "\n",
    "## Define Columns (matching your training script)\n",
    "metadata_cols = [\"GAME_ID\", \"GAME_DATE\", \"TEAM_ID\", \"season\"]\n",
    "target_col = \"actual_second_half_total\"\n",
    "vegas_col = \"h2_total\"\n",
    "\n",
    "feature_cols = [c for c in train_data.columns if c not in metadata_cols + [target_col]]\n",
    "\n",
    "# Use the same train/test split as original training\n",
    "X_train = train_data[feature_cols].copy()\n",
    "y_train = train_data[target_col] - train_data[vegas_col]\n",
    "\n",
    "X_test = test_data[feature_cols].copy()\n",
    "y_test = test_data[target_col] - test_data[vegas_col]\n",
    "\n",
    "## Impute Missing Values\n",
    "for col in X_train.columns:\n",
    "    if X_train[col].isnull().any():\n",
    "        median_val = X_train[col].median()\n",
    "        X_train[col].fillna(median_val, inplace=True)\n",
    "        X_test[col].fillna(median_val, inplace=True)\n",
    "\n",
    "## Load baseline model and compute baseline MAE on test set\n",
    "model = xgb.XGBRegressor()\n",
    "model.load_model('xgboost_residual_model.json')\n",
    "baseline_mae = mean_absolute_error(y_test, model.predict(X_test))\n",
    "print(f\"Baseline MAE (depth=8): {baseline_mae:.3f}\")\n",
    "\n",
    "## Test different depths\n",
    "depths = [4, 6, 8, 10, 12]\n",
    "sensitivity_results = []\n",
    "\n",
    "print(\"\\nTesting max_depth sensitivity...\")\n",
    "for depth in depths:\n",
    "    print(f\"  Training with max_depth={depth}...\")\n",
    "    \n",
    "    model_test = xgb.XGBRegressor(\n",
    "        n_estimators=1800,\n",
    "        learning_rate=0.018,\n",
    "        max_depth=depth,\n",
    "        min_child_weight=1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.75,\n",
    "        gamma=0.05,\n",
    "        reg_alpha=0.2,\n",
    "        reg_lambda=0.6,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        early_stopping_rounds=120,\n",
    "        eval_metric='rmse'\n",
    "    )\n",
    "    \n",
    "    # Added eval_set to match original training\n",
    "    model_test.fit(\n",
    "        X_train, \n",
    "        y_train, \n",
    "        eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    mae = mean_absolute_error(y_test, model_test.predict(X_test))\n",
    "    \n",
    "    sensitivity_results.append({\n",
    "        'max_depth': depth,\n",
    "        'Test MAE': mae,\n",
    "        'Î” MAE from baseline': mae - baseline_mae,\n",
    "        '% Change': ((mae - baseline_mae) / baseline_mae) * 100\n",
    "    })\n",
    "    print(f\"    MAE: {mae:.3f} | Î”: {mae - baseline_mae:+.3f}\")\n",
    "\n",
    "## Results\n",
    "sensitivity_df = pd.DataFrame(sensitivity_results)\n",
    "print(\"\\nMAX_DEPTH SENSITIVITY ANALYSIS\")\n",
    "print(sensitivity_df.to_string(index=False, float_format=lambda x: f\"{x:.3f}\"))\n",
    "\n",
    "# Save results\n",
    "sensitivity_df.to_csv(\"sensitivity_max_depth.csv\", index=False)\n",
    "print(\"\\nSaved results to sensitivity_max_depth.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa0f916",
   "metadata": {},
   "source": [
    "Basically as we were testing we found out that the Vegas line is actually very very good. Even without using first half data its actually better then our tuned XGBoost model. Knowing that we have the Vegas second half total we used that as a residual in another XGBoost model, which gave us some improvements over the Vegas line. Is this enough to make betting model that is profitable? We do not quite know yet. \n",
    "\n",
    "Also then tried a Random Forest because tree based models have similiarities and perhaps RF performs better (but it didn't). We tried to keep the parameters similar to the XGBoost model because we spent tons of time tuning the XGBoost model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5cc4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random Forest Residual Model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "##Load Data\n",
    "train_data = pd.read_csv('train_data.csv')\n",
    "test_data = pd.read_csv('test_data.csv')\n",
    "\n",
    "train_data['GAME_DATE'] = pd.to_datetime(train_data['GAME_DATE'])\n",
    "test_data['GAME_DATE'] = pd.to_datetime(test_data['GAME_DATE'])\n",
    "\n",
    "\n",
    "## Define Columns\n",
    "metadata_cols = ['GAME_ID', 'GAME_DATE', 'TEAM_ID', 'season']\n",
    "target_col = 'actual_second_half_total'\n",
    "vegas_col = 'h2_total'\n",
    "\n",
    "feature_cols = [c for c in train_data.columns if c not in metadata_cols + [target_col]]\n",
    "\n",
    "X_train = train_data[feature_cols].copy()\n",
    "y_train = train_data[target_col] - train_data[vegas_col]\n",
    "\n",
    "X_test = test_data[feature_cols].copy()\n",
    "y_test = test_data[target_col] - test_data[vegas_col]\n",
    "\n",
    "\n",
    "## Impute missing values\n",
    "for col in X_train.columns:\n",
    "    if X_train[col].isnull().any():\n",
    "        median_val = X_train[col].median()\n",
    "        X_train[col].fillna(median_val, inplace=True)\n",
    "        X_test[col].fillna(median_val, inplace=True)\n",
    "\n",
    "\n",
    "## Train Model\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=1800,\n",
    "    max_depth=8,\n",
    "    min_samples_split=5\n",
    "    min_samples_leaf=2,\n",
    "    max_samples=0.8,\n",
    "    max_features=0.75,\n",
    "    min_impurity_decrease=0.0,\n",
    "    bootstrap=True,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "## Evaluate Residual Performance\n",
    "y_pred_resid = model.predict(X_test)\n",
    "\n",
    "mae_resid = mean_absolute_error(y_test, y_pred_resid)\n",
    "rmse_resid = np.sqrt(mean_squared_error(y_test, y_pred_resid))\n",
    "r2_resid = r2_score(y_test, y_pred_resid)\n",
    "\n",
    "print(f\"\\nRandom Forest Residual Metrics:\")\n",
    "print(f\"MAE:  {mae_resid:.3f} pts\")\n",
    "print(f\"RMSE: {rmse_resid:.3f} pts\")\n",
    "print(f\"RÂ²:   {r2_resid:.3f}\")\n",
    "\n",
    "\n",
    "## Reconstruct Full Totals\n",
    "y_pred_total = y_pred_resid + X_test[vegas_col]\n",
    "y_true_total = y_test + X_test[vegas_col]\n",
    "\n",
    "mae_total = mean_absolute_error(y_true_total, y_pred_total)\n",
    "rmse_total = np.sqrt(mean_squared_error(y_true_total, y_pred_total))\n",
    "r2_total = r2_score(y_true_total, y_pred_total)\n",
    "\n",
    "\n",
    "## Vegas Baseline\n",
    "mae_vegas = mean_absolute_error(y_true_total, X_test[vegas_col])\n",
    "rmse_vegas = np.sqrt(mean_squared_error(y_true_total, X_test[vegas_col]))\n",
    "r2_vegas = r2_score(y_true_total, X_test[vegas_col])\n",
    "\n",
    "print(f\"\\nFull Total Performance:\")\n",
    "print(f\"Vegas Line     MAE: {mae_vegas:.3f} | RMSE: {rmse_vegas:.3f} | RÂ²: {r2_vegas:.3f}\")\n",
    "print(f\"Random Forest  MAE: {mae_total:.3f} | RMSE: {rmse_total:.3f} | RÂ²: {r2_total:.3f}\")\n",
    "print(f\"Î” MAE:  {mae_total - mae_vegas:+.3f}\")\n",
    "print(f\"Î” RMSE: {rmse_total - rmse_vegas:+.3f}\")\n",
    "\n",
    "\n",
    "## Save Results\n",
    "test_results = test_data.copy()\n",
    "test_results['rf_predicted_residual'] = y_pred_resid\n",
    "test_results['rf_predicted_total'] = y_pred_total\n",
    "test_results['rf_edge_vs_vegas'] = y_pred_resid\n",
    "\n",
    "test_results.to_csv('test_predictions_rf.csv', index=False)\n",
    "joblib.dump(model, 'random_forest_model.pkl')\n",
    "\n",
    "print(\"\\nSaved: test_predictions_rf.csv, random_forest_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef386d4",
   "metadata": {},
   "source": [
    "Why not try a very complex NN MLP model to see if we can get anything. This model ended up performing better than a very WIDE model with 1024 as the first layer. We originally thought given the large feature set that it might be better but it performed worse. NN might not be the best choice because we do not have enough data to find even more complicated patterns. Also we took out player names to make sure the model generalizes. Perhaps in a future project we could try to just NN everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8052a930",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Neural Network (MLP) Residual Model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "## Load Data\n",
    "train_data = pd.read_csv('train_data.csv')\n",
    "test_data = pd.read_csv('test_data.csv')\n",
    "\n",
    "train_data['GAME_DATE'] = pd.to_datetime(train_data['GAME_DATE'])\n",
    "test_data['GAME_DATE'] = pd.to_datetime(test_data['GAME_DATE'])\n",
    "\n",
    "\n",
    "## Define Columns\n",
    "metadata_cols = ['GAME_ID', 'GAME_DATE', 'TEAM_ID', 'season']\n",
    "target_col = 'actual_second_half_total'\n",
    "vegas_col = 'h2_total'\n",
    "\n",
    "feature_cols = [c for c in train_data.columns if c not in metadata_cols + [target_col]]\n",
    "\n",
    "X_train = train_data[feature_cols].copy()\n",
    "y_train = train_data[target_col] - train_data[vegas_col]\n",
    "\n",
    "X_test = test_data[feature_cols].copy()\n",
    "y_test = test_data[target_col] - test_data[vegas_col]\n",
    "\n",
    "\n",
    "## Imputer also for X_Tesst\n",
    "print(\"Imputing missing values...\")\n",
    "for col in feature_cols:\n",
    "    median_val = X_train[col].median()\n",
    "    X_train[col].fillna(median_val, inplace=True)\n",
    "    X_test[col].fillna(median_val, inplace=True)\n",
    "\n",
    "\n",
    "## Scale Features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "## Train Model\n",
    "model = MLPRegressor(\n",
    "    hidden_layer_sizes=(256, 128, 64),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    alpha=0.4,\n",
    "    batch_size=64,\n",
    "    learning_rate='adaptive',\n",
    "    learning_rate_init=0.018,\n",
    "    max_iter=1800,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.1,\n",
    "    n_iter_no_change=120,\n",
    "    tol=1e-4,\n",
    "    random_state=42,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "## Evaluate Residual Performance\n",
    "y_pred_resid = model.predict(X_test_scaled)\n",
    "\n",
    "mae_resid = mean_absolute_error(y_test, y_pred_resid)\n",
    "rmse_resid = np.sqrt(mean_squared_error(y_test, y_pred_resid))\n",
    "r2_resid = r2_score(y_test, y_pred_resid)\n",
    "\n",
    "print(f\"\\nNeural Network Residual Metrics:\")\n",
    "print(f\"MAE:  {mae_resid:.3f} pts\")\n",
    "print(f\"RMSE: {rmse_resid:.3f} pts\")\n",
    "print(f\"RÂ²:   {r2_resid:.3f}\")\n",
    "\n",
    "## Reconstruct Full totals\n",
    "y_pred_total = y_pred_resid + X_test[vegas_col]\n",
    "y_true_total = y_test + X_test[vegas_col]\n",
    "\n",
    "mae_total = mean_absolute_error(y_true_total, y_pred_total)\n",
    "rmse_total = np.sqrt(mean_squared_error(y_true_total, y_pred_total))\n",
    "r2_total = r2_score(y_true_total, y_pred_total)\n",
    "\n",
    "\n",
    "## Vegas baseline\n",
    "mae_vegas = mean_absolute_error(y_true_total, X_test[vegas_col])\n",
    "rmse_vegas = np.sqrt(mean_squared_error(y_true_total, X_test[vegas_col]))\n",
    "r2_vegas = r2_score(y_true_total, X_test[vegas_col])\n",
    "\n",
    "print(f\"\\nFull Total Performance:\")\n",
    "print(f\"Vegas Line  MAE: {mae_vegas:.3f} | RMSE: {rmse_vegas:.3f} | RÂ²: {r2_vegas:.3f}\")\n",
    "print(f\"Neural Net  MAE: {mae_total:.3f} | RMSE: {rmse_total:.3f} | RÂ²: {r2_total:.3f}\")\n",
    "print(f\"Î” MAE:  {mae_total - mae_vegas:+.3f}\")\n",
    "print(f\"Î” RMSE: {rmse_total - rmse_vegas:+.3f}\")\n",
    "\n",
    "## Save Results\n",
    "test_results = test_data.copy()\n",
    "test_results['mlp_predicted_residual'] = y_pred_resid\n",
    "test_results['mlp_predicted_total'] = y_pred_total\n",
    "test_results['mlp_edge_vs_vegas'] = y_pred_resid\n",
    "\n",
    "test_results.to_csv('test_predictions_mlp.csv', index=False)\n",
    "joblib.dump(model, 'mlp_model.pkl')\n",
    "joblib.dump(scaler, 'mlp_scaler.pkl')\n",
    "\n",
    "print(\"\\nSaved: test_predictions_mlp.csv, mlp_model.pkl, mlp_scaler.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772a2d61",
   "metadata": {},
   "source": [
    "Tested and LightGBM model because its common alternative to XGBoost trying to use parameters that are very similar to XGBoost since we heavily optimized or tuned that model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374f4014",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LightGBM Residual Model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "## Load Data\n",
    "train_data = pd.read_csv('train_data.csv')\n",
    "test_data = pd.read_csv('test_data.csv')\n",
    "\n",
    "train_data['GAME_DATE'] = pd.to_datetime(train_data['GAME_DATE'])\n",
    "test_data['GAME_DATE'] = pd.to_datetime(test_data['GAME_DATE'])\n",
    "\n",
    "\n",
    "## Define Columns\n",
    "metadata_cols = ['GAME_ID', 'GAME_DATE', 'TEAM_ID', 'season']\n",
    "target_col = 'actual_second_half_total'\n",
    "vegas_col = 'h2_total'\n",
    "\n",
    "feature_cols = [c for c in train_data.columns if c not in metadata_cols + [target_col]]\n",
    "\n",
    "X_train = train_data[feature_cols].copy()\n",
    "y_train = train_data[target_col] - train_data[vegas_col]\n",
    "\n",
    "X_test = test_data[feature_cols].copy()\n",
    "y_test = test_data[target_col] - test_data[vegas_col]\n",
    "\n",
    "\n",
    "## Impute missing values\n",
    "for col in feature_cols:\n",
    "    median_val = X_train[col].median()\n",
    "    X_train[col].fillna(median_val, inplace=True)\n",
    "    X_test[col].fillna(median_val, inplace=True)\n",
    "\n",
    "## Train Model\n",
    "model = lgb.LGBMRegressor(\n",
    "    n_estimators=1800,\n",
    "    learning_rate=0.018,\n",
    "    max_depth=8,\n",
    "    num_leaves=255,\n",
    "    min_child_samples=20,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.75,\n",
    "    min_split_gain=0.05,\n",
    "    reg_alpha=0.2,\n",
    "    reg_lambda=0.6,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "# Train with early stopping\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=120), lgb.log_evaluation(period=50)]\n",
    ")\n",
    "\n",
    "\n",
    "## Evaluate Residual Performance\n",
    "y_pred_resid = model.predict(X_test)\n",
    "\n",
    "mae_resid = mean_absolute_error(y_test, y_pred_resid)\n",
    "rmse_resid = np.sqrt(mean_squared_error(y_test, y_pred_resid))\n",
    "r2_resid = r2_score(y_test, y_pred_resid)\n",
    "\n",
    "print(f\"\\nLightGBM Residual Metrics:\")\n",
    "print(f\"MAE:  {mae_resid:.3f} pts\")\n",
    "print(f\"RMSE: {rmse_resid:.3f} pts\")\n",
    "print(f\"RÂ²:   {r2_resid:.3f}\")\n",
    "\n",
    "\n",
    "## Reconstruct Full Totals\n",
    "y_pred_total = y_pred_resid + X_test[vegas_col]\n",
    "y_true_total = y_test + X_test[vegas_col]\n",
    "\n",
    "mae_total = mean_absolute_error(y_true_total, y_pred_total)\n",
    "rmse_total = np.sqrt(mean_squared_error(y_true_total, y_pred_total))\n",
    "r2_total = r2_score(y_true_total, y_pred_total)\n",
    "\n",
    "## Vegas baseline\n",
    "mae_vegas = mean_absolute_error(y_true_total, X_test[vegas_col])\n",
    "rmse_vegas = np.sqrt(mean_squared_error(y_true_total, X_test[vegas_col]))\n",
    "r2_vegas = r2_score(y_true_total, X_test[vegas_col])\n",
    "\n",
    "print(f\"\\nFull Total Performance:\")\n",
    "print(f\"Vegas Line  MAE: {mae_vegas:.3f} | RMSE: {rmse_vegas:.3f} | RÂ²: {r2_vegas:.3f}\")\n",
    "print(f\"LightGBM    MAE: {mae_total:.3f} | RMSE: {rmse_total:.3f} | RÂ²: {r2_total:.3f}\")\n",
    "print(f\"Î” MAE:  {mae_total - mae_vegas:+.3f}\")\n",
    "print(f\"Î” RMSE: {rmse_total - rmse_vegas:+.3f}\")\n",
    "\n",
    "## Save Results\n",
    "test_results = test_data.copy()\n",
    "test_results['lgbm_predicted_residual'] = y_pred_resid\n",
    "test_results['lgbm_predicted_total'] = y_pred_total\n",
    "test_results['lgbm_edge_vs_vegas'] = y_pred_resid\n",
    "\n",
    "test_results.to_csv('test_predictions_lgbm.csv', index=False)\n",
    "model.booster_.save_model('lightgbm_model.txt')\n",
    "\n",
    "print(\"\\nSaved: test_predictions_lgbm.csv, lightgbm_model.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bbf20d",
   "metadata": {},
   "source": [
    "Lastly, we tested an Elastic Net Model in order to see if a linear model would perform better. This was a sanity check and it confirmed our suspicions that linear models would not capture the complexity of NBA games, even if they're rather homogenous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da08345e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Elastic Net Residual Model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "## Load Data\n",
    "train_data = pd.read_csv('train_data.csv')\n",
    "test_data = pd.read_csv('test_data.csv')\n",
    "\n",
    "train_data['GAME_DATE'] = pd.to_datetime(train_data['GAME_DATE'])\n",
    "test_data['GAME_DATE'] = pd.to_datetime(test_data['GAME_DATE'])\n",
    "\n",
    "\n",
    "## Define Columns\n",
    "metadata_cols = ['GAME_ID', 'GAME_DATE', 'TEAM_ID', 'season']\n",
    "target_col = 'actual_second_half_total'\n",
    "vegas_col = 'h2_total'\n",
    "\n",
    "feature_cols = [c for c in train_data.columns if c not in metadata_cols + [target_col]]\n",
    "\n",
    "X_train = train_data[feature_cols].copy()\n",
    "y_train = train_data[target_col] - train_data[vegas_col]\n",
    "\n",
    "X_test = test_data[feature_cols].copy()\n",
    "y_test = test_data[target_col] - test_data[vegas_col]\n",
    "\n",
    "## Impute missing values\n",
    "for col in feature_cols:\n",
    "    median_val = X_train[col].median()\n",
    "    X_train[col].fillna(median_val, inplace=True)\n",
    "    X_test[col].fillna(median_val, inplace=True)\n",
    "\n",
    "\n",
    "## Scale Features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "## Train Model\n",
    "model = ElasticNet(\n",
    "    alpha=0.1,\n",
    "    l1_ratio=0.5,\n",
    "    max_iter=10000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "## Evaluate Residual Performance\n",
    "y_pred_resid = model.predict(X_test_scaled)\n",
    "\n",
    "mae_resid = mean_absolute_error(y_test, y_pred_resid)\n",
    "rmse_resid = np.sqrt(mean_squared_error(y_test, y_pred_resid))\n",
    "r2_resid = r2_score(y_test, y_pred_resid)\n",
    "\n",
    "print(f\"\\nElastic Net Residual Metrics:\")\n",
    "print(f\"MAE:  {mae_resid:.3f} pts\")\n",
    "print(f\"RMSE: {rmse_resid:.3f} pts\")\n",
    "print(f\"RÂ²:   {r2_resid:.3f}\")\n",
    "\n",
    "# Reconstruct totals\n",
    "y_pred_total = y_pred_resid + X_test[vegas_col]\n",
    "y_true_total = y_test + X_test[vegas_col]\n",
    "\n",
    "mae_total = mean_absolute_error(y_true_total, y_pred_total)\n",
    "rmse_total = np.sqrt(mean_squared_error(y_true_total, y_pred_total))\n",
    "r2_total = r2_score(y_true_total, y_pred_total)\n",
    "\n",
    "\n",
    "## Vegas baseline\n",
    "mae_vegas = mean_absolute_error(y_true_total, X_test[vegas_col])\n",
    "rmse_vegas = np.sqrt(mean_squared_error(y_true_total, X_test[vegas_col]))\n",
    "r2_vegas = r2_score(y_true_total, X_test[vegas_col])\n",
    "\n",
    "print(f\"\\nFull Total Performance:\")\n",
    "print(f\"Vegas Line   MAE: {mae_vegas:.3f} | RMSE: {rmse_vegas:.3f} | RÂ²: {r2_vegas:.3f}\")\n",
    "print(f\"Elastic Net  MAE: {mae_total:.3f} | RMSE: {rmse_total:.3f} | RÂ²: {r2_total:.3f}\")\n",
    "print(f\"Î” MAE:  {mae_total - mae_vegas:+.3f}\")\n",
    "print(f\"Î” RMSE: {rmse_total - rmse_vegas:+.3f}\")\n",
    "\n",
    "## Save Results\n",
    "test_results = test_data.copy()\n",
    "test_results['enet_predicted_residual'] = y_pred_resid\n",
    "test_results['enet_predicted_total'] = y_pred_total\n",
    "test_results['enet_edge_vs_vegas'] = y_pred_resid\n",
    "\n",
    "test_results.to_csv('test_predictions_enet.csv', index=False)\n",
    "joblib.dump(model, 'elastic_net_model.pkl')\n",
    "joblib.dump(scaler, 'elastic_net_scaler.pkl')\n",
    "\n",
    "print(\"\\nSaved: test_predictions_enet.csv, elastic_net_model.pkl, elastic_net_scaler.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678591aa",
   "metadata": {},
   "source": [
    "XGBoost performed best, with other tree-based models (Random Forest, LightGBM) showing similar results. All models produced predictions close to the Vegas line with marginal deviations. Given the inherent variance in NBA games and minimal gains from extensive XGBoost tuning, we believe these results represent near the performance ceiling for this task. We therefore opted not to tune the remaining models, particularly the MLP and Elastic Net which performed significantly worse initially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ce44a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Full Model Comparison\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "## Load All Prediction Files\n",
    "vegas_baseline = pd.read_csv(\"test_data.csv\")\n",
    "xgb_preds = pd.read_csv(\"test_predictions_residual.csv\")\n",
    "rf_preds = pd.read_csv(\"test_predictions_rf.csv\")\n",
    "mlp_preds = pd.read_csv(\"test_predictions_mlp.csv\")\n",
    "lgbm_preds = pd.read_csv(\"test_predictions_lgbm.csv\")\n",
    "enet_preds = pd.read_csv(\"test_predictions_enet.csv\")\n",
    "\n",
    "\n",
    "## Get Actual Values and Predictions\n",
    "y_true = vegas_baseline[\"actual_second_half_total\"]\n",
    "y_vegas = vegas_baseline[\"h2_total\"]\n",
    "\n",
    "y_pred_xgb = xgb_preds[\"predicted_total\"]\n",
    "y_pred_rf = rf_preds[\"rf_predicted_total\"]\n",
    "y_pred_mlp = mlp_preds[\"mlp_predicted_total\"]\n",
    "y_pred_lgbm = lgbm_preds[\"lgbm_predicted_total\"]\n",
    "y_pred_enet = enet_preds[\"enet_predicted_total\"]\n",
    "\n",
    "\n",
    "## Evaluation Function\n",
    "def evaluate(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mae, rmse, r2\n",
    "\n",
    "\n",
    "## Calculate Metrics for All Models\n",
    "results = {\n",
    "    \"Vegas Line\": evaluate(y_true, y_vegas),\n",
    "    \"XGBoost Residual\": evaluate(y_true, y_pred_xgb),\n",
    "    \"Random Forest\": evaluate(y_true, y_pred_rf),\n",
    "    \"Neural Network\": evaluate(y_true, y_pred_mlp),\n",
    "    \"LightGBM\": evaluate(y_true, y_pred_lgbm),\n",
    "    \"Elastic Net\": evaluate(y_true, y_pred_enet),\n",
    "}\n",
    "\n",
    "## Create Comparison Dataframe\n",
    "summary = pd.DataFrame(results, index=[\"MAE\", \"RMSE\", \"RÂ²\"]).T\n",
    "summary[\"Î” MAE vs Vegas\"] = summary[\"MAE\"] - summary.loc[\"Vegas Line\", \"MAE\"]\n",
    "summary[\"Î” RMSE vs Vegas\"] = summary[\"RMSE\"] - summary.loc[\"Vegas Line\", \"RMSE\"]\n",
    "\n",
    "# Sort by MAE (best first)\n",
    "summary = summary.sort_values(\"MAE\")\n",
    "\n",
    "print(\"SECOND HALF TOTALS - MODEL COMPARISON\")\n",
    "print(summary.to_string(float_format=lambda x: f\"{x:0.3f}\"))\n",
    "\n",
    "## Save Comparison\n",
    "summary.to_csv('model_comparison.csv')\n",
    "print(\"\\nSaved: model_comparison.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddc0fc4",
   "metadata": {},
   "source": [
    "In the next cell we identify our worst predictions which were: King vs Lakers (3 OT), two more double OT games, a 3pt shooting slug fest in regulation, and another OT game. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0afbd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Failure Analysis - Identify Worst Predictions\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## Load Predictions\n",
    "results = pd.read_csv(\"test_predictions_residual.csv\")\n",
    "\n",
    "## Calculate Absolute Errors\n",
    "results['abs_error'] = abs(results['actual_second_half_total'] - results['predicted_total'])\n",
    "\n",
    "## Get Top 20 Worst Predictions (before deduping to ensure we get enough unique games)\n",
    "worst_games = results.nlargest(40, 'abs_error').copy()\n",
    "\n",
    "# Remove duplicate games (keep first occurrence)\n",
    "worst_games = worst_games.drop_duplicates(subset='GAME_ID', keep='first')\n",
    "\n",
    "# Take top 20 unique games\n",
    "worst_games = worst_games.head(20)\n",
    "\n",
    "# Select relevant columns for analysis\n",
    "analysis_cols = [\n",
    "    'GAME_ID', 'GAME_DATE', 'MATCHUP', 'TEAM_ID', 'season',\n",
    "    'actual_second_half_total', 'predicted_total', 'abs_error',\n",
    "    'h2_total', 'edge_vs_vegas',\n",
    "    'halftime_total', 'halftime_lead_abs',\n",
    "    'current_fh_pts', 'opp_current_fh_pts'\n",
    "]\n",
    "\n",
    "# Check which columns exist\n",
    "available_cols = [col for col in analysis_cols if col in worst_games.columns]\n",
    "worst_display = worst_games[available_cols].copy()\n",
    "\n",
    "## Display Results\n",
    "print(\"\\nTop 20 worst predictions\")\n",
    "print(worst_display.to_string(index=False, float_format=lambda x: f\"{x:.1f}\"))\n",
    "\n",
    "## Summary Statistics\n",
    "print(\"\\nFailure analysis summary\")\n",
    "print(f\"Mean error (worst 20): {worst_display['abs_error'].mean():.2f} points\")\n",
    "print(f\"Median error (worst 20): {worst_display['abs_error'].median():.2f} points\")\n",
    "print(f\"Max error: {worst_display['abs_error'].max():.2f} points\")\n",
    "\n",
    "if 'halftime_total' in worst_display.columns:\n",
    "    print(f\"Median halftime total (failures): {worst_display['halftime_total'].median():.1f}\")\n",
    "if 'halftime_lead_abs' in worst_display.columns:\n",
    "    print(f\"Median halftime lead (failures): {worst_display['halftime_lead_abs'].median():.1f}\")\n",
    "if 'edge_vs_vegas' in worst_display.columns:\n",
    "    print(f\"Mean edge vs Vegas (failures): {worst_display['edge_vs_vegas'].mean():.2f}\")\n",
    "\n",
    "## Save for Investigation\n",
    "worst_display.to_csv('worst_predictions_analysis.csv', index=False)\n",
    "print(\"\\nSaved to 'worst_predictions_analysis.csv'\")\n",
    "\n",
    "## Top 5 Games for Manual Investigation\n",
    "print(\"\\nTop 5 games to investigate\")\n",
    "\n",
    "for idx, row in worst_display.head(5).iterrows():\n",
    "    matchup_str = f\" {row['MATCHUP']}\" if 'MATCHUP' in row else \"\"\n",
    "    print(f\"\\n[Game {row['GAME_ID']}] {row['GAME_DATE']} |{matchup_str}\")\n",
    "    \n",
    "    if 'current_fh_pts' in row and 'opp_current_fh_pts' in row:\n",
    "        print(f\"  Halftime Score: {row['current_fh_pts']:.0f} - {row['opp_current_fh_pts']:.0f} (Total: {row['halftime_total']:.0f})\")\n",
    "    \n",
    "    print(f\"  Predicted 2H Total: {row['predicted_total']:.1f}\")\n",
    "    print(f\"  Actual 2H Total: {row['actual_second_half_total']:.1f}\")\n",
    "    print(f\"  Prediction Error: {row['abs_error']:.1f} points\")\n",
    "    \n",
    "    if 'h2_total' in row and 'edge_vs_vegas' in row:\n",
    "        print(f\"  Vegas Line: {row['h2_total']:.1f} | Our Edge: {row['edge_vs_vegas']:.2f}\")\n",
    "    \n",
    "    print(f\"  Search: 'NBA {row['GAME_DATE']} {matchup_str.strip()} box score'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4037c132",
   "metadata": {},
   "source": [
    "In this next cell we perform PCA and Clustering. PCA proves to work and capture variance most likely because our features are derirvatives of counting statistics. Clustering proves not to work well indicated by the silhouettes and the visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9ce12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Unsupervised Learning\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "## Load Training Data\n",
    "df = pd.read_csv(\"train_data.csv\")\n",
    "df[\"GAME_DATE\"] = pd.to_datetime(df[\"GAME_DATE\"])\n",
    "\n",
    "## Define Columns\n",
    "metadata_cols = [\"GAME_ID\", \"GAME_DATE\", \"TEAM_ID\", \"season\"]\n",
    "target_col = \"actual_second_half_total\"\n",
    "betting_col = \"h2_total\"\n",
    "\n",
    "drop_cols = set(metadata_cols + [target_col, betting_col])\n",
    "feature_cols = [c for c in df.columns if c not in drop_cols]\n",
    "\n",
    "X = df[feature_cols].copy()\n",
    "\n",
    "\n",
    "## Impute missing values\n",
    "missing = X.isna().sum().sum()\n",
    "if missing > 0:\n",
    "    for c in feature_cols:\n",
    "        if X[c].isna().any():\n",
    "            X[c].fillna(X[c].median(), inplace=True)\n",
    "else:\n",
    "    print(\"No imputing necessary\")\n",
    "\n",
    "\n",
    "## Scale and Apply PCA\n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "n_components = min(30, X_scaled.shape[1])\n",
    "pca = PCA(n_components=n_components, svd_solver=\"auto\", random_state=42)\n",
    "X_pcs = pca.fit_transform(X_scaled)\n",
    "\n",
    "explained = pca.explained_variance_ratio_.cumsum()\n",
    "var_99 = np.argmax(explained >= 0.99) + 1 if (explained >= 0.99).any() else n_components\n",
    "\n",
    "print(f\"\\nPCA components: {n_components}\")\n",
    "print(f\"Explained variance (first 5 PCs cumulative): {explained[:5]}\")\n",
    "print(f\"Components to reach ~99% variance: {var_99}\")\n",
    "\n",
    "\n",
    "## K-Means Clustering\n",
    "best = {\"k\": None, \"score\": -1, \"model\": None, \"labels\": None}\n",
    "for k in [6, 8, 10, 12]:\n",
    "    km = KMeans(n_clusters=k, n_init=20, max_iter=500, random_state=42)\n",
    "    labels = km.fit_predict(X_pcs)\n",
    "    score = silhouette_score(X_pcs, labels) if len(np.unique(labels)) > 1 else -1\n",
    "    print(f\"k={k:2d} -> silhouette: {score:.4f}\")\n",
    "\n",
    "    if score > best[\"score\"] or (score == best[\"score\"] and k < best[\"k\"]):\n",
    "        best = {\"k\": k, \"score\": score, \"model\": km, \"labels\": labels}\n",
    "\n",
    "k_best = best[\"k\"]\n",
    "kmeans = best[\"model\"]\n",
    "labels = best[\"labels\"]\n",
    "print(f\"\\nSelected k={k_best} (silhouette={best['score']:.4f})\")\n",
    "\n",
    "\n",
    "## Construct Cluster Output\n",
    "pc_cols = [f\"PC{i+1}\" for i in range(X_pcs.shape[1])]\n",
    "out = df[[\"GAME_ID\", \"GAME_DATE\", \"TEAM_ID\", \"season\"]].copy()\n",
    "for i, col in enumerate(pc_cols):\n",
    "    out[col] = X_pcs[:, i]\n",
    "out[\"cluster_id\"] = labels\n",
    "\n",
    "if target_col in df.columns:\n",
    "    out[target_col] = df[target_col].values\n",
    "if betting_col in df.columns:\n",
    "    out[betting_col] = df[betting_col].values\n",
    "    if target_col in df.columns:\n",
    "        out[\"edge_vs_line\"] = out[target_col] - out[betting_col]\n",
    "\n",
    "out.to_csv(\"pca_kmeans_train.csv\", index=False)\n",
    "print(\"Saved pca_kmeans_train.csv\")\n",
    "\n",
    "\n",
    "## Save Unsupervised Models\n",
    "joblib.dump(scaler, \"unsup_scaler.pkl\")\n",
    "joblib.dump(pca, \"unsup_pca.pkl\")\n",
    "joblib.dump(kmeans, \"unsup_kmeans.pkl\")\n",
    "print(\"Saved: unsup_scaler.pkl, unsup_pca.pkl, unsup_kmeans.pkl\")\n",
    "\n",
    "## Visualization\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "scatter = plt.scatter(X_pcs[:, 0], X_pcs[:, 1], c=labels, cmap='viridis', \n",
    "                        alpha=0.5, s=30, edgecolors='none')\n",
    "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)')\n",
    "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)')\n",
    "plt.title(f'K-Means Clustering in PCA Space (k={k_best}, silhouette={best[\"score\"]:.3f})')\n",
    "plt.colorbar(scatter, label='Cluster ID')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('cluster_visualization.png', dpi=300, bbox_inches='tight')\n",
    "print(\"Saved cluster_visualization.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89555ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## K-Means Evaluation - Silhouette and Inertia Analysis\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Compute silhouette and inertia for multiple k values\n",
    "K_range = [6, 8, 10, 12]\n",
    "silhouette_scores = []\n",
    "inertias = []\n",
    "\n",
    "for k in K_range:\n",
    "    km = KMeans(n_clusters=k, n_init=20, max_iter=500, random_state=42)\n",
    "    labels = km.fit_predict(X_pcs)\n",
    "    silhouette_scores.append(silhouette_score(X_pcs, labels))\n",
    "    inertias.append(km.inertia_)\n",
    "\n",
    "# Print Inertia scores\n",
    "print(\"K-Means Evaluation Results\")\n",
    "print(f\"{'k':<5}{'Silhouette Score':<20}{'Inertia':<15}\")\n",
    "for k, sil, inert in zip(K_range, silhouette_scores, inertias):\n",
    "    print(f\"{k:<5}{sil:<20.5f}{inert:<15.2f}\")\n",
    "\n",
    "# Plot both metrics on dual y-axes\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax1.set_xlabel(\"Number of Clusters (k)\")\n",
    "ax1.set_ylabel(\"Silhouette Score\", color=\"blue\")\n",
    "ax1.plot(K_range, silhouette_scores, marker=\"o\", color=\"blue\", linewidth=2, label=\"Silhouette Score\")\n",
    "ax1.tick_params(axis=\"y\", labelcolor=\"blue\")\n",
    "ax1.axvline(10, color=\"red\", linestyle=\"--\", alpha=0.7, label=\"Selected k=10\")\n",
    "\n",
    "# Second axis for inertia\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel(\"Cluster Compactness (Inertia)\", color=\"orange\")\n",
    "ax2.plot(K_range, inertias, marker=\"s\", color=\"orange\", linewidth=2, label=\"Inertia\")\n",
    "ax2.tick_params(axis=\"y\", labelcolor=\"orange\")\n",
    "\n",
    "# Title and layout\n",
    "plt.title(\"Silhouette Score and Inertia vs Number of Clusters (K-Means on PCA Features)\")\n",
    "fig.tight_layout()\n",
    "\n",
    "# Add legends\n",
    "ax1.legend(loc=\"lower left\")\n",
    "ax2.legend(loc=\"lower right\")\n",
    "\n",
    "plt.savefig(\"silhouette_inertia_analysis.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08eabf0e",
   "metadata": {},
   "source": [
    " PCA performing well is not surprising so many of the features we created were derivatives of stats that are already present. So it makes sense that PCA was able to compress these down into 30 features, there might only be 30 features that observe different qualities of an NBA game from the dataset.\n",
    "\n",
    " Cluster doees not seem to add much of anything. The silhouettes were incredibly small. We think this makes sense because the NBA is a multi-billion dollar industry and it makes sense that its converged similar team composition, style of play, and game outcomes.  Yes there is innovation and variance but teams are incentivized so heavily to win that we do not actually see these innovations completely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e5406c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## XGBoost Residual Model with PCA Features\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "## Load Data\n",
    "train = pd.read_csv(\"train_data.csv\")\n",
    "test = pd.read_csv(\"test_data.csv\")\n",
    "\n",
    "# Format Data\n",
    "for df in (train, test):\n",
    "    if 'GAME_DATE' in df.columns:\n",
    "        df['GAME_DATE'] = pd.to_datetime(df['GAME_DATE'], errors='coerce')\n",
    "\n",
    "## Define Columns\n",
    "metadata_cols = [\"GAME_ID\", \"GAME_DATE\", \"TEAM_ID\", \"season\"]\n",
    "target_col = \"actual_second_half_total\"\n",
    "vegas_col = \"h2_total\"\n",
    "\n",
    "feature_cols = [c for c in train.columns if c not in (metadata_cols + [target_col])]\n",
    "\n",
    "X_train = train[feature_cols].copy()\n",
    "X_test = test[feature_cols].copy()\n",
    "\n",
    "y_train_total = train[target_col].values\n",
    "y_test_total = test[target_col].values\n",
    "\n",
    "y_train = (train[target_col] - train[vegas_col]).values\n",
    "y_test = (test[target_col]  - test[vegas_col]).values\n",
    "\n",
    "\n",
    "## Impute Missing Values\n",
    "medians = X_train.median(numeric_only=True)\n",
    "X_train = X_train.fillna(medians)\n",
    "X_test = X_test.fillna(medians)\n",
    "\n",
    "\n",
    "## Apply PCA (fit fresh or load from disk)\n",
    "use_saved = False\n",
    "scaler_path = \"unsup_scaler.pkl\"\n",
    "pca_path = \"unsup_pca.pkl\"\n",
    "\n",
    "if os.path.exists(scaler_path) and os.path.exists(pca_path):\n",
    "    scaler = joblib.load(scaler_path)\n",
    "    pca    = joblib.load(pca_path)\n",
    "    # Verify feature count matches\n",
    "    try:\n",
    "        if hasattr(scaler, \"n_features_in_\") and scaler.n_features_in_ == X_train.shape[1]:\n",
    "            use_saved = True\n",
    "    except Exception:\n",
    "        use_saved = False\n",
    "\n",
    "if use_saved:\n",
    "    print(\"\\nUsing saved scaler & PCA (unsup_scaler.pkl / unsup_pca.pkl)\")\n",
    "else:\n",
    "    print(\"Falling back to recreating scale and pca\")\n",
    "\n",
    "    scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    \n",
    "    # Choose components: keep up to 99% variance, cap at 50 to be safe\n",
    "    pca_full = PCA(svd_solver=\"auto\", random_state=42)\n",
    "    pca_full.fit(X_train_scaled)\n",
    "    cumsum = np.cumsum(pca_full.explained_variance_ratio_)\n",
    "    n_comp = int(np.searchsorted(cumsum, 0.99) + 1)\n",
    "    n_comp = min(max(n_comp, 10), 50)  # between 10 and 50\n",
    "    print(f\"Selected PCA components: {n_comp} (â‰ˆ99% variance)\")\n",
    "\n",
    "    pca = PCA(n_components=n_comp, svd_solver=\"auto\", random_state=42)\n",
    "    # Re-fit with chosen n_components\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    pca.fit(X_train_scaled)\n",
    "\n",
    "    # Save for reuse next time\n",
    "    joblib.dump(scaler, scaler_path)\n",
    "    joblib.dump(pca, pca_path)\n",
    "    print(\"Saved new unsup_scaler.pkl and unsup_pca.pkl\")\n",
    "\n",
    "# Transform using the scaler/PCA in use (saved or fresh)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_pca = pca.transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "print(f\"\\nPCA features shape -> train: {X_train_pca.shape}, test: {X_test_pca.shape}\")\n",
    "\n",
    "\n",
    "## Train Model\n",
    "model = xgb.XGBRegressor(\n",
    "    n_estimators=1800,\n",
    "    learning_rate=0.018,\n",
    "    max_depth=8,\n",
    "    min_child_weight=1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.75,\n",
    "    gamma=0.05,\n",
    "    reg_alpha=0.2,\n",
    "    reg_lambda=0.6,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    early_stopping_rounds=120,\n",
    "    eval_metric='rmse'\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train_pca, y_train,\n",
    "    eval_set=[(X_train_pca, y_train), (X_test_pca, y_test)],\n",
    "    verbose=50\n",
    ")\n",
    "\n",
    "## Evaluate Residual Performance\n",
    "y_pred_resid = model.predict(X_test_pca)\n",
    "\n",
    "mae_resid = mean_absolute_error(y_test, y_pred_resid)\n",
    "rmse_resid = np.sqrt(mean_squared_error(y_test, y_pred_resid))\n",
    "r2_resid = r2_score(y_test, y_pred_resid)\n",
    "\n",
    "print(\"\\nXGBoost Residual Metrics:\")\n",
    "print(f\"MAE:  {mae_resid:.3f} pts\")\n",
    "print(f\"RMSE: {rmse_resid:.3f} pts\")\n",
    "print(f\"RÂ²:   {r2_resid:.3f}\")\n",
    "\n",
    "\n",
    "## Reconstruct Full Totals\n",
    "y_pred_total = y_pred_resid + test[vegas_col].values\n",
    "mae_total = mean_absolute_error(y_test_total, y_pred_total)\n",
    "rmse_total = np.sqrt(mean_squared_error(y_test_total, y_pred_total))\n",
    "r2_total = r2_score(y_test_total, y_pred_total)\n",
    "\n",
    "## Vegas Baseline\n",
    "mae_line = mean_absolute_error(y_test_total, test[vegas_col].values)\n",
    "rmse_line = np.sqrt(mean_squared_error(y_test_total, test[vegas_col].values))\n",
    "r2_line = r2_score(y_test_total, test[vegas_col].values)\n",
    "\n",
    "print(\"\\nFull Total Performance:\")\n",
    "print(f\"Vegas Line     MAE: {mae_vegas:.3f} | RMSE: {rmse_vegas:.3f} | RÂ²: {r2_vegas:.3f}\")\n",
    "print(f\"XGBoost + PCA  MAE: {mae_total:.3f} | RMSE: {rmse_total:.3f} | RÂ²: {r2_total:.3f}\")\n",
    "print(f\"Î” MAE:  {mae_total - mae_vegas:+.3f}\")\n",
    "print(f\"Î” RMSE: {rmse_total - rmse_vegas:+.3f}\")\n",
    "\n",
    "## Save Predictions\n",
    "test_out = test.copy()\n",
    "test_out[\"predicted_residual_pca\"] = y_pred_resid\n",
    "test_out[\"predicted_total_pca\"] = y_pred_total\n",
    "test_out[\"edge_vs_vegas_pca\"] = y_pred_resid\n",
    "test_out[\"abs_error_pca\"] = np.abs(y_test_total - y_pred_total)\n",
    "\n",
    "test_out.to_csv(\"test_predictions_residual_pca.csv\", index=False)\n",
    "model.save_model(\"xgboost_residual_pca.json\")\n",
    "\n",
    "# Save another feature list\n",
    "with open(\"pca_feature_cols.json\", \"w\") as f:\n",
    "    json.dump(feature_cols, f, indent=2)\n",
    "\n",
    "print(\"Saved test_predictions_residual_pca.csv\")\n",
    "print(\"Saved xgboost_residual_pca.json\")\n",
    "print(\"Saved pca_feature_cols.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6038943c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predict Holdouts\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "# Loading Model\n",
    "model = xgb.XGBRegressor()\n",
    "model.load_model(\"xgboost_residual_model.json\")\n",
    "\n",
    "\n",
    "## Load Data\n",
    "holdout_data = pd.read_csv(\"holdout_data.csv\")\n",
    "print(f\"Holdout: {len(holdout_data)} rows\")\n",
    "\n",
    "## Define Columns\n",
    "metadata_cols = [\"GAME_ID\", \"GAME_DATE\", \"TEAM_ID\", \"season\"]\n",
    "target_col = \"actual_second_half_total\"\n",
    "vegas_col = \"h2_total\"\n",
    "\n",
    "feature_cols = [c for c in holdout_data.columns if c not in metadata_cols + [target_col]]\n",
    "X_holdout = holdout_data[feature_cols].copy()\n",
    "\n",
    "\n",
    "## Impute missing values\n",
    "for col in X_holdout.columns:\n",
    "    if X_holdout[col].isnull().any():\n",
    "        X_holdout[col].fillna(X_holdout[col].median(), inplace=True)\n",
    "\n",
    "\n",
    "## Predict\n",
    "predicted_residuals = model.predict(X_holdout)\n",
    "\n",
    "holdout_data[\"predicted_residual\"] = predicted_residuals\n",
    "holdout_data[\"predicted_total\"] = predicted_residuals + holdout_data[vegas_col]\n",
    "holdout_data[\"bet_edge\"] = predicted_residuals\n",
    "\n",
    "\n",
    "## Save Full Holdout Dataset\n",
    "holdout_data.to_csv(\"holdout_predictions.csv\", index=False)\n",
    "print(f\"Saved holdout_predictions.csv\")\n",
    "\n",
    "\n",
    "## Clean Holdout Dataset\n",
    "clean_predictions = holdout_data[[\n",
    "    'GAME_ID',\n",
    "    'GAME_DATE',\n",
    "    'TEAM_ID',\n",
    "    'h2_total',\n",
    "    'predicted_total',\n",
    "    'actual_second_half_total',\n",
    "    'bet_edge'\n",
    "]].copy()\n",
    "\n",
    "# Format dates\n",
    "clean_predictions['GAME_DATE'] = pd.to_datetime(clean_predictions['GAME_DATE']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Rename columns\n",
    "clean_predictions.columns = [\n",
    "    'game_id',\n",
    "    'date',\n",
    "    'team_id',\n",
    "    'h2_total',\n",
    "    'predicted_total',\n",
    "    'actual_total',\n",
    "    'bet_edge'\n",
    "]\n",
    "\n",
    "# Sort by date\n",
    "clean_predictions = clean_predictions.sort_values('date')\n",
    "\n",
    "\n",
    "## Save clean (two rows per game - home and away teams)\n",
    "clean_predictions.to_csv('holdout_predictions_clean.csv', index=False)\n",
    "print(f\"Saved holdout_predictions_clean.csv\")\n",
    "\n",
    "# Save game-level (one row per game)\n",
    "game_level = clean_predictions.drop_duplicates('game_id').copy()\n",
    "game_level.to_csv('holdout_predictions_games.csv', index=False)\n",
    "print(f\"Saved holdout_predictions_games.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40147338",
   "metadata": {},
   "source": [
    "Using the XGBoost Resid model to predict holdouts for more validation and. Then building code to rapidly test which thresholds (difference between our prediction and vegas) to see what bets are best to take. It settles on a threshold of 1.25, however its important to note that with 110 betting odds we lose money on all strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f56721",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Optimize Betting Thresholds (ROI)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "## Load Data\n",
    "holdout_data = pd.read_csv(\"holdout_predictions_games.csv\")\n",
    "\n",
    "\n",
    "## Filter to Games with Valid Lines + Totals\n",
    "bettable = holdout_data[\n",
    "    (holdout_data[\"h2_total\"].notna()) &\n",
    "    (holdout_data[\"actual_total\"].notna())\n",
    "].copy()\n",
    "\n",
    "\n",
    "## Prepare Values\n",
    "bet_edge = bettable[\"bet_edge\"].values\n",
    "actual_total = bettable[\"actual_total\"].values  # Changed\n",
    "vegas_line = bettable[\"h2_total\"].values\n",
    "\n",
    "## Run Threshold Sweep in .25 increments\n",
    "results = []\n",
    "thresholds = np.arange(0.5, 7.25, 0.25)\n",
    "\n",
    "for threshold in thresholds:\n",
    "    # Filtering bets\n",
    "    bet_over = bet_edge > threshold\n",
    "    bet_under = bet_edge < -threshold\n",
    "    \n",
    "    # Count bets\n",
    "    over_count = bet_over.sum()\n",
    "    under_count = bet_under.sum()\n",
    "    total_bets = over_count + under_count\n",
    "    \n",
    "    if total_bets == 0:\n",
    "        continue\n",
    "    \n",
    "    # Calculate wins\n",
    "    over_wins = ((actual_total > vegas_line) & bet_over).sum()\n",
    "    under_wins = ((actual_total < vegas_line) & bet_under).sum()\n",
    "    total_wins = over_wins + under_wins\n",
    "    \n",
    "    # Win rates\n",
    "    over_win_rate = over_wins / over_count * 100 if over_count > 0 else 0\n",
    "    under_win_rate = under_wins / under_count * 100 if under_count > 0 else 0\n",
    "    total_win_rate = total_wins / total_bets * 100\n",
    "    \n",
    "    # Profit with 110 odds\n",
    "    over_profit = (over_wins * 100) - ((over_count - over_wins) * 110)\n",
    "    under_profit = (under_wins * 100) - ((under_count - under_wins) * 110)\n",
    "    total_profit = over_profit + under_profit\n",
    "    \n",
    "    # ROI\n",
    "    total_risked = total_bets * 110\n",
    "    roi = (total_profit / total_risked * 100) if total_risked > 0 else 0\n",
    "    \n",
    "    results.append({\n",
    "        'threshold': threshold,\n",
    "        'total_bets': total_bets,\n",
    "        'over_bets': over_count,\n",
    "        'under_bets': under_count,\n",
    "        'total_wins': total_wins,\n",
    "        'over_wins': over_wins,\n",
    "        'under_wins': under_wins,\n",
    "        'win_rate': total_win_rate,\n",
    "        'over_win_rate': over_win_rate,\n",
    "        'under_win_rate': under_win_rate,\n",
    "        'profit': total_profit,\n",
    "        'roi': roi\n",
    "    })\n",
    "\n",
    "## Save and Print Top Results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "top_roi = results_df.nlargest(10, 'roi')\n",
    "print(top_roi[['threshold', 'total_bets', 'win_rate', 'profit', 'roi']].to_string(index=False))\n",
    "\n",
    "results_df.to_csv('threshold_optimization_results.csv', index=False)\n",
    "print(f\"Saved threshold_optimization_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
