{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed08001c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Collection - NBA Games (2021-2024)\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from nba_api.stats.endpoints import leaguegamelog\n",
    "from nba_api.stats.endpoints import leaguegamefinder\n",
    "from nba_api.stats.static import teams\n",
    "\n",
    "## Fetch 2023-24 Season\n",
    "print(\"Fetching 2023-24 season...\")\n",
    "games_finder_24 = leaguegamefinder.LeagueGameFinder(\n",
    "    season_nullable='2023-24',\n",
    "    timeout=120\n",
    ")\n",
    "games_24 = games_finder_24.get_data_frames()[0]\n",
    "print(f\"2023-24: {len(games_24)} records\")\n",
    "time.sleep(2)\n",
    "\n",
    "## Get 2022-23 season\n",
    "print(\"Fetching 2022-23 season...\")\n",
    "games_finder_23 = leaguegamefinder.LeagueGameFinder(\n",
    "    season_nullable='2022-23',\n",
    "    timeout=120\n",
    ")\n",
    "games_23 = games_finder_23.get_data_frames()[0]\n",
    "print(f\"2022-23: {len(games_23)} records\")\n",
    "time.sleep(2)\n",
    "\n",
    "## Get 2021-22 season\n",
    "print(\"Fetching 2021-22 season...\")\n",
    "games_finder_22 = leaguegamefinder.LeagueGameFinder(\n",
    "    season_nullable='2021-22',\n",
    "    timeout=120\n",
    ")\n",
    "games_22 = games_finder_22.get_data_frames()[0]\n",
    "print(f\"2021-22: {len(games_22)} records\")\n",
    "time.sleep(2)\n",
    "\n",
    "## Get 2020-21 season\n",
    "print(\"Fetching 2020-21 season...\")\n",
    "games_finder_21 = leaguegamefinder.LeagueGameFinder(\n",
    "    season_nullable='2020-21',\n",
    "    timeout=120\n",
    ")\n",
    "games_21 = games_finder_21.get_data_frames()[0]\n",
    "print(f\"2020-21: {len(games_21)} records\")\n",
    "\n",
    "## Combine All Seasons\n",
    "all_games = pd.concat([games_21, games_22, games_23, games_24], ignore_index=True)\n",
    "print(f\"\\nTotal combined records: {len(all_games)}\")\n",
    "\n",
    "# Get unique game IDs sorted\n",
    "unique_game_ids = sorted(all_games['GAME_ID'].dropna().unique())  # There are NAs to drop\n",
    "print(f\"Unique games: {len(unique_game_ids)}\")\n",
    "\n",
    "## Save to CSV\n",
    "all_games.to_csv('nba_games_2021_to_2024.csv', index=False)\n",
    "print(\"Written to 'nba_games_2021_to_2024.csv'\")\n",
    "\n",
    "# Save unique game IDs separately\n",
    "game_ids_df = pd.DataFrame({'GAME_ID': unique_game_ids})\n",
    "game_ids_df['GAME_ID'] = game_ids_df['GAME_ID'].astype(str)\n",
    "game_ids_df.to_csv('unique_game_ids.csv', index=False)\n",
    "print(\"Written unique game IDs to 'unique_game_ids.csv'\")\n",
    "\n",
    "## Summary\n",
    "print(f\"\\nTotal records: {len(all_games)}\")\n",
    "print(f\"Unique games: {len(unique_game_ids)}\")\n",
    "print(f\"First game ID: {unique_game_ids[0]}\")\n",
    "print(f\"Last game ID: {unique_game_ids[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71c3cac",
   "metadata": {},
   "source": [
    "With the NBA API it was a trial and error process to pull data. It did not seem like there was a definitive reason why data was not pulling. So we built a script that would simply run multiple passes over a unique games list and try to get a complete set of data. This proved to be successful. Even testing different sleep times proved to be unsuccessful.\n",
    "\n",
    "Basically we were collecting two sets of data one was from \"boxscoretraditionalv2\" which gave team and player stats. We needed to collect a set for the first half and the complete game this would give us a complete picture of the data so we could predict a second half point total. We also used \"boxscoresummaryv2\" to collect game times, referees, injuries, points by qtr. It would basically pull a list of 7 tables, the multiple pass code was neccesarily for this as it seemed to fail to pull more often. In addition we had to patch this API pull to code in 'GAME_ID' for a couple of the tables that did not have it present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42255892",
   "metadata": {},
   "outputs": [],
   "source": [
    "## First Half Box Score Data - Multi-Pass Version\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "from nba_api.stats.endpoints import boxscoretraditionalv2\n",
    "\n",
    "## Configuration\n",
    "PASS_NUMBER = 3\n",
    "INPUT_FILE = 'unique_game_ids.csv' if PASS_NUMBER == 1 else f'failed_game_ids_fh_pass{PASS_NUMBER-1}.csv'\n",
    "OUTPUT_SUFFIX = '' if PASS_NUMBER == 1 else f'_pt{PASS_NUMBER}'\n",
    "\n",
    "\n",
    "## Load Game IDs\n",
    "game_ids_df = pd.read_csv(INPUT_FILE, dtype={'GAME_ID': str})\n",
    "game_ids_list = game_ids_df['GAME_ID'].tolist()\n",
    "\n",
    "print(f\"=== PASS {PASS_NUMBER} ===\")\n",
    "print(f\"Total games to process: {len(game_ids_list)}\")\n",
    "print(f\"First game ID: {game_ids_list[0]}\")\n",
    "print(f\"Last game ID: {game_ids_list[-1]}\")\n",
    "\n",
    "\n",
    "## Initialize Data Collection\n",
    "all_fh_player_stats = []\n",
    "all_fh_team_stats = []\n",
    "all_fh_starter_bench = []\n",
    "\n",
    "# Track progress\n",
    "games_processed = 0\n",
    "games_failed = 0\n",
    "start_time = time.time()\n",
    "failed_game_ids = []\n",
    "\n",
    "\n",
    "## First Half Loop\n",
    "for idx, game_id in enumerate(game_ids_list):\n",
    "    try:\n",
    "        # Call API\n",
    "        fh = boxscoretraditionalv2.BoxScoreTraditionalV2(\n",
    "            game_id=game_id,\n",
    "            range_type=1,\n",
    "            start_period=1,\n",
    "            end_period=2\n",
    "        )\n",
    "        \n",
    "        # Convert to dataframes\n",
    "        dfs = fh.get_data_frames()\n",
    "        \n",
    "        # Append\n",
    "        all_fh_player_stats.append(dfs[0])\n",
    "        all_fh_team_stats.append(dfs[1])\n",
    "        all_fh_starter_bench.append(dfs[2])\n",
    "        \n",
    "        # Track process\n",
    "        games_processed += 1\n",
    "        \n",
    "        # Progress update every 1000 games\n",
    "        if (idx + 1) % 1000 == 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print(f\"Progress: {idx + 1}/{len(game_ids_list)} games ({games_processed} success, {games_failed} failed) - {elapsed/60:.1f} min elapsed\")\n",
    "        \n",
    "        time.sleep(0.5)\n",
    "        \n",
    "    except Exception as e:\n",
    "        games_failed += 1\n",
    "        failed_game_ids.append(game_id)\n",
    "        \n",
    "        # Print at 1st failure and every 50\n",
    "        if games_failed == 1 or games_failed % 50 == 0:\n",
    "            print(f\"Failures: {games_failed}\")\n",
    "        continue\n",
    "\n",
    "\n",
    "## Combine and Save\n",
    "if all_fh_player_stats:\n",
    "    fh_players_combined = pd.concat(all_fh_player_stats, ignore_index=True)\n",
    "    fh_teams_combined = pd.concat(all_fh_team_stats, ignore_index=True)\n",
    "    fh_starters_bench_combined = pd.concat(all_fh_starter_bench, ignore_index=True)\n",
    "    \n",
    "    # Save with suffix\n",
    "    fh_players_combined.to_csv(f'first_half_players{OUTPUT_SUFFIX}.csv', index=False)\n",
    "    fh_teams_combined.to_csv(f'first_half_teams{OUTPUT_SUFFIX}.csv', index=False)\n",
    "    fh_starters_bench_combined.to_csv(f'first_half_starters_bench{OUTPUT_SUFFIX}.csv', index=False)\n",
    "    \n",
    "    print(f\"\\nSuccessfully processed: {games_processed}\")\n",
    "    print(f\"Player records: {len(fh_players_combined)}\")\n",
    "    print(f\"Team records: {len(fh_teams_combined)}\")\n",
    "else:\n",
    "    print(\"\\nNo data collected - all games failed\")\n",
    "\n",
    "\n",
    "# Save failed game IDs\n",
    "if failed_game_ids:\n",
    "    failed_df = pd.DataFrame({'GAME_ID': failed_game_ids})\n",
    "    failed_df.to_csv(f'failed_game_ids_fh_pass{PASS_NUMBER}.csv', index=False)\n",
    "    print(f\"\\nFailed game IDs saved to 'failed_game_ids_fh_pass{PASS_NUMBER}.csv'\")\n",
    "    print(f\"Failed games: {len(failed_game_ids)}\")\n",
    "    print(f\"\\nTo run pass {PASS_NUMBER + 1}:\")\n",
    "else:\n",
    "    print(f\"\\n All games successful - no need for pass {PASS_NUMBER + 1}!\")\n",
    "\n",
    "\n",
    "## Final Summary\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"\\n=== PASS {PASS_NUMBER} COMPLETE ===\")\n",
    "print(f\"Successfully processed: {games_processed}/{len(game_ids_list)}\")\n",
    "print(f\"Failed: {games_failed}/{len(game_ids_list)}\")\n",
    "print(f\"Total time: {elapsed/60:.1f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84affc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Box Score Summary Data - Multi-Pass Auto-Loop Version\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "from nba_api.stats.endpoints import boxscoresummaryv2\n",
    "\n",
    "\n",
    "## Configuration\n",
    "MAX_PASSES = 15\n",
    "INITIAL_INPUT_FILE = 'unique_game_ids.csv'\n",
    "\n",
    "\n",
    "## Auto-Loop Through Passes\n",
    "for pass_num in range(1, MAX_PASSES + 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"=== STARTING PASS {pass_num} ===\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Determine input file\n",
    "    if pass_num == 1:\n",
    "        input_file = INITIAL_INPUT_FILE\n",
    "    else:\n",
    "        input_file = f'failed_game_ids_bss_pass{pass_num-1}.csv'\n",
    "        \n",
    "        # Check if there are failures to process\n",
    "        if not os.path.exists(input_file):\n",
    "            print(f\"No failures from pass {pass_num-1} - All done!\")\n",
    "            break\n",
    "    \n",
    "    # Loading Game IDs\n",
    "    game_ids_df = pd.read_csv(input_file, dtype={'GAME_ID': str})\n",
    "    game_ids_list = game_ids_df['GAME_ID'].tolist()\n",
    "    \n",
    "    # Output suffix\n",
    "    output_suffix = '' if pass_num == 1 else f'_pt{pass_num}'\n",
    "    \n",
    "    print(f\"Total games to process: {len(game_ids_list)}\")\n",
    "    print(f\"First game ID: {game_ids_list[0]}\")\n",
    "    print(f\"Last game ID: {game_ids_list[-1]}\")\n",
    "    \n",
    "    \n",
    "    ## Data Collection\n",
    "    all_game_summary = []\n",
    "    all_team_stats = []\n",
    "    all_refs = []\n",
    "    all_inactive = []\n",
    "    all_game_info = []\n",
    "    all_points_by_qtr = []\n",
    "    all_last_meeting = []\n",
    "    \n",
    "    # Track progress\n",
    "    games_processed = 0\n",
    "    games_failed = 0\n",
    "    start_time = time.time()\n",
    "    failed_game_ids = []\n",
    "    \n",
    "    \n",
    "    ## Loop through games\n",
    "    for idx, game_id in enumerate(game_ids_list):\n",
    "        try:\n",
    "            # Call API\n",
    "            summary = boxscoresummaryv2.BoxScoreSummaryV2(game_id=game_id)\n",
    "            \n",
    "            # Get all dataframes\n",
    "            dfs = summary.get_data_frames()\n",
    "            \n",
    "            # Add GAME_ID to each dataframe if missing\n",
    "            for i in range(7):  # Only process 0-6, skip 7-8\n",
    "                if 'GAME_ID' not in dfs[i].columns:\n",
    "                    dfs[i]['GAME_ID'] = game_id\n",
    "            \n",
    "            # Append only the ones we want (0-6, drop 7-8)\n",
    "            all_game_summary.append(dfs[0])\n",
    "            all_team_stats.append(dfs[1])\n",
    "            all_refs.append(dfs[2])\n",
    "            all_inactive.append(dfs[3])\n",
    "            all_game_info.append(dfs[4])\n",
    "            all_points_by_qtr.append(dfs[5])\n",
    "            all_last_meeting.append(dfs[6])\n",
    "            \n",
    "            games_processed += 1\n",
    "            \n",
    "            # Progress Update every 1000 games\n",
    "            if (idx + 1) % 1000 == 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                print(f\"Progress: {idx + 1}/{len(game_ids_list)} games ({games_processed} success, {games_failed} failed) - {elapsed/60:.1f} min elapsed\")\n",
    "            \n",
    "            time.sleep(0.5)\n",
    "            \n",
    "        except Exception as e:\n",
    "            games_failed += 1\n",
    "            failed_game_ids.append(game_id)\n",
    "            if games_failed == 1 or games_failed % 50 == 0:\n",
    "                print(f\"Failures: {games_failed}\")\n",
    "            continue\n",
    "    \n",
    "    ## Combine and Save\n",
    "    if all_game_summary:\n",
    "        game_summary_combined = pd.concat(all_game_summary, ignore_index=True)\n",
    "        team_stats_combined = pd.concat(all_team_stats, ignore_index=True)\n",
    "        refs_combined = pd.concat(all_refs, ignore_index=True)\n",
    "        inactive_combined = pd.concat(all_inactive, ignore_index=True)\n",
    "        game_info_combined = pd.concat(all_game_info, ignore_index=True)\n",
    "        points_qtr_combined = pd.concat(all_points_by_qtr, ignore_index=True)\n",
    "        last_meeting_combined = pd.concat(all_last_meeting, ignore_index=True)\n",
    "        \n",
    "        # Save with suffix\n",
    "        game_summary_combined.to_csv(f'game_summary{output_suffix}.csv', index=False)\n",
    "        team_stats_combined.to_csv(f'team_stats{output_suffix}.csv', index=False)\n",
    "        refs_combined.to_csv(f'refs{output_suffix}.csv', index=False)\n",
    "        inactive_combined.to_csv(f'inactive_players{output_suffix}.csv', index=False)\n",
    "        game_info_combined.to_csv(f'game_info{output_suffix}.csv', index=False)\n",
    "        points_qtr_combined.to_csv(f'points_by_quarter{output_suffix}.csv', index=False)\n",
    "        last_meeting_combined.to_csv(f'last_meeting{output_suffix}.csv', index=False)\n",
    "        \n",
    "        print(f\"\\nPass {pass_num} data saved!\")\n",
    "        print(f\"Successfully processed: {games_processed}\")\n",
    "    else:\n",
    "        print(f\"\\nPass {pass_num}: No data collected - all games failed\")\n",
    "    \n",
    "    \n",
    "    ## Save Failed Game IDs\n",
    "    if failed_game_ids:\n",
    "        failed_df = pd.DataFrame({'GAME_ID': failed_game_ids})\n",
    "        failed_df.to_csv(f'failed_game_ids_bss_pass{pass_num}.csv', index=False)\n",
    "        print(f\"Failed game IDs saved to 'failed_game_ids_bss_pass{pass_num}.csv'\")\n",
    "        print(f\"Failed games: {len(failed_game_ids)}\")\n",
    "    else:\n",
    "        print(f\"Pass {pass_num}: All games successful!\")\n",
    "    \n",
    "    \n",
    "    ## Pass Summary\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\n=== PASS {pass_num} COMPLETE ===\")\n",
    "    print(f\"Successfully processed: {games_processed}/{len(game_ids_list)}\")\n",
    "    print(f\"Failed: {games_failed}/{len(game_ids_list)}\")\n",
    "    print(f\"Total time: {elapsed/60:.1f} minutes\")\n",
    "    \n",
    "    # Check if we should continue to next pass\n",
    "    if not failed_game_ids:\n",
    "        print(f\"\\nAll games processed successfully! No need for more passes.\")\n",
    "        break\n",
    "    elif pass_num < MAX_PASSES:\n",
    "        print(f\"\\nWill attempt pass {pass_num + 1} with {len(failed_game_ids)} failed games...\")\n",
    "        time.sleep(5)  # Brief pause between passes\n",
    "    else:\n",
    "        print(f\"\\nReached maximum passes ({MAX_PASSES}). {len(failed_game_ids)} games still failed.\")\n",
    "\n",
    "print(\"\\n=== ALL PASSES COMPLETE ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd268331",
   "metadata": {},
   "source": [
    "This next cell block is code to concatenate all the various pass files together. This could have been more elegant but I hard coded the amount of passes I had for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028dbed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Concatenate Multi-Pass Files\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "## Initialize Storage\n",
    "combined_data = {}\n",
    "\n",
    "\n",
    "## First Half Files (3 Passes)\n",
    "fh_files = [\n",
    "    ('first_half_players', 3),\n",
    "    ('first_half_teams', 3),\n",
    "    ('first_half_starters_bench', 3)\n",
    "]\n",
    "\n",
    "for base_name, num_passes in fh_files:\n",
    "    all_dfs = []\n",
    "    \n",
    "    for pass_num in range(1, num_passes + 1):\n",
    "        if pass_num == 1:\n",
    "            filename = f'{base_name}.csv'\n",
    "        else:\n",
    "            filename = f'{base_name}_pt{pass_num}.csv'\n",
    "        \n",
    "        if os.path.exists(filename):\n",
    "            df = pd.read_csv(filename)\n",
    "            all_dfs.append(df)\n",
    "            print(f\" Loaded {filename}: {len(df)} records\")\n",
    "        else:\n",
    "            print(f\"{filename} not found, skipping\")\n",
    "    \n",
    "    if all_dfs:\n",
    "        combined = pd.concat(all_dfs, ignore_index=True)\n",
    "        combined_data[base_name] = combined\n",
    "        print(f\"Combined {base_name}: {len(combined)} total records\\n\")\n",
    "\n",
    "\n",
    "## Complete Game Files (5 Passes)\n",
    "cg_files = [\n",
    "    ('complete_game_players', 5),\n",
    "    ('complete_game_teams', 5),\n",
    "    ('complete_game_starters_bench', 5)\n",
    "]\n",
    "\n",
    "for base_name, num_passes in cg_files:\n",
    "    all_dfs = []\n",
    "    \n",
    "    for pass_num in range(1, num_passes + 1):\n",
    "        if pass_num == 1:\n",
    "            filename = f'{base_name}.csv'\n",
    "        else:\n",
    "            filename = f'{base_name}_pt{pass_num}.csv'\n",
    "        \n",
    "        if os.path.exists(filename):\n",
    "            df = pd.read_csv(filename)\n",
    "            all_dfs.append(df)\n",
    "            print(f\"Loaded {filename}: {len(df)} records\")\n",
    "        else:\n",
    "            print(f\"{filename} not found, skipping\")\n",
    "    \n",
    "    if all_dfs:\n",
    "        combined = pd.concat(all_dfs, ignore_index=True)\n",
    "        combined_data[base_name] = combined\n",
    "        print(f\"Combined {base_name}: {len(combined)} total records\\n\")\n",
    "\n",
    "\n",
    "## Box Score Summary Files (9 Passes)\n",
    "bss_files = [\n",
    "    ('game_summary', 9),\n",
    "    ('team_stats', 9),\n",
    "    ('refs', 9),\n",
    "    ('inactive_players', 9),\n",
    "    ('game_info', 9),\n",
    "    ('points_by_quarter', 9),\n",
    "    ('last_meeting', 9)\n",
    "]\n",
    "\n",
    "for base_name, num_passes in bss_files:\n",
    "    all_dfs = []\n",
    "    \n",
    "    for pass_num in range(1, num_passes + 1):\n",
    "        if pass_num == 1:\n",
    "            filename = f'{base_name}.csv'\n",
    "        else:\n",
    "            filename = f'{base_name}_pt{pass_num}.csv'\n",
    "        \n",
    "        if os.path.exists(filename):\n",
    "            df = pd.read_csv(filename)\n",
    "            all_dfs.append(df)\n",
    "            print(f\"Loaded {filename}: {len(df)} records\")\n",
    "        else:\n",
    "            print(f\"{filename} not found, skipping\")\n",
    "    \n",
    "    if all_dfs:\n",
    "        combined = pd.concat(all_dfs, ignore_index=True)\n",
    "        combined_data[base_name] = combined\n",
    "        print(f\"  ðŸ“Š Combined {base_name}: {len(combined)} total records\\n\")\n",
    "\n",
    "## Save All Combined Files\n",
    "print(\"SAVING COMBINED FILES\")\n",
    "\n",
    "for name, df in combined_data.items():\n",
    "    output_filename = f'{name}_COMBINED.csv'\n",
    "    df.to_csv(output_filename, index=False)\n",
    "    print(f\"Saved {output_filename}: {len(df)} records\")\n",
    "\n",
    "print(f\"\\nAll files combined and saved!\")\n",
    "print(f\"Total combined datasets: {len(combined_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda6081a",
   "metadata": {},
   "source": [
    "This next cell block does a quick pass to check if we have a complete dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254500da",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check for Missing Games in Combined Datasets\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "## Load Original Game IDs\n",
    "original_game_ids = pd.read_csv('unique_game_ids.csv', dtype={'GAME_ID': str})\n",
    "total_games = len(original_game_ids)\n",
    "all_game_ids = set(original_game_ids['GAME_ID'].tolist())\n",
    "\n",
    "print(f\"Total games expected: {total_games}\")\n",
    "print(f\"First game ID: {original_game_ids['GAME_ID'].iloc[0]}\")\n",
    "print(f\"Last game ID: {original_game_ids['GAME_ID'].iloc[-1]}\")\n",
    "\n",
    "\n",
    "## Track Coverage by Dataset\n",
    "coverage_report = {}\n",
    "\n",
    "\n",
    "## Check First Half Datasets\n",
    "print(\"\\nFirst Half Datasets\")\n",
    "\n",
    "fh_files = [\n",
    "    'first_half_players_COMBINED.csv',\n",
    "    'first_half_teams_COMBINED.csv',\n",
    "    'first_half_starters_bench_COMBINED.csv'\n",
    "]\n",
    "\n",
    "for filename in fh_files:\n",
    "    if os.path.exists(filename):\n",
    "        df = pd.read_csv(filename)\n",
    "        if 'GAME_ID' in df.columns:\n",
    "            unique_games = df['GAME_ID'].nunique()\n",
    "            game_ids_in_file = set(df['GAME_ID'].dropna().astype(str).unique())\n",
    "            missing_games = all_game_ids - game_ids_in_file\n",
    "            coverage_pct = (unique_games / total_games) * 100\n",
    "            \n",
    "            coverage_report[filename] = {\n",
    "                'games_found': unique_games,\n",
    "                'missing_count': len(missing_games),\n",
    "                'coverage_pct': coverage_pct,\n",
    "                'missing_ids': sorted(missing_games)\n",
    "            }\n",
    "            \n",
    "            print(f\"  {filename}:\")\n",
    "            print(f\"    Games found: {unique_games}/{total_games} ({coverage_pct:.1f}%)\")\n",
    "            print(f\"    Missing: {len(missing_games)}\")\n",
    "        else:\n",
    "            print(f\"{filename}: No GAME_ID column found\")\n",
    "    else:\n",
    "        print(f\"{filename} not found\")\n",
    "\n",
    "\n",
    "## Check Complete Game Datasets\n",
    "print(\"\\nComplete Game Datasets\")\n",
    "\n",
    "cg_files = [\n",
    "    'complete_game_players_COMBINED.csv',\n",
    "    'complete_game_teams_COMBINED.csv',\n",
    "    'complete_game_starters_bench_COMBINED.csv'\n",
    "]\n",
    "\n",
    "for filename in cg_files:\n",
    "    if os.path.exists(filename):\n",
    "        df = pd.read_csv(filename)\n",
    "        if 'GAME_ID' in df.columns:\n",
    "            unique_games = df['GAME_ID'].nunique()\n",
    "            game_ids_in_file = set(df['GAME_ID'].dropna().astype(str).unique())\n",
    "            missing_games = all_game_ids - game_ids_in_file\n",
    "            coverage_pct = (unique_games / total_games) * 100\n",
    "            \n",
    "            coverage_report[filename] = {\n",
    "                'games_found': unique_games,\n",
    "                'missing_count': len(missing_games),\n",
    "                'coverage_pct': coverage_pct,\n",
    "                'missing_ids': sorted(missing_games)\n",
    "            }\n",
    "            \n",
    "            print(f\"{filename}:\")\n",
    "            print(f\"Games found: {unique_games}/{total_games} ({coverage_pct:.1f}%)\")\n",
    "            print(f\"Missing: {len(missing_games)}\")\n",
    "        else:\n",
    "            print(f\"{filename}: No GAME_ID column found\")\n",
    "    else:\n",
    "        print(f\"{filename} not found\")\n",
    "\n",
    "\n",
    "## Check Box Score Summary Datasets\n",
    "print(\"\\nBox Score Summary Datasets\")\n",
    "\n",
    "bss_files = [\n",
    "    'game_summary_COMBINED.csv',\n",
    "    'team_stats_COMBINED.csv',\n",
    "    'refs_COMBINED.csv',\n",
    "    'inactive_players_COMBINED.csv',\n",
    "    'game_info_COMBINED.csv',\n",
    "    'points_by_quarter_COMBINED.csv',\n",
    "    'last_meeting_COMBINED.csv'\n",
    "]\n",
    "\n",
    "for filename in bss_files:\n",
    "    if os.path.exists(filename):\n",
    "        df = pd.read_csv(filename)\n",
    "        if 'GAME_ID' in df.columns:\n",
    "            unique_games = df['GAME_ID'].nunique()\n",
    "            game_ids_in_file = set(df['GAME_ID'].dropna().astype(str).unique())\n",
    "            missing_games = all_game_ids - game_ids_in_file\n",
    "            coverage_pct = (unique_games / total_games) * 100\n",
    "            \n",
    "            coverage_report[filename] = {\n",
    "                'games_found': unique_games,\n",
    "                'missing_count': len(missing_games),\n",
    "                'coverage_pct': coverage_pct,\n",
    "                'missing_ids': sorted(missing_games)\n",
    "            }\n",
    "            \n",
    "            print(f\"{filename}:\")\n",
    "            print(f\"Games found: {unique_games}/{total_games} ({coverage_pct:.1f}%)\")\n",
    "            print(f\"Missing: {len(missing_games)}\")\n",
    "        else:\n",
    "            print(f\"{filename}: No GAME_ID column found\")\n",
    "    else:\n",
    "        print(f\"{filename} not found\")\n",
    "\n",
    "\n",
    "## Summary Report\n",
    "print(\"\\nSummary\")\n",
    "print(f\"Total expected games: {total_games}\")\n",
    "\n",
    "if coverage_report:\n",
    "    best_coverage = max(coverage_report.items(), key=lambda x: x[1]['coverage_pct'])\n",
    "    worst_coverage = min(coverage_report.items(), key=lambda x: x[1]['coverage_pct'])\n",
    "    \n",
    "    print(f\"\\nBest coverage: {best_coverage[0]}\")\n",
    "    print(f\"  {best_coverage[1]['games_found']}/{total_games} ({best_coverage[1]['coverage_pct']:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nWorst coverage: {worst_coverage[0]}\")\n",
    "    print(f\"  {worst_coverage[1]['games_found']}/{total_games} ({worst_coverage[1]['coverage_pct']:.1f}%)\")\n",
    "    \n",
    "    # Find games missing from all datasets\n",
    "    all_missing = set.intersection(*[set(v['missing_ids']) for v in coverage_report.values()])\n",
    "    \n",
    "    if all_missing:\n",
    "        print(f\"\\nGames missing from ALL datasets: {len(all_missing)}\")\n",
    "        print(f\"Sample missing IDs: {list(all_missing)[:10]}\")\n",
    "        \n",
    "        # Save to CSV\n",
    "        missing_df = pd.DataFrame({'GAME_ID': sorted(all_missing)})\n",
    "        missing_df.to_csv('games_missing_from_all_datasets.csv', index=False)\n",
    "        print(f\" Saved to 'games_missing_from_all_datasets.csv'\")\n",
    "    else:\n",
    "        print(f\"\\nNo games are missing from ALL datasets!\")\n",
    "        print(\"(Some datasets may have missing games, but coverage varies)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b368816b",
   "metadata": {},
   "source": [
    "Upon inspecting that data we had thoughts about pulling more specific player information but this was incredibly cumbersome with the API since we would have to make individual pulls on each PLAYER_ID. In thinking about it more it did not make sense to go through the trouble since we want the model to generalize well since we're using an old dataset and players move teams, players retire, and new players arrive.\n",
    "\n",
    "The next cell block is for feature engineering. It is a bit of a mess and desperately needs to be refactored. We added more code snippets to add more features to the datasets. The need for more opponent features created another nested loop which felt easier at the time but simply kept growing it would have been better to replace it with a function. Also the dataset got to be over 1,000 columns and I added some redundant columns because I forgot which ones were already there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486e4672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Configuration\n",
    "time_windows = [7, 14, 30] # 1 week, 2 week, and 1 month rolling snapshots\n",
    "player_groups = [1, 2, 3, 4, 5, 6, 7, 'rest'] #top 7 of the rotation averages and lump sum for rest of team\n",
    "\n",
    "# Stats to average\n",
    "player_stats_avg = ['PTS', 'FGM', 'FGA', 'FG3M', 'FG3A', 'FTM', 'FTA',\n",
    "                    'OREB', 'DREB', 'REB', 'AST', 'STL', 'BLK', 'TO', 'PF', 'PLUS_MINUS']\n",
    "player_stats_total = ['MIN']\n",
    "\n",
    "# Team Complete Game\n",
    "team_stats_avg_cg = ['PTS', 'FGM', 'FGA', 'FG3M', 'FG3A', 'FTM', 'FTA',\n",
    "                    'OREB', 'DREB', 'REB', 'AST', 'STL', 'BLK', 'TO', 'PF', 'PLUS_MINUS']\n",
    "team_stats_total_cg = ['MIN']\n",
    "\n",
    "# Team First Half\n",
    "team_stats_avg_fh = ['PTS', 'FGM', 'FGA', 'FG3M', 'FG3A', 'FTM', 'FTA',\n",
    "                    'OREB', 'DREB', 'REB', 'AST', 'STL', 'BLK', 'TO', 'PF', 'PLUS_MINUS']\n",
    "team_stats_total_fh = ['MIN']\n",
    "\n",
    "# Load our data\n",
    "cg_players = pd.read_csv('complete_game_players_COMBINED.csv')\n",
    "cg_teams = pd.read_csv('complete_game_teams_COMBINED.csv')\n",
    "fh_players = pd.read_csv('first_half_players_COMBINED.csv')\n",
    "fh_teams = pd.read_csv('first_half_teams_COMBINED.csv')\n",
    "games_master = pd.read_csv('nba_games_2021_to_2024.csv')\n",
    "game_summary = pd.read_csv('game_summary_COMBINED.csv')\n",
    "refs = pd.read_csv('refs_COMBINED.csv')\n",
    "last_meeting = pd.read_csv('last_meeting_COMBINED.csv')\n",
    "\n",
    "# Cast numeric for the above\n",
    "for col in player_stats_avg + player_stats_total:\n",
    "    if col in cg_players.columns:\n",
    "        cg_players[col] = pd.to_numeric(cg_players[col], errors='coerce')\n",
    "        fh_players[col] = pd.to_numeric(fh_players[col], errors='coerce')\n",
    "\n",
    "for col in team_stats_avg + team_stats_total:\n",
    "    if col in cg_teams.columns:\n",
    "        cg_teams[col] = pd.to_numeric(cg_teams[col], errors='coerce')\n",
    "        fh_teams[col] = pd.to_numeric(fh_teams[col], errors='coerce')\n",
    "\n",
    "# Format Dates\n",
    "games_master['GAME_DATE'] = pd.to_datetime(games_master['GAME_DATE'])\n",
    "last_meeting['LAST_GAME_DATE_EST'] = pd.to_datetime(last_meeting['LAST_GAME_DATE_EST'], errors='coerce')\n",
    "\n",
    "\n",
    "# Creating an index with unique game_id and date\n",
    "game_date_map = games_master[['GAME_ID', 'GAME_DATE']].drop_duplicates('GAME_ID').set_index('GAME_ID')['GAME_DATE']\n",
    "\n",
    "# Apply it\n",
    "for df in [cg_players, fh_players, cg_teams, fh_teams]:\n",
    "    df['GAME_DATE'] = df['GAME_ID'].map(game_date_map)\n",
    "\n",
    "## Computing Second-Half Stats since we pulled first half and complete game\n",
    "# Merge Key\n",
    "cg_teams['merge_key'] = cg_teams['GAME_ID'].astype(str) + '_' + cg_teams['TEAM_ID'].astype(str)\n",
    "fh_teams['merge_key'] = fh_teams['GAME_ID'].astype(str) + '_' + fh_teams['TEAM_ID'].astype(str)\n",
    "\n",
    "# Merge Alignment\n",
    "merged = cg_teams.merge(\n",
    "    fh_teams[['merge_key', 'PTS', 'FGM', 'FGA', 'FG3M', 'FG3A', 'FTM', 'FTA', 'REB', 'AST', 'TO', 'STL', 'BLK']], \n",
    "    on='merge_key', \n",
    "    how='left',\n",
    "    suffixes=('', '_fh')\n",
    ")\n",
    "\n",
    "# Second-half stats to compute\n",
    "second_half_stats = ['PTS', 'FGM', 'FGA', 'FG3M', 'FG3A', 'FTM', 'FTA', 'REB', 'AST', 'TO', 'STL', 'BLK']\n",
    "\n",
    "# Quick diff for counting stats\n",
    "for stat in second_half_stats:\n",
    "    cg_teams[f'second_half_{stat}'] = merged[stat] - merged[f'{stat}_fh']\n",
    "\n",
    "# Calculate percentage stats\n",
    "cg_teams['second_half_FG_PCT'] = np.where(\n",
    "    cg_teams['second_half_FGA'] > 0,\n",
    "    cg_teams['second_half_FGM'] / cg_teams['second_half_FGA'],\n",
    "    np.nan\n",
    ")\n",
    "cg_teams['second_half_FG3_PCT'] = np.where(\n",
    "    cg_teams['second_half_FG3A'] > 0,\n",
    "    cg_teams['second_half_FG3M'] / cg_teams['second_half_FG3A'],\n",
    "    np.nan\n",
    ")\n",
    "cg_teams['second_half_FT_PCT'] = np.where(\n",
    "    cg_teams['second_half_FTA'] > 0,\n",
    "    cg_teams['second_half_FTM'] / cg_teams['second_half_FTA'],\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "# Kill merge key since its unnessary now\n",
    "cg_teams.drop('merge_key', axis=1, inplace=True)\n",
    "fh_teams.drop('merge_key', axis=1, inplace=True)\n",
    "\n",
    "# Add it to the stats list\n",
    "team_stats_avg_cg.extend([f'second_half_{stat}' for stat in second_half_stats])\n",
    "team_stats_avg_cg.extend(['second_half_FG_PCT', 'second_half_FG3_PCT', 'second_half_FT_PCT'])\n",
    "\n",
    "## Players\n",
    "# Lasso stats into time windows\n",
    "def calculate_player_time_features(player_df, game_id, game_date, player_id, team_id, days):\n",
    "    window_start = game_date - pd.Timedelta(days=days)\n",
    "    \n",
    "    player_games = player_df[\n",
    "        (player_df['PLAYER_ID'] == player_id) &\n",
    "        (player_df['TEAM_ID'] == team_id) &\n",
    "        (player_df['GAME_DATE'] >= window_start) &\n",
    "        (player_df['GAME_DATE'] < game_date) &\n",
    "        (player_df['GAME_ID'] != game_id)\n",
    "    ].copy()\n",
    "    \n",
    "    # Excludes inactivity\n",
    "    if len(player_games) == 0:\n",
    "        base_features = {stat: np.nan for stat in player_stats_total + player_stats_avg}\n",
    "        base_features['FG_PCT'] = np.nan\n",
    "        base_features['FG3_PCT'] = np.nan\n",
    "        base_features['FT_PCT'] = np.nan\n",
    "        return base_features\n",
    "    \n",
    "    features = {}\n",
    "    \n",
    "    # Sum counting stats for percentages later\n",
    "    for stat in player_stats_total:\n",
    "        features[stat] = player_games[stat].sum()\n",
    "        \n",
    "    # Averages for features\n",
    "    for stat in player_stats_avg:\n",
    "        features[stat] = player_games[stat].mean()\n",
    "    \n",
    "    # Calculate percentages from underlying counting stats instead of averaging percentages\n",
    "    total_fgm = player_games['FGM'].sum()\n",
    "    total_fga = player_games['FGA'].sum()\n",
    "    total_fg3m = player_games['FG3M'].sum()\n",
    "    total_fg3a = player_games['FG3A'].sum()\n",
    "    total_ftm = player_games['FTM'].sum()\n",
    "    total_fta = player_games['FTA'].sum()\n",
    "    \n",
    "    features['FG_PCT'] = total_fgm / total_fga if total_fga > 0 else np.nan\n",
    "    features['FG3_PCT'] = total_fg3m / total_fg3a if total_fg3a > 0 else np.nan\n",
    "    features['FT_PCT'] = total_ftm / total_fta if total_fta > 0 else np.nan\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Ranking our top players, which is done on a 30 day basis\n",
    "# 30 day basis will show dropoffs of top players.\n",
    "def get_team_top_players(player_df, game_id, game_date, team_id):\n",
    "    window_start = game_date - pd.Timedelta(days=30)\n",
    "    \n",
    "    team_players = player_df[\n",
    "        (player_df['TEAM_ID'] == team_id) &\n",
    "        (player_df['GAME_DATE'] >= window_start) &\n",
    "        (player_df['GAME_DATE'] < game_date) &\n",
    "        (player_df['GAME_ID'] != game_id)\n",
    "    ].copy()\n",
    "    \n",
    "    # Excludes inactivity\n",
    "    if len(team_players) == 0:\n",
    "        return []\n",
    "    \n",
    "    player_minutes = team_players.groupby('PLAYER_ID')['MIN'].sum().sort_values(ascending=False)\n",
    "    return player_minutes.index.tolist()\n",
    "\n",
    "## Teamwide\n",
    "# Lasso stats into time windows\n",
    "def calculate_team_time_features(team_df, game_id, game_date, team_id, days, stats_avg, stats_total):\n",
    "    window_start = game_date - pd.Timedelta(days=days)\n",
    "    \n",
    "    team_games = team_df[\n",
    "        (team_df['TEAM_ID'] == team_id) &\n",
    "        (team_df['GAME_DATE'] >= window_start) &\n",
    "        (team_df['GAME_DATE'] < game_date) &\n",
    "        (team_df['GAME_ID'] != game_id)\n",
    "    ].copy()\n",
    "    \n",
    "    if len(team_games) == 0:\n",
    "        base_features = {stat: np.nan for stat in stats_total + stats_avg}  # Changed\n",
    "        base_features['FG_PCT'] = np.nan\n",
    "        base_features['FG3_PCT'] = np.nan\n",
    "        base_features['FT_PCT'] = np.nan\n",
    "        base_features['WIN_PCT'] = np.nan\n",
    "        return base_features\n",
    "    \n",
    "    features = {}\n",
    "    \n",
    "    # Sum totals\n",
    "    for stat in stats_total:  # Changed\n",
    "        features[stat] = team_games[stat].sum()\n",
    "    \n",
    "    # Average the averages (including second-half stats for CG only)\n",
    "    for stat in stats_avg:  # Changed\n",
    "        features[stat] = team_games[stat].mean()\n",
    "    \n",
    "    # Calculate TRUE percentages from summed makes/attempts\n",
    "    total_fgm = team_games['FGM'].sum()\n",
    "    total_fga = team_games['FGA'].sum()\n",
    "    total_fg3m = team_games['FG3M'].sum()\n",
    "    total_fg3a = team_games['FG3A'].sum()\n",
    "    total_ftm = team_games['FTM'].sum()\n",
    "    total_fta = team_games['FTA'].sum()\n",
    "    \n",
    "    features['FG_PCT'] = total_fgm / total_fga if total_fga > 0 else np.nan\n",
    "    features['FG3_PCT'] = total_fg3m / total_fg3a if total_fg3a > 0 else np.nan\n",
    "    features['FT_PCT'] = total_ftm / total_fta if total_fta > 0 else np.nan\n",
    "    \n",
    "    # Win percentage\n",
    "    team_game_ids = team_games['GAME_ID'].unique()\n",
    "    team_game_results = games_master[\n",
    "        (games_master['GAME_ID'].isin(team_game_ids)) &\n",
    "        (games_master['TEAM_ID'] == team_id)\n",
    "    ]\n",
    "    if len(team_game_results) > 0:\n",
    "        features['WIN_PCT'] = (team_game_results['WL'] == 'W').mean()\n",
    "    else:\n",
    "        features['WIN_PCT'] = np.nan\n",
    "    \n",
    "    return features\n",
    "\n",
    "## Functions for Schedule\n",
    "# Rest days, back-to-back games, and some general game density\n",
    "def calculate_schedule_features(games_master, game_id, game_date, team_id):\n",
    "    team_games = games_master[\n",
    "        (games_master['TEAM_ID'] == team_id) &\n",
    "        (games_master['GAME_DATE'] < game_date)\n",
    "    ].sort_values('GAME_DATE')\n",
    "    \n",
    "    features = {}\n",
    "    \n",
    "    if len(team_games) == 0:\n",
    "        features['days_since_last_game'] = np.nan\n",
    "        features['is_back_to_back'] = 0\n",
    "        features['games_in_last_3_days'] = 0\n",
    "        features['games_in_last_5_days'] = 0\n",
    "        features['games_in_last_7_days'] = 0\n",
    "    else:\n",
    "        # Here we compute last game and back to backs\n",
    "        last_game_date = team_games['GAME_DATE'].iloc[-1]\n",
    "        features['days_since_last_game'] = (game_date - last_game_date).days\n",
    "        features['is_back_to_back'] = 1 if features['days_since_last_game'] == 1 else 0\n",
    "        \n",
    "        # Game density\n",
    "        recent_games_3d = team_games[team_games['GAME_DATE'] >= game_date - pd.Timedelta(days=3)]\n",
    "        recent_games_5d = team_games[team_games['GAME_DATE'] >= game_date - pd.Timedelta(days=5)]\n",
    "        recent_games_7d = team_games[team_games['GAME_DATE'] >= game_date - pd.Timedelta(days=7)]\n",
    "        \n",
    "        features['games_in_last_3_days'] = len(recent_games_3d)\n",
    "        features['games_in_last_5_days'] = len(recent_games_5d)\n",
    "        features['games_in_last_7_days'] = len(recent_games_7d)\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Lets get home and road game lengths (streaks of home or away)\n",
    "def calculate_home_road_context(games_master, game_id, game_date, team_id):\n",
    "    team_games = games_master[\n",
    "        (games_master['TEAM_ID'] == team_id) &\n",
    "        (games_master['GAME_DATE'] < game_date)\n",
    "    ].sort_values('GAME_DATE')\n",
    "    \n",
    "    features = {}\n",
    "    \n",
    "    # Determine if current game is home\n",
    "    current_game = games_master[(games_master['GAME_ID'] == game_id) & (games_master['TEAM_ID'] == team_id)]\n",
    "    if len(current_game) > 0:\n",
    "        matchup = current_game['MATCHUP'].iloc[0]\n",
    "        features['is_home_game'] = 1 if 'vs.' in str(matchup) else 0 # vs and @ determined home vs away\n",
    "    else:\n",
    "        features['is_home_game'] = np.nan\n",
    "    \n",
    "    if len(team_games) == 0:\n",
    "        # First game of season - count as game #1\n",
    "        features['home_stand_game_number'] = 1 if features['is_home_game'] == 1 else 0\n",
    "        features['road_trip_game_number'] = 1 if features['is_home_game'] == 0 else 0\n",
    "        return features\n",
    "    \n",
    "    # Count consecutive home or road games (BEFORE current game)\n",
    "    consecutive_count = 0\n",
    "    \n",
    "    for _, game in team_games.iloc[::-1].iterrows():\n",
    "        matchup = str(game['MATCHUP'])\n",
    "        is_home = 1 if 'vs.' in matchup else 0\n",
    "        \n",
    "        # Check if this past game matches current game's location\n",
    "        if features['is_home_game'] == is_home:\n",
    "            consecutive_count += 1\n",
    "        else:\n",
    "            break  # Different arena, stop counting\n",
    "    \n",
    "    # Add 1 to include the CURRENT game\n",
    "    features['home_stand_game_number'] = consecutive_count + 1 if features['is_home_game'] == 1 else 0\n",
    "    features['road_trip_game_number'] = consecutive_count + 1 if features['is_home_game'] == 0 else 0\n",
    "    \n",
    "    return features\n",
    "\n",
    "## Record Features\n",
    "# Win and Loss streaks\n",
    "def calculate_streak_features(games_master, game_id, game_date, team_id, lookback_games=[3, 5, 10]):\n",
    "    team_games = games_master[\n",
    "        (games_master['TEAM_ID'] == team_id) &\n",
    "        (games_master['GAME_DATE'] < game_date)\n",
    "    ].sort_values('GAME_DATE')\n",
    "    \n",
    "    features = {}\n",
    "    \n",
    "    if len(team_games) == 0:\n",
    "        features['current_streak'] = 0\n",
    "        for n in lookback_games:\n",
    "            features[f'wins_last_{n}'] = np.nan\n",
    "        features['home_win_pct_last_10'] = np.nan\n",
    "        features['road_win_pct_last_10'] = np.nan\n",
    "        return features\n",
    "    \n",
    "    # Current streak (positive = wins, negative = losses)\n",
    "    recent_results = team_games['WL'].iloc[::-1].values\n",
    "    current_result = recent_results[0] if len(recent_results) > 0 else None\n",
    "    streak = 0\n",
    "    \n",
    "    for result in recent_results:\n",
    "        if result == current_result:\n",
    "            streak += 1\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    features['current_streak'] = streak if current_result == 'W' else -streak\n",
    "    \n",
    "    # Wins in last N games\n",
    "    for n in lookback_games:\n",
    "        last_n = team_games.tail(n)\n",
    "        if len(last_n) > 0:\n",
    "            features[f'wins_last_{n}'] = (last_n['WL'] == 'W').sum()\n",
    "        else:\n",
    "            features[f'wins_last_{n}'] = np.nan\n",
    "    \n",
    "    # Home/Road splits\n",
    "    last_10 = team_games.tail(10)\n",
    "    home_games = last_10[last_10['MATCHUP'].str.contains('vs.', na=False)]\n",
    "    road_games = last_10[last_10['MATCHUP'].str.contains('@', na=False)]\n",
    "    \n",
    "    features['home_win_pct_last_10'] = (home_games['WL'] == 'W').mean() if len(home_games) > 0 else np.nan\n",
    "    features['road_win_pct_last_10'] = (road_games['WL'] == 'W').mean() if len(road_games) > 0 else np.nan\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Head to head record calculations (Team matched against their Opponent)\n",
    "def calculate_head_to_head_features(games_master, last_meeting, game_id, game_date, team_id):\n",
    "    features = {}\n",
    "    \n",
    "    # Get opponent team_id for this game\n",
    "    game_teams = games_master[games_master['GAME_ID'] == game_id]['TEAM_ID'].unique()\n",
    "    opponent_id = [t for t in game_teams if t != team_id]\n",
    "    \n",
    "    if len(opponent_id) == 0:\n",
    "        features['days_since_last_matchup'] = np.nan\n",
    "        features['won_last_matchup'] = np.nan\n",
    "        features['point_diff_last_matchup'] = np.nan\n",
    "        features['season_record_vs_opponent'] = np.nan\n",
    "        return features\n",
    "    \n",
    "    opponent_id = opponent_id[0]\n",
    "    \n",
    "    # Last meeting info\n",
    "    last_mtg = last_meeting[last_meeting['GAME_ID'] == game_id]\n",
    "    if len(last_mtg) > 0 and pd.notna(last_mtg['LAST_GAME_DATE_EST'].iloc[0]):\n",
    "        last_game_date = last_mtg['LAST_GAME_DATE_EST'].iloc[0]\n",
    "        features['days_since_last_matchup'] = (game_date - last_game_date).days\n",
    "        \n",
    "        # Determine who won\n",
    "        home_pts = last_mtg['LAST_GAME_HOME_TEAM_POINTS'].iloc[0]\n",
    "        visitor_pts = last_mtg['LAST_GAME_VISITOR_TEAM_POINTS'].iloc[0]\n",
    "        home_team = last_mtg['LAST_GAME_HOME_TEAM_ID'].iloc[0]\n",
    "        \n",
    "        if home_team == team_id:\n",
    "            features['won_last_matchup'] = 1 if home_pts > visitor_pts else 0\n",
    "            features['point_diff_last_matchup'] = home_pts - visitor_pts\n",
    "        else:\n",
    "            features['won_last_matchup'] = 1 if visitor_pts > home_pts else 0\n",
    "            features['point_diff_last_matchup'] = visitor_pts - home_pts\n",
    "    else:\n",
    "        features['days_since_last_matchup'] = np.nan\n",
    "        features['won_last_matchup'] = np.nan\n",
    "        features['point_diff_last_matchup'] = np.nan\n",
    "    \n",
    "    # Season record vs opponent\n",
    "    season_games = games_master[\n",
    "        (games_master['TEAM_ID'] == team_id) &\n",
    "        (games_master['GAME_DATE'] < game_date)\n",
    "    ]\n",
    "    \n",
    "    # Find games against this opponent\n",
    "    opponent_game_ids = games_master[\n",
    "        (games_master['TEAM_ID'] == opponent_id)\n",
    "    ]['GAME_ID'].unique()\n",
    "    \n",
    "    matchup_games = season_games[season_games['GAME_ID'].isin(opponent_game_ids)]\n",
    "    \n",
    "    if len(matchup_games) > 0:\n",
    "        features['season_record_vs_opponent'] = (matchup_games['WL'] == 'W').sum()\n",
    "    else:\n",
    "        features['season_record_vs_opponent'] = 0\n",
    "    \n",
    "    return features\n",
    "\n",
    "## Referee Features -- basically a join\n",
    "def get_referee_ids(refs, game_id):\n",
    "    game_refs = refs[refs['GAME_ID'] == game_id].sort_values('JERSEY_NUM')\n",
    "    \n",
    "    ref_ids = [np.nan, np.nan, np.nan]\n",
    "    for i, (_, ref) in enumerate(game_refs.iterrows()):\n",
    "        if i < 3:\n",
    "            ref_ids[i] = ref['OFFICIAL_ID']\n",
    "    \n",
    "    return {\n",
    "        'ref_1_id': ref_ids[0],\n",
    "        'ref_2_id': ref_ids[1],\n",
    "        'ref_3_id': ref_ids[2]\n",
    "    }\n",
    "\n",
    "## Opponent features -- this is calculating features for the opponent\n",
    "def get_opponent_id(games_master, game_id, team_id):\n",
    "    \"\"\"Get the opponent team ID for this game\"\"\"\n",
    "    game_teams = games_master[games_master['GAME_ID'] == game_id]['TEAM_ID'].unique()\n",
    "    opponent_ids = [t for t in game_teams if t != team_id]\n",
    "    return opponent_ids[0] if len(opponent_ids) > 0 else None\n",
    "\n",
    "# Unique filter to make sure we are not counting duplicates\n",
    "unique_games = games_master[['GAME_ID', 'GAME_DATE', 'TEAM_ID']].drop_duplicates()\n",
    "unique_games = unique_games.sort_values('GAME_DATE')\n",
    "\n",
    "# Index Reset\n",
    "unique_games = unique_games.reset_index(drop=True)\n",
    "\n",
    "# Preparing to run it\n",
    "all_features = []\n",
    "\n",
    "# Looping over all games\n",
    "for idx, row in unique_games.iterrows():    \n",
    "    if idx % 500 == 0:\n",
    "        print(f\"Progress: {idx}/{len(unique_games)}\")\n",
    "    \n",
    "    game_id = row['GAME_ID']\n",
    "    game_date = row['GAME_DATE']\n",
    "    team_id = row['TEAM_ID']\n",
    "    \n",
    "    game_features = {\n",
    "        'GAME_ID': game_id,\n",
    "        'GAME_DATE': game_date,\n",
    "        'TEAM_ID': team_id\n",
    "    }\n",
    "    \n",
    "    # Player features\n",
    "    top_players_cg = get_team_top_players(cg_players, game_id, game_date, team_id)\n",
    "    top_players_fh = get_team_top_players(fh_players, game_id, game_date, team_id)\n",
    "    \n",
    "    for days in time_windows:\n",
    "        # Complete game players\n",
    "        for n in player_groups:\n",
    "            if n == 'rest':\n",
    "                players = top_players_cg[7:] if len(top_players_cg) > 7 else []\n",
    "            else:\n",
    "                players = top_players_cg[:n] if len(top_players_cg) >= n else []\n",
    "            \n",
    "            if len(players) == 0:\n",
    "                for stat in player_stats_total + player_stats_avg + ['FG_PCT', 'FG3_PCT', 'FT_PCT']:\n",
    "                    game_features[f'top{n}_cg_{stat.lower()}_{days}d'] = np.nan\n",
    "                continue\n",
    "            \n",
    "            player_features_list = [\n",
    "                calculate_player_time_features(cg_players, game_id, game_date, p, team_id, days)\n",
    "                for p in players\n",
    "            ]\n",
    "            \n",
    "            for stat in player_stats_total + player_stats_avg + ['FG_PCT', 'FG3_PCT', 'FT_PCT']:\n",
    "                values = [pf[stat] for pf in player_features_list if not pd.isna(pf[stat])]\n",
    "                game_features[f'top{n}_cg_{stat.lower()}_{days}d'] = np.mean(values) if values else np.nan\n",
    "        \n",
    "        # First half players\n",
    "        for n in player_groups:\n",
    "            if n == 'rest':\n",
    "                players = top_players_fh[7:] if len(top_players_fh) > 7 else []\n",
    "            else:\n",
    "                players = top_players_fh[:n] if len(top_players_fh) >= n else []\n",
    "            \n",
    "            if len(players) == 0:\n",
    "                for stat in player_stats_total + player_stats_avg + ['FG_PCT', 'FG3_PCT', 'FT_PCT']:\n",
    "                    game_features[f'top{n}_fh_{stat.lower()}_{days}d'] = np.nan\n",
    "                continue\n",
    "            \n",
    "            player_features_list = [\n",
    "                calculate_player_time_features(fh_players, game_id, game_date, p, team_id, days)\n",
    "                for p in players\n",
    "            ]\n",
    "            \n",
    "            for stat in player_stats_total + player_stats_avg + ['FG_PCT', 'FG3_PCT', 'FT_PCT']:\n",
    "                values = [pf[stat] for pf in player_features_list if not pd.isna(pf[stat])]\n",
    "                game_features[f'top{n}_fh_{stat.lower()}_{days}d'] = np.mean(values) if values else np.nan\n",
    "    \n",
    "    # Team features\n",
    "    for days in time_windows:\n",
    "    # Complete game with second-half stats\n",
    "        team_cg = calculate_team_time_features(cg_teams, game_id, game_date, team_id, days, \n",
    "                                                team_stats_avg_cg, team_stats_total_cg)\n",
    "        for stat, value in team_cg.items():\n",
    "            game_features[f'team_cg_{stat.lower()}_{days}d'] = value\n",
    "        \n",
    "        # First half WITHOUT second-half stats\n",
    "        team_fh = calculate_team_time_features(fh_teams, game_id, game_date, team_id, days,\n",
    "                                                team_stats_avg_fh, team_stats_total_fh)\n",
    "        for stat, value in team_fh.items():\n",
    "            game_features[f'team_fh_{stat.lower()}_{days}d'] = value\n",
    "    \n",
    "    # Schedule and Record Featurres\n",
    "    schedule_feats = calculate_schedule_features(games_master, game_id, game_date, team_id)\n",
    "    game_features.update(schedule_feats)\n",
    "    \n",
    "    home_road_feats = calculate_home_road_context(games_master, game_id, game_date, team_id)\n",
    "    game_features.update(home_road_feats)\n",
    "    \n",
    "    streak_feats = calculate_streak_features(games_master, game_id, game_date, team_id)\n",
    "    game_features.update(streak_feats)\n",
    "    \n",
    "    h2h_feats = calculate_head_to_head_features(games_master, last_meeting, game_id, game_date, team_id)\n",
    "    game_features.update(h2h_feats)\n",
    "    \n",
    "    # Ref features\n",
    "    ref_feats = get_referee_ids(refs, game_id)\n",
    "    game_features.update(ref_feats)\n",
    "    \n",
    "    # Current Game Stats columns\n",
    "    current_game_fh = fh_teams[\n",
    "        (fh_teams['GAME_ID'] == game_id) & \n",
    "        (fh_teams['TEAM_ID'] == team_id)\n",
    "    ]\n",
    "    \n",
    "    if len(current_game_fh) > 0:\n",
    "        game_features['current_fh_pts'] = current_game_fh['PTS'].iloc[0]\n",
    "        game_features['current_fh_fgm'] = current_game_fh['FGM'].iloc[0]\n",
    "        game_features['current_fh_fga'] = current_game_fh['FGA'].iloc[0]\n",
    "        game_features['current_fh_fg3m'] = current_game_fh['FG3M'].iloc[0]\n",
    "        game_features['current_fh_fg3a'] = current_game_fh['FG3A'].iloc[0]\n",
    "        game_features['current_fh_ftm'] = current_game_fh['FTM'].iloc[0]\n",
    "        game_features['current_fh_fta'] = current_game_fh['FTA'].iloc[0]\n",
    "        game_features['current_fh_reb'] = current_game_fh['REB'].iloc[0]\n",
    "        game_features['current_fh_ast'] = current_game_fh['AST'].iloc[0]\n",
    "        game_features['current_fh_to'] = current_game_fh['TO'].iloc[0]\n",
    "        game_features['current_fh_stl'] = current_game_fh['STL'].iloc[0]\n",
    "        game_features['current_fh_blk'] = current_game_fh['BLK'].iloc[0]\n",
    "        game_features['current_fh_pf'] = current_game_fh['PF'].iloc[0]\n",
    "        \n",
    "        # Calculate percentages and pace\n",
    "        fga = current_game_fh['FGA'].iloc[0]\n",
    "        fg3a = current_game_fh['FG3A'].iloc[0]\n",
    "        fta = current_game_fh['FTA'].iloc[0]\n",
    "        \n",
    "        game_features['current_fh_fg_pct'] = current_game_fh['FGM'].iloc[0] / fga if fga > 0 else np.nan\n",
    "        game_features['current_fh_fg3_pct'] = current_game_fh['FG3M'].iloc[0] / fg3a if fg3a > 0 else np.nan\n",
    "        game_features['current_fh_ft_pct'] = current_game_fh['FTM'].iloc[0] / fta if fta > 0 else np.nan\n",
    "        game_features['current_fh_pace'] = fga + current_game_fh['TO'].iloc[0]\n",
    "    else:\n",
    "        fh_stats = ['pts', 'fgm', 'fga', 'fg3m', 'fg3a', 'ftm', 'fta', 'reb', 'ast', 'to', \n",
    "                    'stl', 'blk', 'pf', 'fg_pct', 'fg3_pct', 'ft_pct', 'pace']\n",
    "        for stat in fh_stats:\n",
    "            game_features[f'current_fh_{stat}'] = np.nan\n",
    "\n",
    "    ## Opponnet Features\n",
    "    opponent_id = get_opponent_id(games_master, game_id, team_id)\n",
    "    \n",
    "    if opponent_id is not None:\n",
    "        # Opponent team features for each time window\n",
    "        for days in time_windows:\n",
    "            opp_team_cg = calculate_team_time_features(cg_teams, game_id, game_date, opponent_id, days,\n",
    "                                                        team_stats_avg_cg, team_stats_total_cg)\n",
    "            for stat, value in opp_team_cg.items():\n",
    "                game_features[f'opp_team_cg_{stat.lower()}_{days}d'] = value\n",
    "            \n",
    "            opp_team_fh = calculate_team_time_features(fh_teams, game_id, game_date, opponent_id, days,\n",
    "                                                        team_stats_avg_fh, team_stats_total_fh)\n",
    "            for stat, value in opp_team_fh.items():\n",
    "                game_features[f'opp_team_fh_{stat.lower()}_{days}d'] = value\n",
    "        \n",
    "        # Opponent schedule features\n",
    "        opp_schedule_feats = calculate_schedule_features(games_master, game_id, game_date, opponent_id)\n",
    "        for key, value in opp_schedule_feats.items():\n",
    "            game_features[f'opp_{key}'] = value\n",
    "        \n",
    "        # Opponent streak features\n",
    "        opp_streak_feats = calculate_streak_features(games_master, game_id, game_date, opponent_id)\n",
    "        for key, value in opp_streak_feats.items():\n",
    "            game_features[f'opp_{key}'] = value\n",
    "            \n",
    "        # Team vs Opponent Differentials\n",
    "        if not pd.isna(game_features.get('days_since_last_game')) and not pd.isna(game_features.get('opp_days_since_last_game')):\n",
    "            game_features['rest_advantage'] = game_features['days_since_last_game'] - game_features['opp_days_since_last_game']\n",
    "        else:\n",
    "            game_features['rest_advantage'] = np.nan\n",
    "        \n",
    "        # Win percentage differential\n",
    "        for days in time_windows:\n",
    "            team_win_pct = game_features.get(f'team_cg_win_pct_{days}d', np.nan)\n",
    "            opp_win_pct = game_features.get(f'opp_team_cg_win_pct_{days}d', np.nan)\n",
    "            if not pd.isna(team_win_pct) and not pd.isna(opp_win_pct):\n",
    "                game_features[f'win_pct_diff_{days}d'] = team_win_pct - opp_win_pct\n",
    "            else:\n",
    "                game_features[f'win_pct_diff_{days}d'] = np.nan\n",
    "        \n",
    "        # Recent form differential (wins in last 5)\n",
    "        team_wins_5 = game_features.get('wins_last_5', np.nan)\n",
    "        opp_wins_5 = game_features.get('opp_wins_last_5', np.nan)\n",
    "        if not pd.isna(team_wins_5) and not pd.isna(opp_wins_5):\n",
    "            game_features['recent_form_diff'] = team_wins_5 - opp_wins_5\n",
    "        else:\n",
    "            game_features['recent_form_diff'] = np.nan\n",
    "        \n",
    "        # Scoring differential\n",
    "        for days in time_windows:\n",
    "            team_pts = game_features.get(f'team_cg_pts_{days}d', np.nan)\n",
    "            opp_pts = game_features.get(f'opp_team_cg_pts_{days}d', np.nan)\n",
    "            if not pd.isna(team_pts) and not pd.isna(opp_pts):\n",
    "                game_features[f'avg_scoring_diff_{days}d'] = team_pts - opp_pts\n",
    "            else:\n",
    "                game_features[f'avg_scoring_diff_{days}d'] = np.nan\n",
    "        \n",
    "        # Opponent Current Game Columns        \n",
    "        opp_game_fh = fh_teams[\n",
    "            (fh_teams['GAME_ID'] == game_id) & \n",
    "            (fh_teams['TEAM_ID'] == opponent_id)\n",
    "        ]\n",
    "        \n",
    "        if len(opp_game_fh) > 0:\n",
    "            game_features['opp_current_fh_pts'] = opp_game_fh['PTS'].iloc[0]\n",
    "            game_features['opp_current_fh_fgm'] = opp_game_fh['FGM'].iloc[0]\n",
    "            game_features['opp_current_fh_fga'] = opp_game_fh['FGA'].iloc[0]\n",
    "            game_features['opp_current_fh_fg3m'] = opp_game_fh['FG3M'].iloc[0]\n",
    "            game_features['opp_current_fh_fg3a'] = opp_game_fh['FG3A'].iloc[0]\n",
    "            game_features['opp_current_fh_reb'] = opp_game_fh['REB'].iloc[0]\n",
    "            game_features['opp_current_fh_ast'] = opp_game_fh['AST'].iloc[0]\n",
    "            game_features['opp_current_fh_to'] = opp_game_fh['TO'].iloc[0]\n",
    "            game_features['opp_current_fh_pf'] = opp_game_fh['PF'].iloc[0]\n",
    "            \n",
    "            opp_fga = opp_game_fh['FGA'].iloc[0]\n",
    "            opp_fg3a = opp_game_fh['FG3A'].iloc[0]\n",
    "            \n",
    "            game_features['opp_current_fh_fg_pct'] = opp_game_fh['FGM'].iloc[0] / opp_fga if opp_fga > 0 else np.nan\n",
    "            game_features['opp_current_fh_fg3_pct'] = opp_game_fh['FG3M'].iloc[0] / opp_fg3a if opp_fg3a > 0 else np.nan\n",
    "            game_features['opp_current_fh_pace'] = opp_fga + opp_game_fh['TO'].iloc[0]\n",
    "        else:\n",
    "            opp_fh_stats = ['pts', 'fgm', 'fga', 'fg3m', 'fg3a', 'reb', 'ast', 'to', 'pf', \n",
    "                            'fg_pct', 'fg3_pct', 'pace']\n",
    "            for stat in opp_fh_stats:\n",
    "                game_features[f'opp_current_fh_{stat}'] = np.nan\n",
    "        \n",
    "        # Halftime Stats        \n",
    "        if len(current_game_fh) > 0 and len(opp_game_fh) > 0:\n",
    "            \n",
    "            # Totals\n",
    "            game_features['halftime_total'] = current_game_fh['PTS'].iloc[0] + opp_game_fh['PTS'].iloc[0]\n",
    "            \n",
    "            # PAce\n",
    "            team_pace = game_features.get('current_fh_pace', 0)\n",
    "            opp_pace = game_features.get('opp_current_fh_pace', 0)\n",
    "            game_features['halftime_total_pace'] = team_pace + opp_pace\n",
    "            \n",
    "            # Shooting PCTs\n",
    "            team_fg_pct = game_features.get('current_fh_fg_pct', np.nan)\n",
    "            opp_fg_pct = game_features.get('opp_current_fh_fg_pct', np.nan)\n",
    "            if not pd.isna(team_fg_pct) and not pd.isna(opp_fg_pct):\n",
    "                game_features['halftime_combined_fg_pct'] = (team_fg_pct + opp_fg_pct) / 2\n",
    "            else:\n",
    "                game_features['halftime_combined_fg_pct'] = np.nan\n",
    "            \n",
    "            # Turnovers\n",
    "            game_features['halftime_total_to'] = current_game_fh['TO'].iloc[0] + opp_game_fh['TO'].iloc[0]\n",
    "            \n",
    "            # Scoring\n",
    "            team_avg = game_features.get('team_fh_pts_7d', np.nan)\n",
    "            opp_avg = game_features.get('opp_team_fh_pts_7d', np.nan)\n",
    "            team_current = current_game_fh['PTS'].iloc[0]\n",
    "            opp_current = opp_game_fh['PTS'].iloc[0]\n",
    "            \n",
    "            if not pd.isna(team_avg) and not pd.isna(opp_avg):\n",
    "                team_var = team_current - team_avg\n",
    "                opp_var = opp_current - opp_avg\n",
    "                game_features['halftime_combined_scoring_variance'] = team_var + opp_var\n",
    "            else:\n",
    "                game_features['halftime_combined_scoring_variance'] = np.nan\n",
    "            \n",
    "            # Lead\n",
    "            game_features['halftime_lead_abs'] = abs(current_game_fh['PTS'].iloc[0] - opp_game_fh['PTS'].iloc[0])\n",
    "        \n",
    "        else:\n",
    "            game_features['halftime_total'] = np.nan\n",
    "            game_features['halftime_total_pace'] = np.nan\n",
    "            game_features['halftime_combined_fg_pct'] = np.nan\n",
    "            game_features['halftime_total_to'] = np.nan\n",
    "            game_features['halftime_combined_scoring_variance'] = np.nan\n",
    "            game_features['halftime_lead_abs'] = np.nan\n",
    "    \n",
    "    ## Getting Second Half Targets\n",
    "    current_game_cg = cg_teams[\n",
    "        (cg_teams['GAME_ID'] == game_id) & \n",
    "        (cg_teams['TEAM_ID'] == team_id)\n",
    "    ]\n",
    "    \n",
    "    # Team's second-half score\n",
    "    if len(current_game_cg) > 0 and len(current_game_fh) > 0:\n",
    "        complete_pts = current_game_cg['PTS'].iloc[0]\n",
    "        first_half_pts = current_game_fh['PTS'].iloc[0]\n",
    "        game_features['actual_second_half_pts'] = complete_pts - first_half_pts\n",
    "    else:\n",
    "        game_features['actual_second_half_pts'] = np.nan\n",
    "    \n",
    "    # Opponent's second-half score\n",
    "    if opponent_id is not None:\n",
    "        opp_game_cg = cg_teams[\n",
    "            (cg_teams['GAME_ID'] == game_id) & \n",
    "            (cg_teams['TEAM_ID'] == opponent_id)\n",
    "        ]\n",
    "        \n",
    "        if len(opp_game_cg) > 0 and len(opp_game_fh) > 0:\n",
    "            opp_complete_pts = opp_game_cg['PTS'].iloc[0]\n",
    "            opp_first_half_pts = opp_game_fh['PTS'].iloc[0]\n",
    "            opp_second_half_pts = opp_complete_pts - opp_first_half_pts\n",
    "            \n",
    "            # Both teams combined for second half (this is the target)\n",
    "            if not pd.isna(game_features['actual_second_half_pts']) and not pd.isna(opp_second_half_pts):\n",
    "                game_features['actual_second_half_total'] = game_features['actual_second_half_pts'] + opp_second_half_pts\n",
    "            else:\n",
    "                game_features['actual_second_half_total'] = np.nan\n",
    "        else:\n",
    "            game_features['actual_second_half_total'] = np.nan\n",
    "    else:\n",
    "        game_features['actual_second_half_total'] = np.nan\n",
    "\n",
    "    all_features.append(game_features)\n",
    "    \n",
    "## Create Final Dataframe\n",
    "features_df = pd.DataFrame(all_features)\n",
    "print(f\"\\nFeature engineering complete!\")\n",
    "print(f\"Total features: {len(features_df.columns)}\")\n",
    "print(f\"Total games: {len(features_df)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccbddbe",
   "metadata": {},
   "source": [
    "Used this to inspect the dataset and then also write the dataset. They're split as a relic of testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd66b2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inspect and Save Features Dataset\n",
    "features_df.head()\n",
    "features_df.to_csv('nba_time_based_features.csv', index=False)\n",
    "print(\"Saved to 'nba_time_based_features.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2263bf",
   "metadata": {},
   "source": [
    "Next cell is using a mapping table to try and create a key based on the team and the date so we can join it to our NBA dataset. There were a number of games missing and a big bulk of those is because we only have half of the 2023 season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930364f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "\n",
      "Created GAME_ID to h2_total mapping\n",
      "Total games: 7804\n",
      "Games with h2_total: 3158\n",
      "Games missing h2_total: 4646\n",
      "\n",
      "Saved to game_id_to_h2_total.csv\n"
     ]
    }
   ],
   "source": [
    "## Create Mapping Table for Betting Lines\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## Load Data\n",
    "betting_data = pd.read_csv('betting_data.csv')\n",
    "games_master = pd.read_csv('nba_games_2021_to_2024.csv')\n",
    "\n",
    "# Format dates\n",
    "betting_data['date'] = pd.to_datetime(betting_data['date'])\n",
    "games_master['GAME_DATE'] = pd.to_datetime(games_master['GAME_DATE'])\n",
    "\n",
    "\n",
    "## Create Team Abbreviation Mapping\n",
    "team_map = {\n",
    "    'atl': 'ATL', 'bos': 'BOS', 'bkn': 'BKN', 'cha': 'CHA', 'chi': 'CHI',\n",
    "    'cle': 'CLE', 'dal': 'DAL', 'den': 'DEN', 'det': 'DET', 'gs': 'GSW',\n",
    "    'hou': 'HOU', 'ind': 'IND', 'lac': 'LAC', 'lal': 'LAL', 'mem': 'MEM',\n",
    "    'mia': 'MIA', 'mil': 'MIL', 'min': 'MIN', 'no': 'NOP', 'nyk': 'NYK',\n",
    "    'okc': 'OKC', 'orl': 'ORL', 'phi': 'PHI', 'phx': 'PHX', 'por': 'POR',\n",
    "    'sac': 'SAC', 'sa': 'SAS', 'tor': 'TOR', 'utah': 'UTA', 'wsh': 'WAS',\n",
    "    'nj': 'BKN', 'ny': 'NYK'\n",
    "}\n",
    "\n",
    "# Apply mapping\n",
    "betting_data['away_team'] = betting_data['away'].map(team_map)\n",
    "betting_data['home_team'] = betting_data['home'].map(team_map)\n",
    "\n",
    "\n",
    "## Create Match Keys\n",
    "betting_data['match_key'] = (\n",
    "    betting_data['date'].dt.strftime('%Y-%m-%d') + '_' + \n",
    "    betting_data['away_team'] + '_' + \n",
    "    betting_data['home_team']\n",
    ")\n",
    "\n",
    "\n",
    "## Create NBA Match Keys\n",
    "games_master['is_home'] = games_master['MATCHUP'].str.contains('vs.', na=False)\n",
    "\n",
    "# Separate home and away games\n",
    "home_games = games_master[games_master['is_home'] == True][\n",
    "    ['GAME_ID', 'GAME_DATE', 'TEAM_ABBREVIATION']\n",
    "].copy()\n",
    "away_games = games_master[games_master['is_home'] == False][\n",
    "    ['GAME_ID', 'GAME_DATE', 'TEAM_ABBREVIATION']\n",
    "].copy()\n",
    "\n",
    "home_games.columns = ['GAME_ID', 'GAME_DATE', 'home_team']\n",
    "away_games.columns = ['GAME_ID', 'GAME_DATE', 'away_team']\n",
    "\n",
    "# Merge to create matchups\n",
    "game_matchups = home_games.merge(away_games, on=['GAME_ID', 'GAME_DATE'])\n",
    "\n",
    "# Create match key\n",
    "game_matchups['match_key'] = (\n",
    "    game_matchups['GAME_DATE'].dt.strftime('%Y-%m-%d') + '_' + \n",
    "    game_matchups['away_team'] + '_' + \n",
    "    game_matchups['home_team']\n",
    ")\n",
    "\n",
    "\n",
    "## Join and Create Mapping\n",
    "game_id_target = game_matchups.merge(\n",
    "    betting_data[['match_key', 'h2_total']],\n",
    "    on='match_key',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Keep only GAME_ID and h2_total\n",
    "game_id_target = game_id_target[['GAME_ID', 'h2_total']].drop_duplicates()\n",
    "\n",
    "print(f\"\\nCreated GAME_ID to h2_total mapping\")\n",
    "print(f\"Total games: {len(game_id_target)}\")\n",
    "print(f\"Games with h2_total: {game_id_target['h2_total'].notna().sum()}\")\n",
    "print(f\"Games missing h2_total: {game_id_target['h2_total'].isna().sum()}\")\n",
    "\n",
    "## Save Mapping\n",
    "game_id_target.to_csv('game_id_to_h2_total.csv', index=False)\n",
    "print(f\"\\nSaved to game_id_to_h2_total.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697ce94e",
   "metadata": {},
   "source": [
    "Cell below actually does the join. Upon further investigation we realized that the failed joins were preseason and international exhibition games so we can drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62608b36",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'nba_time_based_features.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m features_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnba_time_based_features.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m game_id_target \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgame_id_to_h2_total.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Join h2_total to features\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'nba_time_based_features.csv'"
     ]
    }
   ],
   "source": [
    "## Merge Betting Lines and Filter Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "## Load Data\n",
    "features_df = pd.read_csv('nba_time_based_features.csv')\n",
    "game_id_target = pd.read_csv('game_id_to_h2_total.csv')\n",
    "\n",
    "## Join h2_total to Features\n",
    "features_with_target = features_df.merge(\n",
    "    game_id_target,\n",
    "    on='GAME_ID',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"After join: {features_with_target.shape}\")\n",
    "print(f\"Rows with h2_total: {features_with_target['h2_total'].notna().sum()}\")\n",
    "print(f\"Rows without h2_total: {features_with_target['h2_total'].isna().sum()}\")\n",
    "\n",
    "\n",
    "## Drop Rows Without h2_total\n",
    "features_with_target = features_with_target[features_with_target['h2_total'].notna()]\n",
    "\n",
    "print(f\"\\nAfter dropping preseason/exhibition: {features_with_target.shape}\")\n",
    "\n",
    "## Save the joined dataset\n",
    "print(f\"\\nSaving to nba_features_with_target.csv...\")\n",
    "features_with_target.to_csv('nba_features_with_target.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231b4791",
   "metadata": {},
   "source": [
    "This next cell block preps the data for modelling. First it drops all columns that would cost data leaks (basically ones that have second half information) since we are using walk forward building dates are fine. We are testing on the second most recent season we had betting information on and before that is train data. We held out the last partial season of data for seperate validation processes.\n",
    "\n",
    "*** This is where you start the code from the Git Repo ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e3efc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train: 2342 games\n",
      "Test: 2646 games\n",
      "Holdout: 1328 games\n",
      "\n",
      "Saved: train_data.csv, test_data.csv, holdout_data.csv, feature_list.txt\n"
     ]
    }
   ],
   "source": [
    "## Create Train/Test/Holdout Splits\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "## Load data\n",
    "df = pd.read_csv('nba_features_with_target.csv')\n",
    "df['GAME_DATE'] = pd.to_datetime(df['GAME_DATE'])\n",
    "\n",
    "\n",
    "## Drop leakage columns\n",
    "drop_columns = [\n",
    "    # Rolling second-half team stats\n",
    "    'team_cg_second_half_pts_7d', 'team_cg_second_half_fgm_7d', \n",
    "    'team_cg_second_half_fga_7d', 'team_cg_second_half_fg3m_7d',\n",
    "    'team_cg_second_half_fg3a_7d', 'team_cg_second_half_ftm_7d',\n",
    "    'team_cg_second_half_fta_7d', 'team_cg_second_half_reb_7d',\n",
    "    'team_cg_second_half_ast_7d', 'team_cg_second_half_to_7d',\n",
    "    'team_cg_second_half_stl_7d', 'team_cg_second_half_blk_7d',\n",
    "    'team_cg_second_half_fg_pct_7d', 'team_cg_second_half_fg3_pct_7d',\n",
    "    'team_cg_second_half_ft_pct_7d', 'team_cg_second_half_pts_14d',\n",
    "    'team_cg_second_half_fgm_14d', 'team_cg_second_half_fga_14d',\n",
    "    'team_cg_second_half_fg3m_14d', 'team_cg_second_half_fg3a_14d',\n",
    "    'team_cg_second_half_ftm_14d', 'team_cg_second_half_fta_14d',\n",
    "    'team_cg_second_half_reb_14d', 'team_cg_second_half_ast_14d',\n",
    "    'team_cg_second_half_to_14d', 'team_cg_second_half_stl_14d',\n",
    "    'team_cg_second_half_blk_14d', 'team_cg_second_half_fg_pct_14d',\n",
    "    'team_cg_second_half_fg3_pct_14d', 'team_cg_second_half_ft_pct_14d',\n",
    "    'team_cg_second_half_pts_30d', 'team_cg_second_half_fgm_30d',\n",
    "    'team_cg_second_half_fga_30d', 'team_cg_second_half_fg3m_30d',\n",
    "    'team_cg_second_half_fg3a_30d', 'team_cg_second_half_ftm_30d',\n",
    "    'team_cg_second_half_fta_30d', 'team_cg_second_half_reb_30d',\n",
    "    'team_cg_second_half_ast_30d', 'team_cg_second_half_to_30d',\n",
    "    'team_cg_second_half_stl_30d', 'team_cg_second_half_blk_30d',\n",
    "    'team_cg_second_half_fg_pct_30d', 'team_cg_second_half_fg3_pct_30d',\n",
    "    'team_cg_second_half_ft_pct_30d',\n",
    "\n",
    "    # Direct post-game leakage columns\n",
    "    'actual_second_half_pts', 'actual_second_half_fgm',\n",
    "    'actual_second_half_fga', 'actual_second_half_fg3m',\n",
    "    'actual_second_half_fg3a', 'actual_second_half_ftm',\n",
    "    'actual_second_half_fta', 'actual_second_half_reb',\n",
    "    'actual_second_half_ast', 'actual_second_half_to',\n",
    "    'actual_second_half_stl', 'actual_second_half_blk',\n",
    "    'actual_second_half_fg_pct', 'actual_second_half_fg3_pct',\n",
    "    'actual_second_half_ft_pct', 'actual_second_half_plus_minus'\n",
    "]\n",
    "\n",
    "df = df.drop(columns=drop_columns, errors='ignore')\n",
    "\n",
    "\n",
    "## Get seasons\n",
    "def get_nba_season(date):\n",
    "    year = date.year\n",
    "    month = date.month\n",
    "    return f\"{year}-{year+1}\" if month >= 10 else f\"{year-1}-{year}\"\n",
    "\n",
    "df['season'] = df['GAME_DATE'].apply(get_nba_season)\n",
    "df = df.sort_values('GAME_DATE')\n",
    "\n",
    "seasons = sorted(df['season'].unique())\n",
    "\n",
    "\n",
    "## Create dataset splits\n",
    "holdout_season = seasons[-1]\n",
    "test_season = seasons[-2]\n",
    "train_seasons = seasons[:-2]\n",
    "\n",
    "# Filter data\n",
    "train_data = df[\n",
    "    (df['season'].isin(train_seasons)) & \n",
    "    (df['actual_second_half_total'].notna()) &\n",
    "    (df['h2_total'].notna())\n",
    "]\n",
    "\n",
    "test_data = df[\n",
    "    (df['season'] == test_season) & \n",
    "    (df['actual_second_half_total'].notna()) &\n",
    "    (df['h2_total'].notna())\n",
    "]\n",
    "\n",
    "holdout_data = df[\n",
    "    (df['season'] == holdout_season) & \n",
    "    (df['actual_second_half_total'].notna())\n",
    "]\n",
    "\n",
    "print(f\"\\nTrain: {len(train_data)} games\")\n",
    "print(f\"Test: {len(test_data)} games\")\n",
    "print(f\"Holdout: {len(holdout_data)} games\")\n",
    "\n",
    "\n",
    "## Prepare Feature List\n",
    "metadata_cols = ['GAME_ID', 'GAME_DATE', 'TEAM_ID', 'season']\n",
    "target_col = 'actual_second_half_total'\n",
    "betting_line_col = 'h2_total'\n",
    "\n",
    "feature_cols = [c for c in df.columns \n",
    "                if c not in metadata_cols + [target_col, betting_line_col]]\n",
    "\n",
    "## Save datasets\n",
    "train_data.to_csv('train_data.csv', index=False)\n",
    "test_data.to_csv('test_data.csv', index=False)\n",
    "holdout_data.to_csv('holdout_data.csv', index=False)\n",
    "\n",
    "with open('feature_list.txt', 'w') as f:\n",
    "    for col in feature_cols:\n",
    "        f.write(f\"{col}\\n\")\n",
    "\n",
    "print(\"\\nSaved: train_data.csv, test_data.csv, holdout_data.csv, feature_list.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556de189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values handled!\n",
      "[0]\tvalidation_0-rmse:13.96279\tvalidation_1-rmse:13.56825\n",
      "[50]\tvalidation_0-rmse:10.18589\tvalidation_1-rmse:13.46736\n",
      "[100]\tvalidation_0-rmse:7.69453\tvalidation_1-rmse:13.48778\n",
      "[150]\tvalidation_0-rmse:6.06479\tvalidation_1-rmse:13.51003\n",
      "[160]\tvalidation_0-rmse:5.77888\tvalidation_1-rmse:13.50995\n",
      "\n",
      "Test Metrics:\n",
      "MAE:  10.610 points\n",
      "RMSE: 13.458 points\n",
      "RÂ²:   0.004\n",
      "Saved xgboost_model.json\n",
      "Saved feature_importance.csv\n",
      "Saved test_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "## First XGBoost Model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "## Load Data\n",
    "train_data = pd.read_csv('train_data.csv')\n",
    "test_data = pd.read_csv('test_data.csv')\n",
    "\n",
    "# Format Dates\n",
    "train_data['GAME_DATE'] = pd.to_datetime(train_data['GAME_DATE'])\n",
    "test_data['GAME_DATE'] = pd.to_datetime(test_data['GAME_DATE'])\n",
    "\n",
    "## Define Columns\n",
    "metadata_cols = ['GAME_ID', 'GAME_DATE', 'TEAM_ID', 'season']\n",
    "target_col = 'actual_second_half_total'\n",
    "betting_line_col = 'h2_total'\n",
    "\n",
    "# Feature columns\n",
    "drop_from_features = set(metadata_cols + [target_col])\n",
    "if betting_line_col in train_data.columns:\n",
    "    drop_from_features.add(betting_line_col)\n",
    "\n",
    "feature_cols = [c for c in train_data.columns if c not in drop_from_features]\n",
    "\n",
    "\n",
    "## Split into X and y\n",
    "X_train = train_data[feature_cols]\n",
    "y_train = train_data[target_col]\n",
    "\n",
    "X_test = test_data[feature_cols]\n",
    "y_test = test_data[target_col]\n",
    "\n",
    "\n",
    "## Impute Missing Values\n",
    "missing_train = X_train.isnull().sum()\n",
    "cols_with_missing = missing_train[missing_train > 0]\n",
    "\n",
    "if len(cols_with_missing) > 0:\n",
    "    for col in cols_with_missing.index:\n",
    "        median_val = X_train[col].median()\n",
    "        X_train[col].fillna(median_val, inplace=True)\n",
    "        X_test[col].fillna(median_val, inplace=True)\n",
    "    print(\"Missing values handled!\")\n",
    "else:\n",
    "    print(\"No missing values!\")\n",
    "\n",
    "\n",
    "## Train Model\n",
    "model = xgb.XGBRegressor(\n",
    "    n_estimators=1800,\n",
    "    learning_rate=0.018,\n",
    "    max_depth=8,\n",
    "    min_child_weight=1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.75,\n",
    "    gamma=0.05,\n",
    "    reg_alpha=0.2,\n",
    "    reg_lambda=0.6,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    early_stopping_rounds=120,\n",
    "    eval_metric='rmse'\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "    verbose=50\n",
    ")\n",
    "\n",
    "\n",
    "## Evaluate Model\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "\n",
    "print(f\"\\nTest Metrics:\")\n",
    "print(f\"MAE:  {mae_test:.3f} points\")\n",
    "print(f\"RMSE: {rmse_test:.3f} points\")\n",
    "print(f\"RÂ²:   {r2_test:.3f}\")\n",
    "\n",
    "\n",
    "## Save Results\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Test predictions\n",
    "test_results = test_data.copy()\n",
    "test_results['actual_second_half_total_predicted'] = y_pred_test\n",
    "test_results['prediction_error'] = np.abs(y_test - y_pred_test)\n",
    "\n",
    "show_cols = ['GAME_ID', 'GAME_DATE', 'actual_second_half_total',\n",
    "            'actual_second_half_total_predicted', 'prediction_error']\n",
    "if betting_line_col in test_results.columns:\n",
    "    test_results['edge_vs_line'] = test_results['actual_second_half_total_predicted'] - test_results[betting_line_col]\n",
    "    show_cols.append(betting_line_col)\n",
    "    show_cols.append('edge_vs_line')\n",
    "\n",
    "\n",
    "# Save\n",
    "model.save_model('xgboost_model.json')\n",
    "print(\"Saved xgboost_model.json\")\n",
    "\n",
    "feature_importance.to_csv('feature_importance.csv', index=False)\n",
    "print(\"Saved feature_importance.csv\")\n",
    "\n",
    "test_results.to_csv('test_predictions.csv', index=False)\n",
    "print(\"Saved test_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28e7e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:13.24557\tvalidation_1-rmse:12.61378\n",
      "[50]\tvalidation_0-rmse:10.74339\tvalidation_1-rmse:12.61934\n",
      "[100]\tvalidation_0-rmse:8.57413\tvalidation_1-rmse:12.66605\n",
      "[150]\tvalidation_0-rmse:6.78661\tvalidation_1-rmse:12.72903\n",
      "[151]\tvalidation_0-rmse:6.74765\tvalidation_1-rmse:12.73144\n",
      "\n",
      "Residual Model Metrics:\n",
      "MAE:  9.735 pts\n",
      "RMSE: 12.601 pts\n",
      "RÂ²:   0.002\n",
      "FULL TOTAL PERFORMANCE (Actual Second Half Totals)\n",
      "MAE:  9.735 pts\n",
      "RMSE: 12.601 pts\n",
      "RÂ²:   0.127\n",
      "Saved model (xgboost_residual_model.json)\n",
      "Saved predictions (test_predictions_residual.csv)\n"
     ]
    }
   ],
   "source": [
    "## XGBoost Using h2_total Residual\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "## Load Data\n",
    "train_data = pd.read_csv(\"train_data.csv\")\n",
    "test_data = pd.read_csv(\"test_data.csv\")\n",
    "\n",
    "# Format dates\n",
    "train_data[\"GAME_DATE\"] = pd.to_datetime(train_data[\"GAME_DATE\"])\n",
    "test_data[\"GAME_DATE\"] = pd.to_datetime(test_data[\"GAME_DATE\"])\n",
    "\n",
    "\n",
    "## Define Columns\n",
    "metadata_cols = [\"GAME_ID\", \"GAME_DATE\", \"TEAM_ID\", \"season\"]\n",
    "target_col = \"actual_second_half_total\"\n",
    "vegas_col = \"h2_total\"\n",
    "\n",
    "feature_cols = [c for c in train_data.columns if c not in metadata_cols + [target_col]]\n",
    "\n",
    "X_train = train_data[feature_cols].copy()\n",
    "# Add Residual Here\n",
    "y_train = train_data[target_col] - train_data[vegas_col]\n",
    "\n",
    "X_test = test_data[feature_cols].copy()\n",
    "# Add Residual Here\n",
    "y_test = test_data[target_col] - test_data[vegas_col]\n",
    "\n",
    "\n",
    "## Impute Missing Values\n",
    "for col in X_train.columns:\n",
    "    if X_train[col].isnull().any():\n",
    "        median_val = X_train[col].median()\n",
    "        X_train[col].fillna(median_val, inplace=True)\n",
    "        X_test[col].fillna(median_val, inplace=True)\n",
    "\n",
    "\n",
    "## Train Model\n",
    "model = xgb.XGBRegressor(\n",
    "    n_estimators=1800,\n",
    "    learning_rate=0.018,\n",
    "    max_depth=8,\n",
    "    min_child_weight=1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.75,\n",
    "    gamma=0.05,\n",
    "    reg_alpha=0.2,\n",
    "    reg_lambda=0.6,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    early_stopping_rounds=120,\n",
    "    eval_metric='rmse'\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "    verbose=50\n",
    ")\n",
    "\n",
    " \n",
    "## Evaluate Residual Performance\n",
    "y_pred_resid = model.predict(X_test)\n",
    "mae_resid = mean_absolute_error(y_test, y_pred_resid)\n",
    "rmse_resid = np.sqrt(mean_squared_error(y_test, y_pred_resid))\n",
    "r2_resid = r2_score(y_test, y_pred_resid)\n",
    "\n",
    "print(f\"\\nResidual Model Metrics:\")\n",
    "print(f\"MAE:  {mae_resid:.3f} pts\")\n",
    "print(f\"RMSE: {rmse_resid:.3f} pts\")\n",
    "print(f\"RÂ²:   {r2_resid:.3f}\")\n",
    "\n",
    "## Reconstruct Full Total Predictions\n",
    "y_pred_total = y_pred_resid + X_test[vegas_col]\n",
    "y_true_total = y_test + X_test[vegas_col]\n",
    "\n",
    "mae_total = mean_absolute_error(y_true_total, y_pred_total)\n",
    "rmse_total = np.sqrt(mean_squared_error(y_true_total, y_pred_total))\n",
    "r2_total = r2_score(y_true_total, y_pred_total)\n",
    "\n",
    "print(\"\\nFull Total Performance (Actual Second Half Totals)\")\n",
    "print(f\"MAE:  {mae_total:.3f} pts\")\n",
    "print(f\"RMSE: {rmse_total:.3f} pts\")\n",
    "print(f\"RÂ²:   {r2_total:.3f}\")\n",
    "\n",
    "\n",
    "## Save Results\n",
    "test_results = test_data.copy()\n",
    "test_results[\"predicted_residual\"] = y_pred_resid\n",
    "test_results[\"predicted_total\"] = y_pred_total\n",
    "test_results[\"residual_error\"] = y_test - y_pred_resid\n",
    "test_results[\"actual_residual\"] = y_test\n",
    "test_results[\"edge_vs_vegas\"] = y_pred_resid\n",
    "\n",
    "model.save_model(\"xgboost_residual_model.json\")\n",
    "test_results.to_csv(\"test_predictions_residual.csv\", index=False)\n",
    "\n",
    "print(\"Saved model (xgboost_residual_model.json)\")\n",
    "print(\"Saved predictions (test_predictions_residual.csv)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce8dcae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SECOND HALF TOTALS â€“ MODEL BENCHMARK COMPARISON\n",
      "                     MAE   RMSE    RÂ²  Î” MAE vs Vegas  Î” RMSE vs Vegas\n",
      "Vegas Line         9.738 12.618 0.124           0.000            0.000\n",
      "No Residual Model 10.610 13.458 0.004           0.872            0.840\n",
      "Residual Model     9.735 12.601 0.127          -0.004           -0.017\n"
     ]
    }
   ],
   "source": [
    "## Model Comparison XGBoost and XGboost with resid\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "## Load Prediction Files\n",
    "resid = pd.read_csv(\"test_predictions.csv\")                  # main (no residual) model\n",
    "no_resid = pd.read_csv(\"test_predictions_residual.csv\")      # residual model\n",
    "\n",
    "\n",
    "## Get Prediction Column Names (i named them badly)\n",
    "def get_pred_col(df):\n",
    "    if \"predicted_total\" in df.columns:\n",
    "        return \"predicted_total\"\n",
    "    elif \"actual_second_half_total_predicted\" in df.columns:\n",
    "        return \"actual_second_half_total_predicted\"\n",
    "    else:\n",
    "        raise KeyError(\"still can't get the columns right\")\n",
    "\n",
    "pred_col_resid = get_pred_col(resid)\n",
    "pred_col_no_resid = get_pred_col(no_resid)\n",
    "\n",
    "\n",
    "## Define Targets and Predictions\n",
    "y_true = resid[\"actual_second_half_total\"]\n",
    "y_vegas = resid[\"h2_total\"]\n",
    "\n",
    "y_pred_no_residual = resid[pred_col_resid]\n",
    "y_pred_residual = no_resid[pred_col_no_resid]\n",
    "\n",
    "\n",
    "## Evaluation Function\n",
    "def evaluate(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mae, rmse, r2\n",
    "\n",
    "\n",
    "## Calculate Metrics\n",
    "results = {\n",
    "    \"Vegas Line\": evaluate(y_true, y_vegas),\n",
    "    \"No Residual Model\": evaluate(y_true, y_pred_no_residual),\n",
    "    \"Residual Model\": evaluate(y_true, y_pred_residual),\n",
    "}\n",
    "\n",
    "\n",
    "## Create Summary\n",
    "summary = pd.DataFrame(results, index=[\"MAE\", \"RMSE\", \"RÂ²\"]).T\n",
    "summary[\"Î” MAE vs Vegas\"] = summary[\"MAE\"] - summary.loc[\"Vegas Line\", \"MAE\"]\n",
    "summary[\"Î” RMSE vs Vegas\"] = summary[\"RMSE\"] - summary.loc[\"Vegas Line\", \"RMSE\"]\n",
    "\n",
    "print(\"SECOND HALF TOTALS â€“ MODEL BENCHMARK COMPARISON\")\n",
    "print(summary.to_string(float_format=lambda x: f\"{x:0.3f}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa0f916",
   "metadata": {},
   "source": [
    "Basically as we were testing we found out that the Vegas line is actually very very good. Even without using first half data its actually better then our tuned XGBoost model. Knowing that we have the Vegas second half total we used that as a residual in another XGBoost model, which gave us some improvements over the Vegas line. Is this enough to make betting model that is profitable? We do not quite know yet. \n",
    "\n",
    "Also then tried a Random Forest because tree based models have similiarities and perhaps RF performs better (but it didn't). We tried to keep the parameters similar to the XGBoost model because we spent tons of time tuning the XGBoost model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5cc4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest with XGBoost-inspired hyperparameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   17.8s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   32.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:   50.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1800 out of 1800 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 1776 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 1800 out of 1800 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Residual Metrics:\n",
      "MAE:  9.747 pts\n",
      "RMSE: 12.620 pts\n",
      "RÂ²:   -0.002\n",
      "\n",
      "FULL TOTAL PERFORMANCE:\n",
      "Vegas Line    -> MAE: 9.738 | RMSE: 12.618 | RÂ²: 0.124\n",
      "Random Forest -> MAE: 9.747 | RMSE: 12.620 | RÂ²: 0.124\n",
      "Î” MAE:  +0.008\n",
      "Î” RMSE: +0.002\n",
      "\n",
      "Saved: test_predictions_rf.csv, random_forest_model.pkl\n"
     ]
    }
   ],
   "source": [
    "## Random Forest Residual Model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "##Load Data\n",
    "train_data = pd.read_csv('train_data.csv')\n",
    "test_data = pd.read_csv('test_data.csv')\n",
    "\n",
    "train_data['GAME_DATE'] = pd.to_datetime(train_data['GAME_DATE'])\n",
    "test_data['GAME_DATE'] = pd.to_datetime(test_data['GAME_DATE'])\n",
    "\n",
    "\n",
    "## Define Columns\n",
    "metadata_cols = ['GAME_ID', 'GAME_DATE', 'TEAM_ID', 'season']\n",
    "target_col = 'actual_second_half_total'\n",
    "vegas_col = 'h2_total'\n",
    "\n",
    "feature_cols = [c for c in train_data.columns if c not in metadata_cols + [target_col]]\n",
    "\n",
    "X_train = train_data[feature_cols].copy()\n",
    "y_train = train_data[target_col] - train_data[vegas_col]\n",
    "\n",
    "X_test = test_data[feature_cols].copy()\n",
    "y_test = test_data[target_col] - test_data[vegas_col]\n",
    "\n",
    "\n",
    "## Impute missing values\n",
    "for col in X_train.columns:\n",
    "    if X_train[col].isnull().any():\n",
    "        median_val = X_train[col].median()\n",
    "        X_train[col].fillna(median_val, inplace=True)\n",
    "        X_test[col].fillna(median_val, inplace=True)\n",
    "\n",
    "\n",
    "## Train Model\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=1800,\n",
    "    max_depth=8,\n",
    "    min_samples_split=5\n",
    "    min_samples_leaf=2,\n",
    "    max_samples=0.8,\n",
    "    max_features=0.75,\n",
    "    min_impurity_decrease=0.0,\n",
    "    bootstrap=True,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "## Evaluate Residual Performance\n",
    "y_pred_resid = model.predict(X_test)\n",
    "\n",
    "mae_resid = mean_absolute_error(y_test, y_pred_resid)\n",
    "rmse_resid = np.sqrt(mean_squared_error(y_test, y_pred_resid))\n",
    "r2_resid = r2_score(y_test, y_pred_resid)\n",
    "\n",
    "print(f\"\\nRandom Forest Residual Metrics:\")\n",
    "print(f\"MAE:  {mae_resid:.3f} pts\")\n",
    "print(f\"RMSE: {rmse_resid:.3f} pts\")\n",
    "print(f\"RÂ²:   {r2_resid:.3f}\")\n",
    "\n",
    "\n",
    "## Reconstruct Full Totals\n",
    "y_pred_total = y_pred_resid + X_test[vegas_col]\n",
    "y_true_total = y_test + X_test[vegas_col]\n",
    "\n",
    "mae_total = mean_absolute_error(y_true_total, y_pred_total)\n",
    "rmse_total = np.sqrt(mean_squared_error(y_true_total, y_pred_total))\n",
    "r2_total = r2_score(y_true_total, y_pred_total)\n",
    "\n",
    "\n",
    "## Vegas Baseline\n",
    "mae_vegas = mean_absolute_error(y_true_total, X_test[vegas_col])\n",
    "rmse_vegas = np.sqrt(mean_squared_error(y_true_total, X_test[vegas_col]))\n",
    "r2_vegas = r2_score(y_true_total, X_test[vegas_col])\n",
    "\n",
    "print(f\"\\nFull Total Performance:\")\n",
    "print(f\"Vegas Line     MAE: {mae_vegas:.3f} | RMSE: {rmse_vegas:.3f} | RÂ²: {r2_vegas:.3f}\")\n",
    "print(f\"Random Forest  MAE: {mae_total:.3f} | RMSE: {rmse_total:.3f} | RÂ²: {r2_total:.3f}\")\n",
    "print(f\"Î” MAE:  {mae_total - mae_vegas:+.3f}\")\n",
    "print(f\"Î” RMSE: {rmse_total - rmse_vegas:+.3f}\")\n",
    "\n",
    "\n",
    "## Save Results\n",
    "test_results = test_data.copy()\n",
    "test_results['rf_predicted_residual'] = y_pred_resid\n",
    "test_results['rf_predicted_total'] = y_pred_total\n",
    "test_results['rf_edge_vs_vegas'] = y_pred_resid\n",
    "\n",
    "test_results.to_csv('test_predictions_rf.csv', index=False)\n",
    "joblib.dump(model, 'random_forest_model.pkl')\n",
    "\n",
    "print(\"\\nSaved: test_predictions_rf.csv, random_forest_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef386d4",
   "metadata": {},
   "source": [
    "Why not try a very complex NN MLP model to see if we can get anything. This model ended up performing better than a very WIDE model with 1024 as the first layer. We originally thought given the large feature set that it might be better but it performed worse. NN might not be the best choice because we do not have enough data to find even more complicated patterns. Also we took out player names to make sure the model generalizes. Perhaps in a future project we could try to just NN everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8052a930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing missing values...\n",
      "Train NaNs remaining: 0\n",
      "Test NaNs remaining: 0\n",
      "Training Neural Network with XGBoost-inspired hyperparameters...\n",
      "Iteration 1, loss = 139.23240362\n",
      "Validation score: -0.027150\n",
      "Iteration 2, loss = 100.24986277\n",
      "Validation score: -0.096970\n",
      "Iteration 3, loss = 97.42461393\n",
      "Validation score: -0.034450\n",
      "Iteration 4, loss = 95.55759341\n",
      "Validation score: -0.012095\n",
      "Iteration 5, loss = 92.21806015\n",
      "Validation score: -0.115603\n",
      "Iteration 6, loss = 90.07100402\n",
      "Validation score: -0.079195\n",
      "Iteration 7, loss = 93.88368165\n",
      "Validation score: -0.017726\n",
      "Iteration 8, loss = 90.28775485\n",
      "Validation score: -0.059193\n",
      "Iteration 9, loss = 88.50343644\n",
      "Validation score: -0.029744\n",
      "Iteration 10, loss = 85.54630175\n",
      "Validation score: -0.180636\n",
      "Iteration 11, loss = 85.46636853\n",
      "Validation score: -0.223517\n",
      "Iteration 12, loss = 84.08095441\n",
      "Validation score: -0.065341\n",
      "Iteration 13, loss = 82.48237434\n",
      "Validation score: -0.279907\n",
      "Iteration 14, loss = 79.62942167\n",
      "Validation score: -0.153252\n",
      "Iteration 15, loss = 78.85683866\n",
      "Validation score: -0.207703\n",
      "Iteration 16, loss = 77.50133935\n",
      "Validation score: -0.124647\n",
      "Iteration 17, loss = 74.50243959\n",
      "Validation score: -0.153767\n",
      "Iteration 18, loss = 73.11461939\n",
      "Validation score: -0.103776\n",
      "Iteration 19, loss = 76.81059802\n",
      "Validation score: -0.117305\n",
      "Iteration 20, loss = 76.81701741\n",
      "Validation score: -0.230831\n",
      "Iteration 21, loss = 72.63649915\n",
      "Validation score: -0.270815\n",
      "Iteration 22, loss = 69.36074789\n",
      "Validation score: -0.102428\n",
      "Iteration 23, loss = 67.46177212\n",
      "Validation score: -0.174534\n",
      "Iteration 24, loss = 67.35896458\n",
      "Validation score: -0.163001\n",
      "Iteration 25, loss = 69.36657565\n",
      "Validation score: -0.243197\n",
      "Iteration 26, loss = 66.42291618\n",
      "Validation score: -0.287102\n",
      "Iteration 27, loss = 65.26699546\n",
      "Validation score: -0.113198\n",
      "Iteration 28, loss = 68.64094915\n",
      "Validation score: -0.274644\n",
      "Iteration 29, loss = 67.95800474\n",
      "Validation score: -0.058936\n",
      "Iteration 30, loss = 64.06677402\n",
      "Validation score: -0.192274\n",
      "Iteration 31, loss = 64.38206946\n",
      "Validation score: -0.283295\n",
      "Iteration 32, loss = 67.71455363\n",
      "Validation score: -0.221178\n",
      "Iteration 33, loss = 68.35066903\n",
      "Validation score: -0.192892\n",
      "Iteration 34, loss = 66.46797157\n",
      "Validation score: -0.148151\n",
      "Iteration 35, loss = 63.97462695\n",
      "Validation score: -0.252631\n",
      "Iteration 36, loss = 64.41237117\n",
      "Validation score: -0.352493\n",
      "Iteration 37, loss = 64.20039367\n",
      "Validation score: -0.353530\n",
      "Iteration 38, loss = 62.47612651\n",
      "Validation score: -0.302932\n",
      "Iteration 39, loss = 59.27140950\n",
      "Validation score: -0.269231\n",
      "Iteration 40, loss = 61.09288206\n",
      "Validation score: -0.269720\n",
      "Iteration 41, loss = 56.88665680\n",
      "Validation score: -0.193355\n",
      "Iteration 42, loss = 59.23271239\n",
      "Validation score: -0.319295\n",
      "Iteration 43, loss = 59.42271930\n",
      "Validation score: -0.505897\n",
      "Iteration 44, loss = 57.86886324\n",
      "Validation score: -0.180503\n",
      "Iteration 45, loss = 55.88941602\n",
      "Validation score: -0.265444\n",
      "Iteration 46, loss = 57.12496568\n",
      "Validation score: -0.180204\n",
      "Iteration 47, loss = 56.04127584\n",
      "Validation score: -0.283540\n",
      "Iteration 48, loss = 55.82545574\n",
      "Validation score: -0.266368\n",
      "Iteration 49, loss = 56.36470242\n",
      "Validation score: -0.365844\n",
      "Iteration 50, loss = 57.64893651\n",
      "Validation score: -0.367975\n",
      "Iteration 51, loss = 53.55252819\n",
      "Validation score: -0.385117\n",
      "Iteration 52, loss = 49.66444011\n",
      "Validation score: -0.325914\n",
      "Iteration 53, loss = 51.51299242\n",
      "Validation score: -0.197054\n",
      "Iteration 54, loss = 49.43846322\n",
      "Validation score: -0.284709\n",
      "Iteration 55, loss = 48.65442655\n",
      "Validation score: -0.244045\n",
      "Iteration 56, loss = 50.27984304\n",
      "Validation score: -0.273735\n",
      "Iteration 57, loss = 47.22822342\n",
      "Validation score: -0.331969\n",
      "Iteration 58, loss = 49.73422042\n",
      "Validation score: -0.328346\n",
      "Iteration 59, loss = 49.34444539\n",
      "Validation score: -0.450344\n",
      "Iteration 60, loss = 48.40524687\n",
      "Validation score: -0.398636\n",
      "Iteration 61, loss = 51.53343025\n",
      "Validation score: -0.359115\n",
      "Iteration 62, loss = 51.71820961\n",
      "Validation score: -0.543088\n",
      "Iteration 63, loss = 50.03102020\n",
      "Validation score: -0.296092\n",
      "Iteration 64, loss = 49.01766605\n",
      "Validation score: -0.356393\n",
      "Iteration 65, loss = 46.36092969\n",
      "Validation score: -0.407219\n",
      "Iteration 66, loss = 45.59051813\n",
      "Validation score: -0.333859\n",
      "Iteration 67, loss = 46.40654206\n",
      "Validation score: -0.442924\n",
      "Iteration 68, loss = 46.01034095\n",
      "Validation score: -0.396870\n",
      "Iteration 69, loss = 46.87635217\n",
      "Validation score: -0.340085\n",
      "Iteration 70, loss = 49.32143026\n",
      "Validation score: -0.353233\n",
      "Iteration 71, loss = 48.79289663\n",
      "Validation score: -0.312968\n",
      "Iteration 72, loss = 48.19916527\n",
      "Validation score: -0.273005\n",
      "Iteration 73, loss = 48.61737130\n",
      "Validation score: -0.369070\n",
      "Iteration 74, loss = 48.22601533\n",
      "Validation score: -0.390211\n",
      "Iteration 75, loss = 44.30653675\n",
      "Validation score: -0.369372\n",
      "Iteration 76, loss = 43.61172376\n",
      "Validation score: -0.421289\n",
      "Iteration 77, loss = 44.26117582\n",
      "Validation score: -0.265615\n",
      "Iteration 78, loss = 43.17395943\n",
      "Validation score: -0.336893\n",
      "Iteration 79, loss = 42.46040823\n",
      "Validation score: -0.370601\n",
      "Iteration 80, loss = 41.03760898\n",
      "Validation score: -0.450116\n",
      "Iteration 81, loss = 42.05061014\n",
      "Validation score: -0.324385\n",
      "Iteration 82, loss = 41.19385734\n",
      "Validation score: -0.460969\n",
      "Iteration 83, loss = 41.17400535\n",
      "Validation score: -0.232416\n",
      "Iteration 84, loss = 43.34999047\n",
      "Validation score: -0.230724\n",
      "Iteration 85, loss = 45.83881472\n",
      "Validation score: -0.475572\n",
      "Iteration 86, loss = 45.10460110\n",
      "Validation score: -0.339449\n",
      "Iteration 87, loss = 43.67105374\n",
      "Validation score: -0.469321\n",
      "Iteration 88, loss = 44.00972040\n",
      "Validation score: -0.285990\n",
      "Iteration 89, loss = 42.04976381\n",
      "Validation score: -0.544035\n",
      "Iteration 90, loss = 40.12980094\n",
      "Validation score: -0.377097\n",
      "Iteration 91, loss = 38.80014633\n",
      "Validation score: -0.398934\n",
      "Iteration 92, loss = 37.76566069\n",
      "Validation score: -0.365839\n",
      "Iteration 93, loss = 37.07528187\n",
      "Validation score: -0.351301\n",
      "Iteration 94, loss = 38.92075157\n",
      "Validation score: -0.485577\n",
      "Iteration 95, loss = 41.48766473\n",
      "Validation score: -0.534747\n",
      "Iteration 96, loss = 44.16080761\n",
      "Validation score: -0.411531\n",
      "Iteration 97, loss = 42.56690328\n",
      "Validation score: -0.535301\n",
      "Iteration 98, loss = 41.98995588\n",
      "Validation score: -0.439557\n",
      "Iteration 99, loss = 37.95070134\n",
      "Validation score: -0.434773\n",
      "Iteration 100, loss = 37.90034171\n",
      "Validation score: -0.358558\n",
      "Iteration 101, loss = 40.39913558\n",
      "Validation score: -0.402574\n",
      "Iteration 102, loss = 39.13027675\n",
      "Validation score: -0.390602\n",
      "Iteration 103, loss = 37.61429552\n",
      "Validation score: -0.505902\n",
      "Iteration 104, loss = 39.32023978\n",
      "Validation score: -0.352254\n",
      "Iteration 105, loss = 41.82446747\n",
      "Validation score: -0.307877\n",
      "Iteration 106, loss = 40.27621849\n",
      "Validation score: -0.238130\n",
      "Iteration 107, loss = 40.81147477\n",
      "Validation score: -0.373326\n",
      "Iteration 108, loss = 38.67484088\n",
      "Validation score: -0.311789\n",
      "Iteration 109, loss = 36.94791020\n",
      "Validation score: -0.346811\n",
      "Iteration 110, loss = 37.86479826\n",
      "Validation score: -0.440311\n",
      "Iteration 111, loss = 38.35187742\n",
      "Validation score: -0.272449\n",
      "Iteration 112, loss = 38.68381177\n",
      "Validation score: -0.365302\n",
      "Iteration 113, loss = 40.04115983\n",
      "Validation score: -0.315296\n",
      "Iteration 114, loss = 38.46585378\n",
      "Validation score: -0.479770\n",
      "Iteration 115, loss = 38.82072776\n",
      "Validation score: -0.376107\n",
      "Iteration 116, loss = 38.23988268\n",
      "Validation score: -0.370181\n",
      "Iteration 117, loss = 39.28240670\n",
      "Validation score: -0.358326\n",
      "Iteration 118, loss = 38.54785150\n",
      "Validation score: -0.506846\n",
      "Iteration 119, loss = 37.91453523\n",
      "Validation score: -0.412668\n",
      "Iteration 120, loss = 36.79820479\n",
      "Validation score: -0.440785\n",
      "Iteration 121, loss = 36.49459972\n",
      "Validation score: -0.430203\n",
      "Iteration 122, loss = 35.22867925\n",
      "Validation score: -0.528092\n",
      "Iteration 123, loss = 34.93190192\n",
      "Validation score: -0.367961\n",
      "Iteration 124, loss = 32.57433144\n",
      "Validation score: -0.409333\n",
      "Iteration 125, loss = 32.83558818\n",
      "Validation score: -0.382614\n",
      "Validation score did not improve more than tol=0.000100 for 120 consecutive epochs. Stopping.\n",
      "\n",
      "Neural Network Residual Metrics:\n",
      "MAE:  9.806 pts\n",
      "RMSE: 12.722 pts\n",
      "RÂ²:   -0.018\n",
      "\n",
      "FULL TOTAL PERFORMANCE:\n",
      "Vegas Line -> MAE: 9.738 | RMSE: 12.618 | RÂ²: 0.124\n",
      "Neural Net -> MAE: 9.806 | RMSE: 12.722 | RÂ²: 0.110\n",
      "Î” MAE:  +0.067\n",
      "Î” RMSE: +0.103\n",
      "\n",
      "Saved: test_predictions_mlp.csv, mlp_model.pkl, mlp_scaler.pkl\n"
     ]
    }
   ],
   "source": [
    "## Neural Network (MLP) Residual Model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "## Load Data\n",
    "train_data = pd.read_csv('train_data.csv')\n",
    "test_data = pd.read_csv('test_data.csv')\n",
    "\n",
    "train_data['GAME_DATE'] = pd.to_datetime(train_data['GAME_DATE'])\n",
    "test_data['GAME_DATE'] = pd.to_datetime(test_data['GAME_DATE'])\n",
    "\n",
    "\n",
    "## Define Columns\n",
    "metadata_cols = ['GAME_ID', 'GAME_DATE', 'TEAM_ID', 'season']\n",
    "target_col = 'actual_second_half_total'\n",
    "vegas_col = 'h2_total'\n",
    "\n",
    "feature_cols = [c for c in train_data.columns if c not in metadata_cols + [target_col]]\n",
    "\n",
    "X_train = train_data[feature_cols].copy()\n",
    "y_train = train_data[target_col] - train_data[vegas_col]\n",
    "\n",
    "X_test = test_data[feature_cols].copy()\n",
    "y_test = test_data[target_col] - test_data[vegas_col]\n",
    "\n",
    "\n",
    "## Imputer also for X_Tesst\n",
    "print(\"Imputing missing values...\")\n",
    "for col in feature_cols:\n",
    "    median_val = X_train[col].median()\n",
    "    X_train[col].fillna(median_val, inplace=True)\n",
    "    X_test[col].fillna(median_val, inplace=True)\n",
    "\n",
    "\n",
    "## Scale Features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "## Train Model\n",
    "model = MLPRegressor(\n",
    "    hidden_layer_sizes=(256, 128, 64),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    alpha=0.4,\n",
    "    batch_size=64,\n",
    "    learning_rate='adaptive',\n",
    "    learning_rate_init=0.018,\n",
    "    max_iter=1800,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.1,\n",
    "    n_iter_no_change=120,\n",
    "    tol=1e-4,\n",
    "    random_state=42,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "## Evaluate Residual Performance\n",
    "y_pred_resid = model.predict(X_test_scaled)\n",
    "\n",
    "mae_resid = mean_absolute_error(y_test, y_pred_resid)\n",
    "rmse_resid = np.sqrt(mean_squared_error(y_test, y_pred_resid))\n",
    "r2_resid = r2_score(y_test, y_pred_resid)\n",
    "\n",
    "print(f\"\\nNeural Network Residual Metrics:\")\n",
    "print(f\"MAE:  {mae_resid:.3f} pts\")\n",
    "print(f\"RMSE: {rmse_resid:.3f} pts\")\n",
    "print(f\"RÂ²:   {r2_resid:.3f}\")\n",
    "\n",
    "## Reconstruct Full totals\n",
    "y_pred_total = y_pred_resid + X_test[vegas_col]\n",
    "y_true_total = y_test + X_test[vegas_col]\n",
    "\n",
    "mae_total = mean_absolute_error(y_true_total, y_pred_total)\n",
    "rmse_total = np.sqrt(mean_squared_error(y_true_total, y_pred_total))\n",
    "r2_total = r2_score(y_true_total, y_pred_total)\n",
    "\n",
    "\n",
    "## Vegas baseline\n",
    "mae_vegas = mean_absolute_error(y_true_total, X_test[vegas_col])\n",
    "rmse_vegas = np.sqrt(mean_squared_error(y_true_total, X_test[vegas_col]))\n",
    "r2_vegas = r2_score(y_true_total, X_test[vegas_col])\n",
    "\n",
    "print(f\"\\nFull Total Performance:\")\n",
    "print(f\"Vegas Line  MAE: {mae_vegas:.3f} | RMSE: {rmse_vegas:.3f} | RÂ²: {r2_vegas:.3f}\")\n",
    "print(f\"Neural Net  MAE: {mae_total:.3f} | RMSE: {rmse_total:.3f} | RÂ²: {r2_total:.3f}\")\n",
    "print(f\"Î” MAE:  {mae_total - mae_vegas:+.3f}\")\n",
    "print(f\"Î” RMSE: {rmse_total - rmse_vegas:+.3f}\")\n",
    "\n",
    "## Save Results\n",
    "test_results = test_data.copy()\n",
    "test_results['mlp_predicted_residual'] = y_pred_resid\n",
    "test_results['mlp_predicted_total'] = y_pred_total\n",
    "test_results['mlp_edge_vs_vegas'] = y_pred_resid\n",
    "\n",
    "test_results.to_csv('test_predictions_mlp.csv', index=False)\n",
    "joblib.dump(model, 'mlp_model.pkl')\n",
    "joblib.dump(scaler, 'mlp_scaler.pkl')\n",
    "\n",
    "print(\"\\nSaved: test_predictions_mlp.csv, mlp_model.pkl, mlp_scaler.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772a2d61",
   "metadata": {},
   "source": [
    "Tested and LightGBM model because its common alternative to XGBoost trying to use parameters that are very similar to XGBoost since we heavily optimized or tuned that model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374f4014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LightGBM with XGBoost-inspired hyperparameters...\n",
      "Training until validation scores don't improve for 120 rounds\n",
      "[50]\tvalid_0's l2: 160.131\n",
      "[100]\tvalid_0's l2: 161.367\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's l2: 159.05\n",
      "\n",
      "LightGBM Residual Metrics:\n",
      "MAE:  9.745 pts\n",
      "RMSE: 12.611 pts\n",
      "RÂ²:   -0.000\n",
      "\n",
      "FULL TOTAL PERFORMANCE:\n",
      "Vegas Line -> MAE: 9.738 | RMSE: 12.618 | RÂ²: 0.124\n",
      "LightGBM   -> MAE: 9.745 | RMSE: 12.611 | RÂ²: 0.125\n",
      "Î” MAE:  +0.007\n",
      "Î” RMSE: -0.007\n",
      "\n",
      "Saved: test_predictions_lgbm.csv, lightgbm_model.txt\n"
     ]
    }
   ],
   "source": [
    "## LightGBM Residual Model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "## Load Data\n",
    "train_data = pd.read_csv('train_data.csv')\n",
    "test_data = pd.read_csv('test_data.csv')\n",
    "\n",
    "train_data['GAME_DATE'] = pd.to_datetime(train_data['GAME_DATE'])\n",
    "test_data['GAME_DATE'] = pd.to_datetime(test_data['GAME_DATE'])\n",
    "\n",
    "\n",
    "## Define Columns\n",
    "metadata_cols = ['GAME_ID', 'GAME_DATE', 'TEAM_ID', 'season']\n",
    "target_col = 'actual_second_half_total'\n",
    "vegas_col = 'h2_total'\n",
    "\n",
    "feature_cols = [c for c in train_data.columns if c not in metadata_cols + [target_col]]\n",
    "\n",
    "X_train = train_data[feature_cols].copy()\n",
    "y_train = train_data[target_col] - train_data[vegas_col]\n",
    "\n",
    "X_test = test_data[feature_cols].copy()\n",
    "y_test = test_data[target_col] - test_data[vegas_col]\n",
    "\n",
    "\n",
    "## Impute missing values\n",
    "for col in feature_cols:\n",
    "    median_val = X_train[col].median()\n",
    "    X_train[col].fillna(median_val, inplace=True)\n",
    "    X_test[col].fillna(median_val, inplace=True)\n",
    "\n",
    "## Train Model\n",
    "model = lgb.LGBMRegressor(\n",
    "    n_estimators=1800,\n",
    "    learning_rate=0.018,\n",
    "    max_depth=8,\n",
    "    num_leaves=255,\n",
    "    min_child_samples=20,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.75,\n",
    "    min_split_gain=0.05,\n",
    "    reg_alpha=0.2,\n",
    "    reg_lambda=0.6,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "# Train with early stopping\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=120), lgb.log_evaluation(period=50)]\n",
    ")\n",
    "\n",
    "\n",
    "## Evaluate Residual Performance\n",
    "y_pred_resid = model.predict(X_test)\n",
    "\n",
    "mae_resid = mean_absolute_error(y_test, y_pred_resid)\n",
    "rmse_resid = np.sqrt(mean_squared_error(y_test, y_pred_resid))\n",
    "r2_resid = r2_score(y_test, y_pred_resid)\n",
    "\n",
    "print(f\"\\nLightGBM Residual Metrics:\")\n",
    "print(f\"MAE:  {mae_resid:.3f} pts\")\n",
    "print(f\"RMSE: {rmse_resid:.3f} pts\")\n",
    "print(f\"RÂ²:   {r2_resid:.3f}\")\n",
    "\n",
    "\n",
    "## Reconstruct Full Totals\n",
    "y_pred_total = y_pred_resid + X_test[vegas_col]\n",
    "y_true_total = y_test + X_test[vegas_col]\n",
    "\n",
    "mae_total = mean_absolute_error(y_true_total, y_pred_total)\n",
    "rmse_total = np.sqrt(mean_squared_error(y_true_total, y_pred_total))\n",
    "r2_total = r2_score(y_true_total, y_pred_total)\n",
    "\n",
    "## Vegas baseline\n",
    "mae_vegas = mean_absolute_error(y_true_total, X_test[vegas_col])\n",
    "rmse_vegas = np.sqrt(mean_squared_error(y_true_total, X_test[vegas_col]))\n",
    "r2_vegas = r2_score(y_true_total, X_test[vegas_col])\n",
    "\n",
    "print(f\"\\nFull Total Performance:\")\n",
    "print(f\"Vegas Line  MAE: {mae_vegas:.3f} | RMSE: {rmse_vegas:.3f} | RÂ²: {r2_vegas:.3f}\")\n",
    "print(f\"LightGBM    MAE: {mae_total:.3f} | RMSE: {rmse_total:.3f} | RÂ²: {r2_total:.3f}\")\n",
    "print(f\"Î” MAE:  {mae_total - mae_vegas:+.3f}\")\n",
    "print(f\"Î” RMSE: {rmse_total - rmse_vegas:+.3f}\")\n",
    "\n",
    "## Save Results\n",
    "test_results = test_data.copy()\n",
    "test_results['lgbm_predicted_residual'] = y_pred_resid\n",
    "test_results['lgbm_predicted_total'] = y_pred_total\n",
    "test_results['lgbm_edge_vs_vegas'] = y_pred_resid\n",
    "\n",
    "test_results.to_csv('test_predictions_lgbm.csv', index=False)\n",
    "model.booster_.save_model('lightgbm_model.txt')\n",
    "\n",
    "print(\"\\nSaved: test_predictions_lgbm.csv, lightgbm_model.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bbf20d",
   "metadata": {},
   "source": [
    "Lastly, we tested an Elastic Net Model in order to see if a linear model would perform better. This was a sanity check and it confirmed our suspicions that linear models would not capture the complexity of NBA games, even if they're rather homogenous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da08345e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Elastic Net...\n",
      "\n",
      "Elastic Net Residual Metrics:\n",
      "MAE:  10.868 pts\n",
      "RMSE: 13.880 pts\n",
      "RÂ²:   -0.211\n",
      "\n",
      "FULL TOTAL PERFORMANCE:\n",
      "Vegas Line  -> MAE: 9.738 | RMSE: 12.618 | RÂ²: 0.124\n",
      "Elastic Net -> MAE: 10.868 | RMSE: 13.880 | RÂ²: -0.060\n",
      "Î” MAE:  +1.130\n",
      "Î” RMSE: +1.262\n",
      "\n",
      "Saved: test_predictions_enet.csv, elastic_net_model.pkl, elastic_net_scaler.pkl\n"
     ]
    }
   ],
   "source": [
    "## Elastic Net Residual Model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "## Load Data\n",
    "train_data = pd.read_csv('train_data.csv')\n",
    "test_data = pd.read_csv('test_data.csv')\n",
    "\n",
    "train_data['GAME_DATE'] = pd.to_datetime(train_data['GAME_DATE'])\n",
    "test_data['GAME_DATE'] = pd.to_datetime(test_data['GAME_DATE'])\n",
    "\n",
    "\n",
    "## Define Columns\n",
    "metadata_cols = ['GAME_ID', 'GAME_DATE', 'TEAM_ID', 'season']\n",
    "target_col = 'actual_second_half_total'\n",
    "vegas_col = 'h2_total'\n",
    "\n",
    "feature_cols = [c for c in train_data.columns if c not in metadata_cols + [target_col]]\n",
    "\n",
    "X_train = train_data[feature_cols].copy()\n",
    "y_train = train_data[target_col] - train_data[vegas_col]\n",
    "\n",
    "X_test = test_data[feature_cols].copy()\n",
    "y_test = test_data[target_col] - test_data[vegas_col]\n",
    "\n",
    "## Impute missing values\n",
    "for col in feature_cols:\n",
    "    median_val = X_train[col].median()\n",
    "    X_train[col].fillna(median_val, inplace=True)\n",
    "    X_test[col].fillna(median_val, inplace=True)\n",
    "\n",
    "\n",
    "## Scale Features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "## Train Model\n",
    "model = ElasticNet(\n",
    "    alpha=0.1,\n",
    "    l1_ratio=0.5,\n",
    "    max_iter=10000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "## Evaluate Residual Performance\n",
    "y_pred_resid = model.predict(X_test_scaled)\n",
    "\n",
    "mae_resid = mean_absolute_error(y_test, y_pred_resid)\n",
    "rmse_resid = np.sqrt(mean_squared_error(y_test, y_pred_resid))\n",
    "r2_resid = r2_score(y_test, y_pred_resid)\n",
    "\n",
    "print(f\"\\nElastic Net Residual Metrics:\")\n",
    "print(f\"MAE:  {mae_resid:.3f} pts\")\n",
    "print(f\"RMSE: {rmse_resid:.3f} pts\")\n",
    "print(f\"RÂ²:   {r2_resid:.3f}\")\n",
    "\n",
    "# Reconstruct totals\n",
    "y_pred_total = y_pred_resid + X_test[vegas_col]\n",
    "y_true_total = y_test + X_test[vegas_col]\n",
    "\n",
    "mae_total = mean_absolute_error(y_true_total, y_pred_total)\n",
    "rmse_total = np.sqrt(mean_squared_error(y_true_total, y_pred_total))\n",
    "r2_total = r2_score(y_true_total, y_pred_total)\n",
    "\n",
    "\n",
    "## Vegas baseline\n",
    "mae_vegas = mean_absolute_error(y_true_total, X_test[vegas_col])\n",
    "rmse_vegas = np.sqrt(mean_squared_error(y_true_total, X_test[vegas_col]))\n",
    "r2_vegas = r2_score(y_true_total, X_test[vegas_col])\n",
    "\n",
    "print(f\"\\nFull Total Performance:\")\n",
    "print(f\"Vegas Line   MAE: {mae_vegas:.3f} | RMSE: {rmse_vegas:.3f} | RÂ²: {r2_vegas:.3f}\")\n",
    "print(f\"Elastic Net  MAE: {mae_total:.3f} | RMSE: {rmse_total:.3f} | RÂ²: {r2_total:.3f}\")\n",
    "print(f\"Î” MAE:  {mae_total - mae_vegas:+.3f}\")\n",
    "print(f\"Î” RMSE: {rmse_total - rmse_vegas:+.3f}\")\n",
    "\n",
    "## Save Results\n",
    "test_results = test_data.copy()\n",
    "test_results['enet_predicted_residual'] = y_pred_resid\n",
    "test_results['enet_predicted_total'] = y_pred_total\n",
    "test_results['enet_edge_vs_vegas'] = y_pred_resid\n",
    "\n",
    "test_results.to_csv('test_predictions_enet.csv', index=False)\n",
    "joblib.dump(model, 'elastic_net_model.pkl')\n",
    "joblib.dump(scaler, 'elastic_net_scaler.pkl')\n",
    "\n",
    "print(\"\\nSaved: test_predictions_enet.csv, elastic_net_model.pkl, elastic_net_scaler.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678591aa",
   "metadata": {},
   "source": [
    "XGBoost performed best, with other tree-based models (Random Forest, LightGBM) showing similar results. All models produced predictions close to the Vegas line with marginal deviations. Given the inherent variance in NBA games and minimal gains from extensive XGBoost tuning, we believe these results represent near the performance ceiling for this task. We therefore opted not to tune the remaining models, particularly the MLP and Elastic Net which performed significantly worse initially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ce44a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SECOND HALF TOTALS - MODEL COMPARISON\n",
      "                    MAE   RMSE     RÂ²  Î” MAE vs Vegas  Î” RMSE vs Vegas\n",
      "XGBoost Residual  9.735 12.601  0.127          -0.004           -0.017\n",
      "Vegas Line        9.738 12.618  0.124           0.000            0.000\n",
      "LightGBM          9.745 12.611  0.125           0.007           -0.007\n",
      "Random Forest     9.747 12.620  0.124           0.008            0.002\n",
      "Neural Network    9.806 12.722  0.110           0.067            0.103\n",
      "Elastic Net      10.868 13.880 -0.060           1.130            1.262\n",
      "\n",
      "XGBoost Residual beats Vegas line\n",
      "\n",
      "Saved: model_comparison.csv\n"
     ]
    }
   ],
   "source": [
    "## Full Model Comparison\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "## Load All Prediction Files\n",
    "vegas_baseline = pd.read_csv(\"test_data.csv\")\n",
    "xgb_preds = pd.read_csv(\"test_predictions_residual.csv\")\n",
    "rf_preds = pd.read_csv(\"test_predictions_rf.csv\")\n",
    "mlp_preds = pd.read_csv(\"test_predictions_mlp.csv\")\n",
    "lgbm_preds = pd.read_csv(\"test_predictions_lgbm.csv\")\n",
    "enet_preds = pd.read_csv(\"test_predictions_enet.csv\")\n",
    "\n",
    "\n",
    "## Get Actual Values and Predictions\n",
    "y_true = vegas_baseline[\"actual_second_half_total\"]\n",
    "y_vegas = vegas_baseline[\"h2_total\"]\n",
    "\n",
    "y_pred_xgb = xgb_preds[\"predicted_total\"]\n",
    "y_pred_rf = rf_preds[\"rf_predicted_total\"]\n",
    "y_pred_mlp = mlp_preds[\"mlp_predicted_total\"]\n",
    "y_pred_lgbm = lgbm_preds[\"lgbm_predicted_total\"]\n",
    "y_pred_enet = enet_preds[\"enet_predicted_total\"]\n",
    "\n",
    "\n",
    "## Evaluation Function\n",
    "def evaluate(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mae, rmse, r2\n",
    "\n",
    "\n",
    "## Calculate Metrics for All Models\n",
    "results = {\n",
    "    \"Vegas Line\": evaluate(y_true, y_vegas),\n",
    "    \"XGBoost Residual\": evaluate(y_true, y_pred_xgb),\n",
    "    \"Random Forest\": evaluate(y_true, y_pred_rf),\n",
    "    \"Neural Network\": evaluate(y_true, y_pred_mlp),\n",
    "    \"LightGBM\": evaluate(y_true, y_pred_lgbm),\n",
    "    \"Elastic Net\": evaluate(y_true, y_pred_enet),\n",
    "}\n",
    "\n",
    "## Create Comparison Dataframe\n",
    "summary = pd.DataFrame(results, index=[\"MAE\", \"RMSE\", \"RÂ²\"]).T\n",
    "summary[\"Î” MAE vs Vegas\"] = summary[\"MAE\"] - summary.loc[\"Vegas Line\", \"MAE\"]\n",
    "summary[\"Î” RMSE vs Vegas\"] = summary[\"RMSE\"] - summary.loc[\"Vegas Line\", \"RMSE\"]\n",
    "\n",
    "# Sort by MAE (best first)\n",
    "summary = summary.sort_values(\"MAE\")\n",
    "\n",
    "print(\"SECOND HALF TOTALS - MODEL COMPARISON\")\n",
    "print(summary.to_string(float_format=lambda x: f\"{x:0.3f}\"))\n",
    "\n",
    "## Save Comparison\n",
    "summary.to_csv('model_comparison.csv')\n",
    "print(\"\\nSaved: model_comparison.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9ce12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Unsupervised Learning\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "## Load Training Data\n",
    "df = pd.read_csv(\"train_data.csv\")\n",
    "df[\"GAME_DATE\"] = pd.to_datetime(df[\"GAME_DATE\"])\n",
    "\n",
    "## Define Columns\n",
    "metadata_cols = [\"GAME_ID\", \"GAME_DATE\", \"TEAM_ID\", \"season\"]\n",
    "target_col = \"actual_second_half_total\"\n",
    "betting_col = \"h2_total\"\n",
    "\n",
    "drop_cols = set(metadata_cols + [target_col, betting_col])\n",
    "feature_cols = [c for c in df.columns if c not in drop_cols]\n",
    "\n",
    "X = df[feature_cols].copy()\n",
    "\n",
    "\n",
    "## Impute missing values\n",
    "missing = X.isna().sum().sum()\n",
    "if missing > 0:\n",
    "    for c in feature_cols:\n",
    "        if X[c].isna().any():\n",
    "            X[c].fillna(X[c].median(), inplace=True)\n",
    "else:\n",
    "    print(\"No imputing necessary\")\n",
    "\n",
    "\n",
    "## Scale and Apply PCA\n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "n_components = min(30, X_scaled.shape[1])\n",
    "pca = PCA(n_components=n_components, svd_solver=\"auto\", random_state=42)\n",
    "X_pcs = pca.fit_transform(X_scaled)\n",
    "\n",
    "explained = pca.explained_variance_ratio_.cumsum()\n",
    "var_99 = np.argmax(explained >= 0.99) + 1 if (explained >= 0.99).any() else n_components\n",
    "\n",
    "print(f\"\\nPCA components: {n_components}\")\n",
    "print(f\"Explained variance (first 5 PCs cumulative): {explained[:5]}\")\n",
    "print(f\"Components to reach ~99% variance: {var_99}\")\n",
    "\n",
    "\n",
    "## K-Means Clustering\n",
    "best = {\"k\": None, \"score\": -1, \"model\": None, \"labels\": None}\n",
    "for k in [6, 8, 10, 12]:\n",
    "    km = KMeans(n_clusters=k, n_init=20, max_iter=500, random_state=42)\n",
    "    labels = km.fit_predict(X_pcs)\n",
    "    score = silhouette_score(X_pcs, labels) if len(np.unique(labels)) > 1 else -1\n",
    "    print(f\"k={k:2d} -> silhouette: {score:.4f}\")\n",
    "\n",
    "    if score > best[\"score\"] or (score == best[\"score\"] and k < best[\"k\"]):\n",
    "        best = {\"k\": k, \"score\": score, \"model\": km, \"labels\": labels}\n",
    "\n",
    "k_best = best[\"k\"]\n",
    "kmeans = best[\"model\"]\n",
    "labels = best[\"labels\"]\n",
    "print(f\"\\nSelected k={k_best} (silhouette={best['score']:.4f})\")\n",
    "\n",
    "\n",
    "## Construct Cluster Output\n",
    "pc_cols = [f\"PC{i+1}\" for i in range(X_pcs.shape[1])]\n",
    "out = df[[\"GAME_ID\", \"GAME_DATE\", \"TEAM_ID\", \"season\"]].copy()\n",
    "for i, col in enumerate(pc_cols):\n",
    "    out[col] = X_pcs[:, i]\n",
    "out[\"cluster_id\"] = labels\n",
    "\n",
    "if target_col in df.columns:\n",
    "    out[target_col] = df[target_col].values\n",
    "if betting_col in df.columns:\n",
    "    out[betting_col] = df[betting_col].values\n",
    "    if target_col in df.columns:\n",
    "        out[\"edge_vs_line\"] = out[target_col] - out[betting_col]\n",
    "\n",
    "out.to_csv(\"pca_kmeans_train.csv\", index=False)\n",
    "print(\"Saved pca_kmeans_train.csv\")\n",
    "\n",
    "\n",
    "## Save Unsupervised Models\n",
    "joblib.dump(scaler, \"unsup_scaler.pkl\")\n",
    "joblib.dump(pca, \"unsup_pca.pkl\")\n",
    "joblib.dump(kmeans, \"unsup_kmeans.pkl\")\n",
    "print(\"Saved: unsup_scaler.pkl, unsup_pca.pkl, unsup_kmeans.pkl\")\n",
    "\n",
    "## Visualization\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "scatter = plt.scatter(X_pcs[:, 0], X_pcs[:, 1], c=labels, cmap='viridis', \n",
    "                        alpha=0.5, s=30, edgecolors='none')\n",
    "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)')\n",
    "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)')\n",
    "plt.title(f'K-Means Clustering in PCA Space (k={k_best}, silhouette={best[\"score\"]:.3f})')\n",
    "plt.colorbar(scatter, label='Cluster ID')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('cluster_visualization.png', dpi=300, bbox_inches='tight')\n",
    "print(\"Saved cluster_visualization.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08eabf0e",
   "metadata": {},
   "source": [
    " PCA performing well is not surprising so many of the features we created were derivatives of stats that are already present. So it makes sense that PCA was able to compress these down into 30 features, there might only be 30 features that observe different qualities of an NBA game from the dataset.\n",
    "\n",
    " Cluster doees not seem to add much of anything. The silhouettes were incredibly small. We think this makes sense because the NBA is a multi-billion dollar industry and it makes sense that its converged similar team composition, style of play, and game outcomes.  Yes there is innovation and variance but teams are incentivized so heavily to win that we do not actually see these innovations completely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e5406c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## XGBoost Residual Model with PCA Features\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "## Load Data\n",
    "train = pd.read_csv(\"train_data.csv\")\n",
    "test = pd.read_csv(\"test_data.csv\")\n",
    "\n",
    "# Format Data\n",
    "for df in (train, test):\n",
    "    if 'GAME_DATE' in df.columns:\n",
    "        df['GAME_DATE'] = pd.to_datetime(df['GAME_DATE'], errors='coerce')\n",
    "\n",
    "## Define Columns\n",
    "metadata_cols = [\"GAME_ID\", \"GAME_DATE\", \"TEAM_ID\", \"season\"]\n",
    "target_col = \"actual_second_half_total\"\n",
    "vegas_col = \"h2_total\"\n",
    "\n",
    "feature_cols = [c for c in train.columns if c not in (metadata_cols + [target_col])]\n",
    "\n",
    "X_train = train[feature_cols].copy()\n",
    "X_test = test[feature_cols].copy()\n",
    "\n",
    "y_train_total = train[target_col].values\n",
    "y_test_total = test[target_col].values\n",
    "\n",
    "y_train = (train[target_col] - train[vegas_col]).values\n",
    "y_test = (test[target_col]  - test[vegas_col]).values\n",
    "\n",
    "\n",
    "## Impute Missing Values\n",
    "medians = X_train.median(numeric_only=True)\n",
    "X_train = X_train.fillna(medians)\n",
    "X_test = X_test.fillna(medians)\n",
    "\n",
    "\n",
    "## Apply PCA (fit fresh or load from disk)\n",
    "use_saved = False\n",
    "scaler_path = \"unsup_scaler.pkl\"\n",
    "pca_path = \"unsup_pca.pkl\"\n",
    "\n",
    "if os.path.exists(scaler_path) and os.path.exists(pca_path):\n",
    "    scaler = joblib.load(scaler_path)\n",
    "    pca    = joblib.load(pca_path)\n",
    "    # Verify feature count matches\n",
    "    try:\n",
    "        if hasattr(scaler, \"n_features_in_\") and scaler.n_features_in_ == X_train.shape[1]:\n",
    "            use_saved = True\n",
    "    except Exception:\n",
    "        use_saved = False\n",
    "\n",
    "if use_saved:\n",
    "    print(\"\\nUsing saved scaler & PCA (unsup_scaler.pkl / unsup_pca.pkl)\")\n",
    "else:\n",
    "    print(\"Falling back to recreating scale and pca\")\n",
    "\n",
    "    scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    \n",
    "    # Choose components: keep up to 99% variance, cap at 50 to be safe\n",
    "    pca_full = PCA(svd_solver=\"auto\", random_state=42)\n",
    "    pca_full.fit(X_train_scaled)\n",
    "    cumsum = np.cumsum(pca_full.explained_variance_ratio_)\n",
    "    n_comp = int(np.searchsorted(cumsum, 0.99) + 1)\n",
    "    n_comp = min(max(n_comp, 10), 50)  # between 10 and 50\n",
    "    print(f\"Selected PCA components: {n_comp} (â‰ˆ99% variance)\")\n",
    "\n",
    "    pca = PCA(n_components=n_comp, svd_solver=\"auto\", random_state=42)\n",
    "    # Re-fit with chosen n_components\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    pca.fit(X_train_scaled)\n",
    "\n",
    "    # Save for reuse next time\n",
    "    joblib.dump(scaler, scaler_path)\n",
    "    joblib.dump(pca, pca_path)\n",
    "    print(\"Saved new unsup_scaler.pkl and unsup_pca.pkl\")\n",
    "\n",
    "# Transform using the scaler/PCA in use (saved or fresh)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_pca = pca.transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "print(f\"\\nPCA features shape -> train: {X_train_pca.shape}, test: {X_test_pca.shape}\")\n",
    "\n",
    "\n",
    "## Train Model\n",
    "model = xgb.XGBRegressor(\n",
    "    n_estimators=1300,\n",
    "    learning_rate=0.018,\n",
    "    max_depth=6,\n",
    "    min_child_weight=2,\n",
    "    subsample=0.75,\n",
    "    colsample_bytree=0.7,\n",
    "    gamma=0.15,\n",
    "    reg_alpha=0.6,\n",
    "    reg_lambda=1.2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    early_stopping_rounds=75,\n",
    "    eval_metric=\"rmse\"\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train_pca, y_train,\n",
    "    eval_set=[(X_train_pca, y_train), (X_test_pca, y_test)],\n",
    "    verbose=50\n",
    ")\n",
    "\n",
    "## Evaluate Residual Performance\n",
    "y_pred_resid = model.predict(X_test_pca)\n",
    "\n",
    "mae_resid = mean_absolute_error(y_test, y_pred_resid)\n",
    "rmse_resid = np.sqrt(mean_squared_error(y_test, y_pred_resid))\n",
    "r2_resid = r2_score(y_test, y_pred_resid)\n",
    "\n",
    "print(\"\\nXGBoost Residual Metrics:\")\n",
    "print(f\"MAE:  {mae_resid:.3f} pts\")\n",
    "print(f\"RMSE: {rmse_resid:.3f} pts\")\n",
    "print(f\"RÂ²:   {r2_resid:.3f}\")\n",
    "\n",
    "\n",
    "## Reconstruct Full Totals\n",
    "y_pred_total = y_pred_resid + test[vegas_col].values\n",
    "mae_total = mean_absolute_error(y_test_total, y_pred_total)\n",
    "rmse_total = np.sqrt(mean_squared_error(y_test_total, y_pred_total))\n",
    "r2_total = r2_score(y_test_total, y_pred_total)\n",
    "\n",
    "## Vegas Baseline\n",
    "mae_line = mean_absolute_error(y_test_total, test[vegas_col].values)\n",
    "rmse_line = np.sqrt(mean_squared_error(y_test_total, test[vegas_col].values))\n",
    "r2_line = r2_score(y_test_total, test[vegas_col].values)\n",
    "\n",
    "print(\"\\nFull Total Performance:\")\n",
    "print(f\"Vegas Line     MAE: {mae_vegas:.3f} | RMSE: {rmse_vegas:.3f} | RÂ²: {r2_vegas:.3f}\")\n",
    "print(f\"XGBoost + PCA  MAE: {mae_total:.3f} | RMSE: {rmse_total:.3f} | RÂ²: {r2_total:.3f}\")\n",
    "print(f\"Î” MAE:  {mae_total - mae_vegas:+.3f}\")\n",
    "print(f\"Î” RMSE: {rmse_total - rmse_vegas:+.3f}\")\n",
    "\n",
    "## Save Predictions\n",
    "test_out = test.copy()\n",
    "test_out[\"predicted_residual_pca\"] = y_pred_resid\n",
    "test_out[\"predicted_total_pca\"] = y_pred_total\n",
    "test_out[\"edge_vs_vegas_pca\"] = y_pred_resid\n",
    "test_out[\"abs_error_pca\"] = np.abs(y_test_total - y_pred_total)\n",
    "\n",
    "test_out.to_csv(\"test_predictions_residual_pca.csv\", index=False)\n",
    "model.save_model(\"xgboost_residual_pca.json\")\n",
    "\n",
    "# Save another feature list\n",
    "with open(\"pca_feature_cols.json\", \"w\") as f:\n",
    "    json.dump(feature_cols, f, indent=2)\n",
    "\n",
    "print(\"Saved test_predictions_residual_pca.csv\")\n",
    "print(\"Saved xgboost_residual_pca.json\")\n",
    "print(\"Saved pca_feature_cols.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6038943c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predict Holdouts\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "# Loading Model\n",
    "model = xgb.XGBRegressor()\n",
    "model.load_model(\"xgboost_residual_model.json\")\n",
    "\n",
    "\n",
    "## Load Data\n",
    "holdout_data = pd.read_csv(\"holdout_data.csv\")\n",
    "print(f\"Holdout: {len(holdout_data)} rows\")\n",
    "\n",
    "## Define Columns\n",
    "metadata_cols = [\"GAME_ID\", \"GAME_DATE\", \"TEAM_ID\", \"season\"]\n",
    "target_col = \"actual_second_half_total\"\n",
    "vegas_col = \"h2_total\"\n",
    "\n",
    "feature_cols = [c for c in holdout_data.columns if c not in metadata_cols + [target_col]]\n",
    "X_holdout = holdout_data[feature_cols].copy()\n",
    "\n",
    "\n",
    "## Impute missing values\n",
    "for col in X_holdout.columns:\n",
    "    if X_holdout[col].isnull().any():\n",
    "        X_holdout[col].fillna(X_holdout[col].median(), inplace=True)\n",
    "\n",
    "\n",
    "## Predict\n",
    "predicted_residuals = model.predict(X_holdout)\n",
    "\n",
    "holdout_data[\"predicted_residual\"] = predicted_residuals\n",
    "holdout_data[\"predicted_total\"] = predicted_residuals + holdout_data[vegas_col]\n",
    "holdout_data[\"bet_edge\"] = predicted_residuals\n",
    "\n",
    "\n",
    "## Save Full Holdout Dataset\n",
    "holdout_data.to_csv(\"holdout_predictions.csv\", index=False)\n",
    "print(f\"Saved holdout_predictions.csv\")\n",
    "\n",
    "\n",
    "## Clean Holdout Dataset\n",
    "clean_predictions = holdout_data[[\n",
    "    'GAME_ID',\n",
    "    'GAME_DATE',\n",
    "    'TEAM_ID',\n",
    "    'h2_total',\n",
    "    'predicted_total',\n",
    "    'actual_second_half_total',\n",
    "    'bet_edge'\n",
    "]].copy()\n",
    "\n",
    "# Format dates\n",
    "clean_predictions['GAME_DATE'] = pd.to_datetime(clean_predictions['GAME_DATE']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Rename columns\n",
    "clean_predictions.columns = [\n",
    "    'game_id',\n",
    "    'date',\n",
    "    'team_id',\n",
    "    'h2_total',\n",
    "    'predicted_total',\n",
    "    'actual_total',\n",
    "    'bet_edge'\n",
    "]\n",
    "\n",
    "# Sort by date\n",
    "clean_predictions = clean_predictions.sort_values('date')\n",
    "\n",
    "\n",
    "## Save clean (two rows per game - home and away teams)\n",
    "clean_predictions.to_csv('holdout_predictions_clean.csv', index=False)\n",
    "print(f\"Saved holdout_predictions_clean.csv\")\n",
    "\n",
    "# Save game-level (one row per game)\n",
    "game_level = clean_predictions.drop_duplicates('game_id').copy()\n",
    "game_level.to_csv('holdout_predictions_games.csv', index=False)\n",
    "print(f\"Saved holdout_predictions_games.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f56721",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Optimize Betting Thresholds (ROI)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "## Load Data\n",
    "holdout_data = pd.read_csv(\"holdout_predictions_games.csv\")\n",
    "\n",
    "\n",
    "## Filter to Games with Valid Lines + Totals\n",
    "bettable = holdout_data[\n",
    "    (holdout_data[\"h2_total\"].notna()) &\n",
    "    (holdout_data[\"actual_total\"].notna())\n",
    "].copy()\n",
    "\n",
    "\n",
    "## Prepare Values\n",
    "bet_edge = bettable[\"bet_edge\"].values\n",
    "actual_total = bettable[\"actual_total\"].values  # Changed\n",
    "vegas_line = bettable[\"h2_total\"].values\n",
    "\n",
    "## Run Threshold Sweep in .25 increments\n",
    "results = []\n",
    "thresholds = np.arange(0.5, 7.25, 0.25)\n",
    "\n",
    "for threshold in thresholds:\n",
    "    # Filtering bets\n",
    "    bet_over = bet_edge > threshold\n",
    "    bet_under = bet_edge < -threshold\n",
    "    \n",
    "    # Count bets\n",
    "    over_count = bet_over.sum()\n",
    "    under_count = bet_under.sum()\n",
    "    total_bets = over_count + under_count\n",
    "    \n",
    "    if total_bets == 0:\n",
    "        continue\n",
    "    \n",
    "    # Calculate wins\n",
    "    over_wins = ((actual_total > vegas_line) & bet_over).sum()\n",
    "    under_wins = ((actual_total < vegas_line) & bet_under).sum()\n",
    "    total_wins = over_wins + under_wins\n",
    "    \n",
    "    # Win rates\n",
    "    over_win_rate = over_wins / over_count * 100 if over_count > 0 else 0\n",
    "    under_win_rate = under_wins / under_count * 100 if under_count > 0 else 0\n",
    "    total_win_rate = total_wins / total_bets * 100\n",
    "    \n",
    "    # Profit with 110 odds\n",
    "    over_profit = (over_wins * 100) - ((over_count - over_wins) * 110)\n",
    "    under_profit = (under_wins * 100) - ((under_count - under_wins) * 110)\n",
    "    total_profit = over_profit + under_profit\n",
    "    \n",
    "    # ROI\n",
    "    total_risked = total_bets * 110\n",
    "    roi = (total_profit / total_risked * 100) if total_risked > 0 else 0\n",
    "    \n",
    "    results.append({\n",
    "        'threshold': threshold,\n",
    "        'total_bets': total_bets,\n",
    "        'over_bets': over_count,\n",
    "        'under_bets': under_count,\n",
    "        'total_wins': total_wins,\n",
    "        'over_wins': over_wins,\n",
    "        'under_wins': under_wins,\n",
    "        'win_rate': total_win_rate,\n",
    "        'over_win_rate': over_win_rate,\n",
    "        'under_win_rate': under_win_rate,\n",
    "        'profit': total_profit,\n",
    "        'roi': roi\n",
    "    })\n",
    "\n",
    "## Save and Print Top Results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "top_roi = results_df.nlargest(10, 'roi')\n",
    "print(top_roi[['threshold', 'total_bets', 'win_rate', 'profit', 'roi']].to_string(index=False))\n",
    "\n",
    "results_df.to_csv('threshold_optimization_results.csv', index=False)\n",
    "print(f\"Saved threshold_optimization_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
